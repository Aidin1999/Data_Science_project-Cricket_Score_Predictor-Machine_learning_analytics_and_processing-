{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Model Training\n",
        "\n",
        "In this section, we focus on training regression models for score prediction and logistic regression models for winner prediction. A custom evaluation metric is also introduced to balance overfitting, underfitting, and model accuracy. The process involves preparing the environment by loading pre-processed data and installing the necessary libraries.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 1: Install Necessary Libraries (Colab Configuration)\n",
        "Before beginning model training, ensure that all necessary libraries are installed. Libraries such as `numpy`, `pandas`, `scikit-learn`, `matplotlib`, and `catboost` are essential for our tasks.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 2: Load Processed Data\n",
        "Load the pre-processed data into the environment to ensure it is ready for model training and validation.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 3: Regression Model - Data Exploration and Feature Importance\n",
        "- Explore the data to identify key features and their importance.\n",
        "- Perform correlation analysis and feature mapping to understand the relationships and the impact of each feature on model predictions.\n",
        "- Split the data into training and testing sets to validate model performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 4: Define Regression Training and Evaluation Functions\n",
        "Define functions for training and evaluating regression models. These functions compute critical performance metrics, including:\n",
        "- **R²**: Variance explained by the model.\n",
        "- **RMSE**: Average magnitude of prediction errors.\n",
        "- **MBD**: Average bias between predictions and actual values.\n",
        "\n",
        "The custom evaluation metrics is introduced:\n",
        "$$\n",
        "\\text{Custom Metric} = \\left(\\frac{\\text{R² (Test)}}{\\text{R² Difference}}\\right) \\times \\left(\\frac{1}{\\text{RMSE (Test)} \\cdot \\sqrt[4]{\\text{RMSE Difference}}}\\right) \\times \\left(\\frac{1}{|\\text{MBD (Test)}| \\cdot \\sqrt[4]{\\text{MBD Difference}}}\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Custom Metric2} = \\left(\\frac{\\text{R² op}}  {\\sqrt[4]{\\text{R² Difference}}}\\right) \\times \\left(\\frac{1}{\\text{RMSE op} \\cdot \\sqrt[4]{\\text{RMSE Difference}}}\\right) \\times \\left(\\frac{1}{|\\text{MBD op}| \\cdot \\sqrt[4]{\\text{MBD Difference}}}\\right)\n",
        "$$\n",
        "where\n",
        "   $$\n",
        "   R^2_{\\text{op}} = \\frac{2 \\cdot R^2_{\\text{test}} - R^2_{\\text{train}}}{3}\n",
        "   $$\n",
        "  \n",
        "   $$\n",
        "   \\text{RMSE}_{\\text{op}} = \\frac{2 \\cdot \\text{RMSE}_{\\text{test}} + \\text{RMSE}_{\\text{train}}}{3}\n",
        "   $$\n",
        "\n",
        "   $$\n",
        "   \\text{MBD}_{\\text{op}} = \\frac{2 \\cdot |\\text{MBD}_{\\text{test}}| + |\\text{MBD}_{\\text{train}}|}{3}\n",
        "   $$\n",
        "\n",
        "This metric balances prediction accuracy, overfitting, and underfitting, making it vital for selecting robust models.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 5: Regression Model Training\n",
        "Train the regression model using the training dataset. Employ cross-validation techniques to ensure the model generalizes well to unseen data. After finding best params for each model, train best combination of top models based on stack.  \n",
        "\n",
        "---\n",
        "\n",
        "#### Step 6: Evaluate Regression Model\n",
        "Evaluate the regression model using the test dataset. Metrics such as R², RMSE, and the custom metric and custom metric2 are analyzed to gauge model performance and reliability on unseen data and test data.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 7: Logistic Regression - Data Exploration and Feature Importance\n",
        "Similar to regression, explore data for logistic regression to identify significant features. Prepare the dataset for binary classification tasks.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 8: Define Logistic Training and Evaluation Functions\n",
        "Define functions for training and evaluating logistic regression models. These functions compute key classification metrics:\n",
        "- **Accuracy**: Percentage of correct predictions.\n",
        "- **Precision**: Proportion of true positives among predicted positives.\n",
        "- **Recall**: Proportion of true positives among actual positives.\n",
        "- **F1-Score**: Harmonic mean of precision and recall.\n",
        "\n",
        "A custom evaluation metric is introduced for logistic regression to address overfitting, underfitting, and prediction reliability:\n",
        "$$\n",
        "\\text{Custom Metric} = \\left(\\frac{\\text{F1 (Test)}}{\\text{F1 Difference}}\\right) \\times \\left(\\frac{\\text{Accuracy (Test)}}{\\text{Accuracy Difference}}\\right)\n",
        "$$\n",
        "This metric ensures that models with high test F1 scores and minimal overfitting are prioritized.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 9: Logistic Regression Training\n",
        "Train the logistic regression model using the training dataset. Adjust model-specific parameters (e.g., regularization) to improve performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 10: Evaluate Logistic Regression Model\n",
        "Evaluate the logistic regression model on the test dataset using metrics such as accuracy, precision, recall, and F1-score. Analyze the confusion matrix for insights into model performance.\n",
        "\n",
        "The custom metric is applied to regression and logistic models to ensure balanced evaluation, addressing overfitting and underfitting concerns effectively.\n"
      ],
      "metadata": {
        "id": "i5RYXaTqZVoG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLheKVH6rEOh"
      },
      "source": [
        "# Step 1: Install Necessary Libraries colab configuration\n",
        "## Google Colab:\n",
        "I utilize Google Colab for processing large datasets due to its Software as a Service (SaaS) nature provided by Google. With Google Colab, I can avoid the need for infrastructure maintenance and limits, making it a hassle-free solution for my project. Its ease of use and seamless integration with other Google services make it a convenient choice for implementing my data processing tasks. Additionally, Google Colab provides powerful computational resources, including GPU and TPU support, enabling me to efficiently handle the computational demands of big data analytics without worrying about hardware constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pliBcKscd5JQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24d6397-4ba5-4485-da05-c2368f8aea33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: monut to google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3kIEVGCzMuwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c7c18f-e0ee-417f-af50-a483c572cbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LYAwM1SF_9iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7770f46-2ab4-40bd-e465-e151bb9ba2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ZB0-XSkmJwZ"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np   # For numerical computations and array operations\n",
        "import matplotlib.pyplot as plt # For visualisations\n",
        "\n",
        "# Scikit-learn utilities and models\n",
        "from sklearn.pipeline import Pipeline, make_pipeline  # To build pipelines for data transformation and modeling\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures  # StandardScaler for feature scaling, PolynomialFeatures for polynomial regression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV, cross_val_predict, KFold  # For data splitting, hyperparameter tuning, and cross-validation\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, BayesianRidge, Ridge, LogisticRegression  # Linear and regularized regression models\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier  # Tree models for regression and classification\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier, StackingRegressor  # Ensemble methods\n",
        "from sklearn.svm import SVR  # Support Vector Regression\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier  # Nearest Neighbors for regression and classification\n",
        "from sklearn.metrics import r2_score, mean_squared_error, make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_auc_score # For model evaluation metrics\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor  # Gaussian Process Regression\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C  # Kernels for Gaussian Process Regression\n",
        "\n",
        "# CatBoost library\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier  # CatBoost for regression and classification\n",
        "\n",
        "\n",
        "# XGBoost library\n",
        "from xgboost import XGBRegressor, XGBClassifier  # XGBoost for high-performance regression and classification\n",
        "\n",
        "from itertools import combinations #for stack combinations\n",
        "\n",
        "# Warnings\n",
        "import warnings  # To handle warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# step 2: Load Processed Data"
      ],
      "metadata": {
        "id": "0DoTs-qebg2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bFXhvfYNenmx"
      },
      "outputs": [],
      "source": [
        "data_win_p=pd.read_csv('/content/drive/MyDrive/cricket /data.csv')#reading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_pB1fASy6HB"
      },
      "source": [
        "now data is proccesd to be ready to be consumed for ml app"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Regression Model: Data Exploration and Feature Importance"
      ],
      "metadata": {
        "id": "TJnE-bK0bjQM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LyRo0CqSjPwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "12336958-1141-4869-e9e4-0939e26b3cd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sum team mate  sum team opponent  number of wins  Type Gender  month  \\\n",
              "0         151.028046         221.846948             364  Test   male     11   \n",
              "1         116.145696         153.524269             364  Test   male     11   \n",
              "2         112.889448         152.355429             364  Test   male     11   \n",
              "3         112.889448         106.416181             364  Test   male     12   \n",
              "4         112.889448         100.614929             364  Test   male     12   \n",
              "...              ...                ...             ...   ...    ...    ...   \n",
              "35681      58.111437          30.926471              28   MDM   male     11   \n",
              "35682      18.329607         117.884663              83   T20   male     11   \n",
              "35683     117.964467          59.177502             440   ODI   male     11   \n",
              "35684       1.051244          11.080450               3   T20   male     11   \n",
              "35685       8.834284           2.065272              16   T20   male     11   \n",
              "\n",
              "       Score  total_wins  team_experience  opponent_total_wins  \\\n",
              "0        605         705              582                  268   \n",
              "1        246         705              582                  268   \n",
              "2        510         705              582                  268   \n",
              "3        631         705              582                  249   \n",
              "4        624         705              582                  249   \n",
              "...      ...         ...              ...                  ...   \n",
              "35681    447          30               77                   33   \n",
              "35682    139         100              159                  104   \n",
              "35683    175         462              899                  396   \n",
              "35684     56          13               14                   16   \n",
              "35685     94          37               34                    3   \n",
              "\n",
              "       opponent_experience  \n",
              "0                      477  \n",
              "1                      477  \n",
              "2                      477  \n",
              "3                      505  \n",
              "4                      505  \n",
              "...                    ...  \n",
              "35681                   78  \n",
              "35682                  255  \n",
              "35683                  954  \n",
              "35684                   34  \n",
              "35685                   14  \n",
              "\n",
              "[35686 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a3e69da-8fe9-4266-8b17-c72981b9da53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>month</th>\n",
              "      <th>Score</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151.028046</td>\n",
              "      <td>221.846948</td>\n",
              "      <td>364</td>\n",
              "      <td>Test</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>605</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>116.145696</td>\n",
              "      <td>153.524269</td>\n",
              "      <td>364</td>\n",
              "      <td>Test</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>246</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>152.355429</td>\n",
              "      <td>364</td>\n",
              "      <td>Test</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>510</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>106.416181</td>\n",
              "      <td>364</td>\n",
              "      <td>Test</td>\n",
              "      <td>male</td>\n",
              "      <td>12</td>\n",
              "      <td>631</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>100.614929</td>\n",
              "      <td>364</td>\n",
              "      <td>Test</td>\n",
              "      <td>male</td>\n",
              "      <td>12</td>\n",
              "      <td>624</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35681</th>\n",
              "      <td>58.111437</td>\n",
              "      <td>30.926471</td>\n",
              "      <td>28</td>\n",
              "      <td>MDM</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>447</td>\n",
              "      <td>30</td>\n",
              "      <td>77</td>\n",
              "      <td>33</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35682</th>\n",
              "      <td>18.329607</td>\n",
              "      <td>117.884663</td>\n",
              "      <td>83</td>\n",
              "      <td>T20</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>139</td>\n",
              "      <td>100</td>\n",
              "      <td>159</td>\n",
              "      <td>104</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35683</th>\n",
              "      <td>117.964467</td>\n",
              "      <td>59.177502</td>\n",
              "      <td>440</td>\n",
              "      <td>ODI</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>175</td>\n",
              "      <td>462</td>\n",
              "      <td>899</td>\n",
              "      <td>396</td>\n",
              "      <td>954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35684</th>\n",
              "      <td>1.051244</td>\n",
              "      <td>11.080450</td>\n",
              "      <td>3</td>\n",
              "      <td>T20</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35685</th>\n",
              "      <td>8.834284</td>\n",
              "      <td>2.065272</td>\n",
              "      <td>16</td>\n",
              "      <td>T20</td>\n",
              "      <td>male</td>\n",
              "      <td>11</td>\n",
              "      <td>94</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35686 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3e69da-8fe9-4266-8b17-c72981b9da53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a3e69da-8fe9-4266-8b17-c72981b9da53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a3e69da-8fe9-4266-8b17-c72981b9da53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c59b294d-d486-4e5a-b75e-b32baf6653df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c59b294d-d486-4e5a-b75e-b32baf6653df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c59b294d-d486-4e5a-b75e-b32baf6653df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_530752e8-81f4-4a05-885d-50ec66d1efce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_530752e8-81f4-4a05-885d-50ec66d1efce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 35686,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.00151957238577,\n        \"min\": 0.0,\n        \"max\": 544.7364157800768,\n        \"num_unique_values\": 26751,\n        \"samples\": [\n          4.464577863439122,\n          17.964335437573876,\n          39.96826782529196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87.2436055375471,\n        \"min\": 0.0,\n        \"max\": 602.3700120746582,\n        \"num_unique_values\": 26729,\n        \"samples\": [\n          147.14934075342754,\n          30.481900521875897,\n          104.2117605087649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          37,\n          56,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Test\",\n          \"ODI\",\n          \"IT20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 841,\n        \"samples\": [\n          387,\n          785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206,\n        \"min\": 0,\n        \"max\": 705,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          176,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          405,\n          108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          19,\n          282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          57,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = data_win_p.drop(columns=['is_winner', 'Unnamed: 0','Team'])\n",
        "data #\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApMMpnB5zEoP"
      },
      "source": [
        "The data has been mapped, with categorical variables converted into numerical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RKYmTFAvfqtY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "487eb642-344e-433b-f000-4ad89c459694"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sum team mate  sum team opponent  number of wins  Type  Gender  month  \\\n",
              "0         151.028046         221.846948             364     0       0     11   \n",
              "1         116.145696         153.524269             364     0       0     11   \n",
              "2         112.889448         152.355429             364     0       0     11   \n",
              "3         112.889448         106.416181             364     0       0     12   \n",
              "4         112.889448         100.614929             364     0       0     12   \n",
              "...              ...                ...             ...   ...     ...    ...   \n",
              "35681      58.111437          30.926471              28     3       0     11   \n",
              "35682      18.329607         117.884663              83     2       0     11   \n",
              "35683     117.964467          59.177502             440     1       0     11   \n",
              "35684       1.051244          11.080450               3     2       0     11   \n",
              "35685       8.834284           2.065272              16     2       0     11   \n",
              "\n",
              "       Score  total_wins  team_experience  opponent_total_wins  \\\n",
              "0        605         705              582                  268   \n",
              "1        246         705              582                  268   \n",
              "2        510         705              582                  268   \n",
              "3        631         705              582                  249   \n",
              "4        624         705              582                  249   \n",
              "...      ...         ...              ...                  ...   \n",
              "35681    447          30               77                   33   \n",
              "35682    139         100              159                  104   \n",
              "35683    175         462              899                  396   \n",
              "35684     56          13               14                   16   \n",
              "35685     94          37               34                    3   \n",
              "\n",
              "       opponent_experience  \n",
              "0                      477  \n",
              "1                      477  \n",
              "2                      477  \n",
              "3                      505  \n",
              "4                      505  \n",
              "...                    ...  \n",
              "35681                   78  \n",
              "35682                  255  \n",
              "35683                  954  \n",
              "35684                   34  \n",
              "35685                   14  \n",
              "\n",
              "[35686 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3a7c3b4-fe7f-4250-9097-1590fee7f857\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>month</th>\n",
              "      <th>Score</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151.028046</td>\n",
              "      <td>221.846948</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>605</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>116.145696</td>\n",
              "      <td>153.524269</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>246</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>152.355429</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>510</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>106.416181</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>631</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>100.614929</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>624</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35681</th>\n",
              "      <td>58.111437</td>\n",
              "      <td>30.926471</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>447</td>\n",
              "      <td>30</td>\n",
              "      <td>77</td>\n",
              "      <td>33</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35682</th>\n",
              "      <td>18.329607</td>\n",
              "      <td>117.884663</td>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>139</td>\n",
              "      <td>100</td>\n",
              "      <td>159</td>\n",
              "      <td>104</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35683</th>\n",
              "      <td>117.964467</td>\n",
              "      <td>59.177502</td>\n",
              "      <td>440</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>175</td>\n",
              "      <td>462</td>\n",
              "      <td>899</td>\n",
              "      <td>396</td>\n",
              "      <td>954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35684</th>\n",
              "      <td>1.051244</td>\n",
              "      <td>11.080450</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35685</th>\n",
              "      <td>8.834284</td>\n",
              "      <td>2.065272</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>94</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35686 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3a7c3b4-fe7f-4250-9097-1590fee7f857')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3a7c3b4-fe7f-4250-9097-1590fee7f857 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3a7c3b4-fe7f-4250-9097-1590fee7f857');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac09f421-ca1d-4f4e-8256-52f94b40f302\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac09f421-ca1d-4f4e-8256-52f94b40f302')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac09f421-ca1d-4f4e-8256-52f94b40f302 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b75ba9e4-0125-4714-a450-e98fb76f00db\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b75ba9e4-0125-4714-a450-e98fb76f00db button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 35686,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.00151957238577,\n        \"min\": 0.0,\n        \"max\": 544.7364157800768,\n        \"num_unique_values\": 26751,\n        \"samples\": [\n          4.464577863439122,\n          17.964335437573876,\n          39.96826782529196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87.2436055375471,\n        \"min\": 0.0,\n        \"max\": 602.3700120746582,\n        \"num_unique_values\": 26729,\n        \"samples\": [\n          147.14934075342754,\n          30.481900521875897,\n          104.2117605087649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          37,\n          56,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 841,\n        \"samples\": [\n          387,\n          785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206,\n        \"min\": 0,\n        \"max\": 705,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          176,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          405,\n          108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          19,\n          282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          57,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type_map={type: i for i, type in enumerate(data['Type'].unique())}\n",
        "gender_map={gender:i for i,gender in enumerate(data['Gender'].unique())}\n",
        "\n",
        "data['Type']=data['Type'].map(type_map)\n",
        "data['Gender']=data['Gender'].map(gender_map)\n",
        "data_win_p['Type']=data_win_p['Type'].map(type_map)\n",
        "data_win_p['Gender']=data_win_p['Gender'].map(gender_map)\n",
        "data_win_p['is_winner']=data_win_p['is_winner'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gYOT09eji57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "36a2ef32-0b5a-4b86-d8cf-c05bef16fece"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     sum team mate  sum team opponent  number of wins  \\\n",
              "sum team mate             1.000000           0.684891        0.302300   \n",
              "sum team opponent         0.684891           1.000000        0.245995   \n",
              "number of wins            0.302300           0.245995        1.000000   \n",
              "Type                     -0.413741          -0.393195       -0.335123   \n",
              "Gender                   -0.292645          -0.311223        0.161918   \n",
              "month                    -0.117834          -0.119739        0.001414   \n",
              "Score                     0.201012           0.194396        0.128207   \n",
              "total_wins                0.540069           0.417460        0.766618   \n",
              "team_experience           0.270682           0.246303        0.976674   \n",
              "opponent_total_wins       0.222352           0.320865        0.819640   \n",
              "opponent_experience       0.220012           0.295153        0.852332   \n",
              "\n",
              "                         Type    Gender     month     Score  total_wins  \\\n",
              "sum team mate       -0.413741 -0.292645 -0.117834  0.201012    0.540069   \n",
              "sum team opponent   -0.393195 -0.311223 -0.119739  0.194396    0.417460   \n",
              "number of wins      -0.335123  0.161918  0.001414  0.128207    0.766618   \n",
              "Type                 1.000000  0.000648  0.058074 -0.076651   -0.486483   \n",
              "Gender               0.000648  1.000000  0.071117 -0.250694    0.048788   \n",
              "month                0.058074  0.071117  1.000000 -0.011609   -0.012576   \n",
              "Score               -0.076651 -0.250694 -0.011609  1.000000    0.235506   \n",
              "total_wins          -0.486483  0.048788 -0.012576  0.235506    1.000000   \n",
              "team_experience     -0.331916  0.158217  0.006711  0.138152    0.734807   \n",
              "opponent_total_wins -0.335123  0.161918  0.001414  0.101838    0.613411   \n",
              "opponent_experience -0.331916  0.158217  0.006711  0.119325    0.630730   \n",
              "\n",
              "                     team_experience  opponent_total_wins  opponent_experience  \n",
              "sum team mate               0.270682             0.222352             0.220012  \n",
              "sum team opponent           0.246303             0.320865             0.295153  \n",
              "number of wins              0.976674             0.819640             0.852332  \n",
              "Type                       -0.331916            -0.335123            -0.331916  \n",
              "Gender                      0.158217             0.161918             0.158217  \n",
              "month                       0.006711             0.001414             0.006711  \n",
              "Score                       0.138152             0.101838             0.119325  \n",
              "total_wins                  0.734807             0.613411             0.630730  \n",
              "team_experience             1.000000             0.852332             0.889891  \n",
              "opponent_total_wins         0.852332             1.000000             0.976674  \n",
              "opponent_experience         0.889891             0.976674             1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34521981-d189-48d5-b1c7-10a3477152c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>month</th>\n",
              "      <th>Score</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sum team mate</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.684891</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>-0.413741</td>\n",
              "      <td>-0.292645</td>\n",
              "      <td>-0.117834</td>\n",
              "      <td>0.201012</td>\n",
              "      <td>0.540069</td>\n",
              "      <td>0.270682</td>\n",
              "      <td>0.222352</td>\n",
              "      <td>0.220012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sum team opponent</th>\n",
              "      <td>0.684891</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.245995</td>\n",
              "      <td>-0.393195</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>-0.119739</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.417460</td>\n",
              "      <td>0.246303</td>\n",
              "      <td>0.320865</td>\n",
              "      <td>0.295153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number of wins</th>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.245995</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.335123</td>\n",
              "      <td>0.161918</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>0.128207</td>\n",
              "      <td>0.766618</td>\n",
              "      <td>0.976674</td>\n",
              "      <td>0.819640</td>\n",
              "      <td>0.852332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type</th>\n",
              "      <td>-0.413741</td>\n",
              "      <td>-0.393195</td>\n",
              "      <td>-0.335123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.058074</td>\n",
              "      <td>-0.076651</td>\n",
              "      <td>-0.486483</td>\n",
              "      <td>-0.331916</td>\n",
              "      <td>-0.335123</td>\n",
              "      <td>-0.331916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>-0.292645</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.161918</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071117</td>\n",
              "      <td>-0.250694</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>0.158217</td>\n",
              "      <td>0.161918</td>\n",
              "      <td>0.158217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>-0.117834</td>\n",
              "      <td>-0.119739</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>0.058074</td>\n",
              "      <td>0.071117</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.011609</td>\n",
              "      <td>-0.012576</td>\n",
              "      <td>0.006711</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>0.006711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Score</th>\n",
              "      <td>0.201012</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.128207</td>\n",
              "      <td>-0.076651</td>\n",
              "      <td>-0.250694</td>\n",
              "      <td>-0.011609</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.235506</td>\n",
              "      <td>0.138152</td>\n",
              "      <td>0.101838</td>\n",
              "      <td>0.119325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_wins</th>\n",
              "      <td>0.540069</td>\n",
              "      <td>0.417460</td>\n",
              "      <td>0.766618</td>\n",
              "      <td>-0.486483</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>-0.012576</td>\n",
              "      <td>0.235506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.734807</td>\n",
              "      <td>0.613411</td>\n",
              "      <td>0.630730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>team_experience</th>\n",
              "      <td>0.270682</td>\n",
              "      <td>0.246303</td>\n",
              "      <td>0.976674</td>\n",
              "      <td>-0.331916</td>\n",
              "      <td>0.158217</td>\n",
              "      <td>0.006711</td>\n",
              "      <td>0.138152</td>\n",
              "      <td>0.734807</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.852332</td>\n",
              "      <td>0.889891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <td>0.222352</td>\n",
              "      <td>0.320865</td>\n",
              "      <td>0.819640</td>\n",
              "      <td>-0.335123</td>\n",
              "      <td>0.161918</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>0.101838</td>\n",
              "      <td>0.613411</td>\n",
              "      <td>0.852332</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.976674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>opponent_experience</th>\n",
              "      <td>0.220012</td>\n",
              "      <td>0.295153</td>\n",
              "      <td>0.852332</td>\n",
              "      <td>-0.331916</td>\n",
              "      <td>0.158217</td>\n",
              "      <td>0.006711</td>\n",
              "      <td>0.119325</td>\n",
              "      <td>0.630730</td>\n",
              "      <td>0.889891</td>\n",
              "      <td>0.976674</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34521981-d189-48d5-b1c7-10a3477152c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34521981-d189-48d5-b1c7-10a3477152c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34521981-d189-48d5-b1c7-10a3477152c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-630bd9ef-40ca-4740-b7fd-a148fe24928a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-630bd9ef-40ca-4740-b7fd-a148fe24928a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-630bd9ef-40ca-4740-b7fd-a148fe24928a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41372799177643693,\n        \"min\": -0.4137414918152478,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.11783428536831686,\n          1.0,\n          0.22235243666284515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4065260365587625,\n        \"min\": -0.3931953126303506,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.11973897575411938,\n          0.6848905214972096,\n          0.3208646954889189\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45234710448667564,\n        \"min\": -0.3351234923427448,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.0014142159583717148,\n          0.30229952134163574,\n          0.8196404408663334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42077551371566757,\n        \"min\": -0.48648287592643547,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.058073515463976016,\n          -0.4137414918152478,\n          -0.33512349234274397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35785787233903876,\n        \"min\": -0.31122336201424733,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.07111686801801223,\n          -0.2926445494168295,\n          0.16191847385491515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3108133072091975,\n        \"min\": -0.11973897575411938,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          1.0,\n          -0.11783428536831686,\n          0.001414215958371635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31221471433800196,\n        \"min\": -0.2506944451964307,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.011608717322741989,\n          0.20101242315665646,\n          0.10183796003371247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42789937769990416,\n        \"min\": -0.48648287592643547,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -0.01257602938105388,\n          0.5400690741508921,\n          0.6134111717324853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45610328564660413,\n        \"min\": -0.33191612239034185,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.006710577328810263,\n          0.27068237864735745,\n          0.8523323192067656\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44623527586938,\n        \"min\": -0.33512349234274397,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.001414215958371635,\n          0.22235243666284515,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4522800774627163,\n        \"min\": -0.33191612239034296,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.006710577328810098,\n          0.22001166978958364,\n          0.9766736530479239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Mh3U0xzWeZ"
      },
      "source": [
        "Since the: month column has corelation less than 0.1 it is better to be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NRZ176CIUiX4"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['month'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPPvEolXzmOZ"
      },
      "source": [
        "data is normized to be ready for ml app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tJHchFW1lRMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4a03d343-94eb-4062-8fef-69c60884e820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sum team mate  sum team opponent  number of wins      Type    Gender  \\\n",
              "0           0.641238           1.389239        2.153023 -2.137727 -0.468189   \n",
              "1           0.249302           0.606103        2.153023 -2.137727 -0.468189   \n",
              "2           0.212715           0.592705        2.153023 -2.137727 -0.468189   \n",
              "3           0.212715           0.066135        2.153023 -2.137727 -0.468189   \n",
              "4           0.212715          -0.000361        2.153023 -2.137727 -0.468189   \n",
              "...              ...                ...             ...       ...       ...   \n",
              "35681      -0.402766          -0.799152       -0.503399  0.978654 -0.468189   \n",
              "35682      -0.849751           0.197590       -0.068568 -0.060140 -0.468189   \n",
              "35683       0.269738          -0.475330        2.753881 -1.098933 -0.468189   \n",
              "35684      -1.043890          -1.026634       -0.701049 -0.060140 -0.468189   \n",
              "35685      -0.956440          -1.129968       -0.598271 -0.060140 -0.468189   \n",
              "\n",
              "       total_wins  team_experience  opponent_total_wins  opponent_experience  \n",
              "0        2.443300         1.592254             1.394046             1.162349  \n",
              "1        2.443300         1.592254             1.394046             1.162349  \n",
              "2        2.443300         1.592254             1.394046             1.162349  \n",
              "3        2.443300         1.592254             1.243831             1.276991  \n",
              "4        2.443300         1.592254             1.243831             1.276991  \n",
              "...           ...              ...                  ...                  ...  \n",
              "35681   -0.823743        -0.475382            -0.463869            -0.471288  \n",
              "35682   -0.484938        -0.139647             0.097459             0.253408  \n",
              "35683    1.267165         2.890156             2.406016             3.115344  \n",
              "35684   -0.906024        -0.733325            -0.598271            -0.651438  \n",
              "35685   -0.789862        -0.651438            -0.701049            -0.733325  \n",
              "\n",
              "[35686 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98e6501f-45ae-4b74-8cb6-fb225b244094\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.641238</td>\n",
              "      <td>1.389239</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.249302</td>\n",
              "      <td>0.606103</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>0.592705</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>0.066135</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.243831</td>\n",
              "      <td>1.276991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>-0.000361</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.243831</td>\n",
              "      <td>1.276991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35681</th>\n",
              "      <td>-0.402766</td>\n",
              "      <td>-0.799152</td>\n",
              "      <td>-0.503399</td>\n",
              "      <td>0.978654</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.823743</td>\n",
              "      <td>-0.475382</td>\n",
              "      <td>-0.463869</td>\n",
              "      <td>-0.471288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35682</th>\n",
              "      <td>-0.849751</td>\n",
              "      <td>0.197590</td>\n",
              "      <td>-0.068568</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.484938</td>\n",
              "      <td>-0.139647</td>\n",
              "      <td>0.097459</td>\n",
              "      <td>0.253408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35683</th>\n",
              "      <td>0.269738</td>\n",
              "      <td>-0.475330</td>\n",
              "      <td>2.753881</td>\n",
              "      <td>-1.098933</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>1.267165</td>\n",
              "      <td>2.890156</td>\n",
              "      <td>2.406016</td>\n",
              "      <td>3.115344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35684</th>\n",
              "      <td>-1.043890</td>\n",
              "      <td>-1.026634</td>\n",
              "      <td>-0.701049</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.906024</td>\n",
              "      <td>-0.733325</td>\n",
              "      <td>-0.598271</td>\n",
              "      <td>-0.651438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35685</th>\n",
              "      <td>-0.956440</td>\n",
              "      <td>-1.129968</td>\n",
              "      <td>-0.598271</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.789862</td>\n",
              "      <td>-0.651438</td>\n",
              "      <td>-0.701049</td>\n",
              "      <td>-0.733325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35686 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98e6501f-45ae-4b74-8cb6-fb225b244094')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98e6501f-45ae-4b74-8cb6-fb225b244094 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98e6501f-45ae-4b74-8cb6-fb225b244094');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83f46b2e-b004-427d-893f-87b9a6bd0f93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83f46b2e-b004-427d-893f-87b9a6bd0f93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83f46b2e-b004-427d-893f-87b9a6bd0f93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6af39786-1c3b-4c3b-9c55-301a81633155\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6af39786-1c3b-4c3b-9c55-301a81633155 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 35686,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.000014011391266,\n        \"min\": -1.055701402422755,\n        \"max\": 5.0649137388961005,\n        \"num_unique_values\": 26388,\n        \"samples\": [\n          -0.931960649180483,\n          -0.7148686158366735,\n          -0.2924776250991563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912575,\n        \"min\": -1.1536412683494022,\n        \"max\": 5.7509157866354785,\n        \"num_unique_values\": 26400,\n        \"samples\": [\n          0.2648525991314305,\n          0.4588607040779317,\n          -1.0059535663478494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.00001401139128,\n        \"min\": -0.7247671164966706,\n        \"max\": 4.485298647086373,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          -0.432244456022357,\n          -0.28203011685987167,\n          -0.3927143667690714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113914018,\n        \"min\": -2.137726979845088,\n        \"max\": 3.056241061410925,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -2.137726979845088,\n          -1.0989333715938856,\n          3.056241061410925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912743,\n        \"min\": -0.46818858020543347,\n        \"max\": 2.135891481080586,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.135891481080586,\n          -0.46818858020543347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912943,\n        \"min\": -0.9689445959178532,\n        \"max\": 2.4433001283012623,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          -0.11709343072272659,\n          -0.8285827561982017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912295,\n        \"min\": -0.7906452615725718,\n        \"max\": 3.8236628314719816,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          0.8675577354842553,\n          -0.3484577956907512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912819,\n        \"min\": -0.7247671164966706,\n        \"max\": 4.485298647086373,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          -0.5745527773341852,\n          1.5047299173886381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912281,\n        \"min\": -0.7906452615725718,\n        \"max\": 3.8236628314719816,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          -0.5572685434682776,\n          -0.3402691389151619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X = data.drop(columns=['Score'])  # Features (all columns except 'Score')\n",
        "y = data['Score']  # Target variable\n",
        "\n",
        "x_kernel= X\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "z_scores = scaler.fit_transform(X)\n",
        "\n",
        "X = pd.DataFrame(z_scores, columns=X.columns)\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqsWrYPczupm"
      },
      "source": [
        "### Code Explanation\n",
        "\n",
        "#### Data Preparation\n",
        "1. **Feature and Target Separation**:\n",
        "   - The `data` DataFrame is split into:\n",
        "     - `X`: Features (all columns except `'Score'`).\n",
        "     - `y`: Target variable (`'Score'`).\n",
        "\n",
        "#### Train-Test Split\n",
        "2. **Splitting the Data**:\n",
        "   - The dataset is divided into training and testing sets using an 80-20 split:\n",
        "     - `X_train`, `y_train`: 80% of the data for training.\n",
        "     - `X_test`, `y_test`: 20% of the data for testing.\n",
        "\n",
        "3. **Select Subset for Hyperparameter Tuning**:\n",
        "   - From the training set (`X_train`, `y_train`), a smaller subset (5% of the original training data) is selected for hyperparameter tuning:\n",
        "     - `X_select`, `y_select`: 5% of the training data for tuning.\n",
        "     - `x_test_select`, `y_test_select`: Remaining 1% of the training data.\n",
        "     - `x_train_select`, `y_train_select`: Remaining 4% of the training data.\n",
        "\n",
        "#### Data Summary\n",
        "4. **Shape of the Splits**:\n",
        "   - The shapes of all splits are printed to confirm the sizes of the training, testing, and select datasets:\n",
        "     - `X_train` and `y_train`: Main training dataset.\n",
        "     - `X_test` and `y_test`: Main test dataset.\n",
        "     - `X_train_select` and `y_train_select`: Subset of the training data for tuning.\n",
        "     - `x_test_select` and `y_test_select`: Remaining training data for validation or other purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train_seen, X_test_unseen, y_train_seen, y_test_unseen = train_test_split(X, y, test_size=0.01, random_state=85) # 99% train for seen data, 1% test for unseen\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_seen,y_train_seen, test_size=0.2, random_state=99) # 80% train, 20% test\n",
        "X_select, _ , y_select, _ = train_test_split(X_train, y_train, test_size=0.95, random_state=42) # since we have a large scale data we get 5 of training data for selcting and tuning  (4 percent of whole data)\n",
        "\n",
        "# Select a subset for hyperparameter tuning\n",
        "X_train_select, x_test_select, y_train_select, y_test_select = train_test_split(X_select, y_select, test_size=0.2, random_state=42)\n",
        "\n",
        "# we can use X_train, X_test, y_train, and y_test for model training and evaluation\n",
        "print(f\"X_train_seen shape: {X_train_seen.shape}\")\n",
        "print(f\"y_tarin_seen shape: {y_train_seen.shape}\\n\")\n",
        "print(f\"x_test_unseen shape: {X_test_unseen.shape}\")\n",
        "print(f\"y_test_unseen shape: {y_test_unseen.shape}\\n\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\\n\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\\n\")\n",
        "print(f\"X_train_select shape: {X_train_select.shape}\")\n",
        "print(f\"y_tarin_select shape: {y_train_select.shape}\\n\")\n",
        "print(f\"x_test_select shape: {x_test_select.shape}\")\n",
        "print(f\"y_test_select shape: {y_test_select.shape}\\n\")\n",
        "\n",
        "print(f\"whole records of X ({X.shape[0]}) are X = X_test_unseen + X_train_seen = {X_test_unseen.shape[0]} + {X_train_seen.shape[0]} = {X_train_seen.shape[0] + X_test_unseen.shape[0]} = {X.shape[0]} \")\n",
        "print(f\"Whole records of Y ({y.shape[0]}) are Y = y_test_unseen + y_train_seen = {y_test_unseen.shape[0]} +  {y_train_seen.shape[0]} = {y_train_seen.shape[0] + y_test_unseen.shape[0]} = {y.shape[0]} \\n\")\n",
        "\n",
        "print(f\"whole records of X_train_seen ({X_train_seen.shape[0]}) are X_train_seen = X_train + X_test = {X_train.shape[0]} + {X_test.shape[0]} = {X_train.shape[0] + X_test.shape[0]} = {X_train_seen.shape[0]} \")\n",
        "print(f\"whole records of y_train_seen ({y_train_seen.shape[0]}) are y_train_seen = y_train + y_test = {y_train.shape[0]} + {y_test.shape[0]} = {y_train.shape[0] + y_test.shape[0]} = {y_train_seen.shape[0]} \\n\")"
      ],
      "metadata": {
        "id": "1QFHvsI6wOwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ff5738-7e33-4d82-9f30-1bafb99a3401"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seen shape: (35329, 9)\n",
            "y_tarin_seen shape: (35329,)\n",
            "\n",
            "x_test_unseen shape: (357, 9)\n",
            "y_test_unseen shape: (357,)\n",
            "\n",
            "X_train shape: (28263, 9)\n",
            "y_train shape: (28263,)\n",
            "\n",
            "X_test shape: (7066, 9)\n",
            "y_test shape: (7066,)\n",
            "\n",
            "X_train_select shape: (1130, 9)\n",
            "y_tarin_select shape: (1130,)\n",
            "\n",
            "x_test_select shape: (283, 9)\n",
            "y_test_select shape: (283,)\n",
            "\n",
            "whole records of X (35686) are X = X_test_unseen + X_train_seen = 357 + 35329 = 35686 = 35686 \n",
            "Whole records of Y (35686) are Y = y_test_unseen + y_train_seen = 357 +  35329 = 35686 = 35686 \n",
            "\n",
            "whole records of X_train_seen (35329) are X_train_seen = X_train + X_test = 28263 + 7066 = 35329 = 35329 \n",
            "whole records of y_train_seen (35329) are y_train_seen = y_train + y_test = 28263 + 7066 = 35329 = 35329 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets for kernel\n",
        "Xk_train_seen, Xk_test_unseen, yk_train_seen, yk_test_unseen = train_test_split(x_kernel, y, test_size=0.01, random_state=85) # 99% train for seen data, 1% test for unseen\n",
        "Xk_train, Xk_test, yk_train, yk_test = train_test_split(Xk_train_seen,yk_train_seen, test_size=0.2, random_state=99) # 80% train, 20% test\n",
        "Xk_select, _ , yk_select, _ = train_test_split(Xk_train, yk_train, test_size=0.95, random_state=42) # since we have a large scale data we get 5 of training data for selcting and tuning  (4 percent of whole data)\n",
        "\n",
        "# Select a subset for hyperparameter tuning\n",
        "Xk_train_select, xk_test_select, yk_train_select, yk_test_select = train_test_split(Xk_select, yk_select, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BeY9dzuBaKwN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Step 4: Define Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "K66xYZ47b2H1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51DEv2nn0ss0"
      },
      "source": [
        "### `evaluation_model` Function Explanation\n",
        "\n",
        "The `evaluation_model` function evaluates the performance of a regression model on both training and testing datasets. It calculates key metrics to assess predictive accuracy, generalization capability, and bias in predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Function Inputs**\n",
        "1. **`model`**: The machine learning model to evaluate (e.g., a regression model).\n",
        "2. **`x_train`, `x_test`**: Training and testing feature datasets.\n",
        "3. **`y_train`, `y_test`**: Training and testing target datasets.\n",
        "\n",
        "---\n",
        "\n",
        "### **Function Steps**\n",
        "\n",
        "#### 1. **Model Training**\n",
        "   - The model is trained on the training data (`x_train`, `y_train`) using the `.fit()` method.\n",
        "\n",
        "#### 2. **Predictions**\n",
        "   - Predictions are generated for both the training (`x_train`) and testing (`x_test`) datasets using the `.predict()` method.\n",
        "\n",
        "#### 3. **Evaluation Metrics**\n",
        "   The function computes the following metrics for both training and testing datasets:\n",
        "\n",
        "   - **R² Score**:\n",
        "     - Measures how well the model explains the variance in the target variable.\n",
        "     - Computed using `r2_score` for both datasets.\n",
        "\n",
        "   - **RMSE (Root Mean Squared Error)**:\n",
        "     - Quantifies the average magnitude of prediction errors.\n",
        "     - Computed using `mean_squared_error`.\n",
        "\n",
        "   - **MBD (Mean Bias Deviation)**:\n",
        "     - Captures the average bias (difference) between predictions and actual values.\n",
        "     - Indicates systematic over- or under-prediction.\n",
        "\n",
        "   - **Differences**:\n",
        "     - **R² Difference**: Absolute difference between training and testing R² scores.\n",
        "     - **RMSE Difference**: Absolute difference between training and testing RMSE values.\n",
        "     - **MBD Difference**: Absolute difference between training and testing MBD values.\n",
        "\n",
        "#### 4. **Custom Metric**\n",
        "   - A custom metric evaluates the model's balance between accuracy, overfitting, and underfitting. It is defined as:\n",
        "   $$\n",
        "   \\text{Custom Metric} = \\left(\\frac{\\text{R² (Test)}}{\\text{R² Difference}}\\right) \\times \\left(\\frac{1}{\\text{RMSE (Test)} \\cdot \\sqrt[4]{\\text{RMSE Difference}}}\\right) \\times \\left(\\frac{1}{|\\text{MBD (Test)}| \\cdot \\sqrt[4]{\\text{MBD Difference}}}\\right)\n",
        "   $$\n",
        "   - Penalizes models with large differences between training and testing performance while rewarding accurate predictions.\n",
        "\n",
        "#### 5. **Metrics Display**\n",
        "   - The computed metrics, including R², RMSE, MBD, and the custom metric, are printed for both testing and training datasets.\n",
        "\n",
        "#### 6. **Return Best Parameters**\n",
        "   - If the model is part of a grid search process, the best parameters are returned.\n",
        "\n",
        "---\n",
        "\n",
        "### **Function Outputs**\n",
        "- **Printed Metrics**:\n",
        "  - **R²**: Proportion of variance explained by the model.\n",
        "  - **RMSE**: Average magnitude of prediction errors.\n",
        "  - **MBD**: Average bias in predictions.\n",
        "  - **Custom Metric**: Balances accuracy, overfitting, and underfitting.\n",
        "- **Best Parameters** (if available): Optimal hyperparameters for the model.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example Output**\n",
        "```plaintext\n",
        "Test Metrics:\n",
        "R² (Test): 0.7352\n",
        "RMSE (Test): 72.2998\n",
        "MBD (Test): -1.1000\n",
        "Custom Metric: 0.5034\n",
        "\n",
        "Train Metrics:\n",
        "R² (Train): 0.8342\n",
        "RMSE (Train): 57.4626\n",
        "MBD (Train): -0.0086\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "EDx95jatigfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e2IehQQpneeR"
      },
      "outputs": [],
      "source": [
        "def evaluation_model(model, x_train, x_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "      model:\n",
        "      x_train:\n",
        "      x_test:\n",
        "      y_train:\n",
        "      y_test:\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    # Fit the model on training data\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Predictions for train and test sets\n",
        "    y_pre_test = model.predict(x_test)\n",
        "    y_pre_train = model.predict(x_train)\n",
        "\n",
        "    # R² Scores\n",
        "    r2_test = r2_score(y_test, y_pre_test)\n",
        "    r2_train = r2_score(y_train, y_pre_train)\n",
        "\n",
        "    # RMSE (Root Mean Squared Error)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pre_test))\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pre_train))\n",
        "\n",
        "    # MBD (Mean Bias Deviation)\n",
        "    mbd_test = np.mean(y_pre_test - y_test)\n",
        "    mbd_train = np.mean(y_pre_train - y_train)\n",
        "\n",
        "    # Differences\n",
        "    mbd_diff = abs(mbd_test - mbd_train)\n",
        "    r2_diff = abs(r2_test - r2_train)\n",
        "    rmse_diff = abs(rmse_test - rmse_train)\n",
        "\n",
        "    # Prevent division by zero for custom metric\n",
        "    if r2_diff == 0 or rmse_diff == 0 or mbd_diff == 0:\n",
        "        custom_metric = 'Error'\n",
        "    else:\n",
        "        custom_metric = (r2_test / r2_diff) * (1 / (rmse_test * np.power(rmse_diff, 1/4))) * (1 / (abs(mbd_test) * np.power(mbd_diff, 1/4)))\n",
        "\n",
        "    # Print Evaluation Metrics\n",
        "    print(\"Test Metrics:\")\n",
        "    print(f\"R² (Test): {r2_test:.4f}\")\n",
        "    print(f\"RMSE (Test): {rmse_test:.4f}\")\n",
        "    print(f\"MBD (Test): {mbd_test:.4f}\")\n",
        "    print(f\"Custom Metric: {custom_metric:.4f}\")\n",
        "\n",
        "    print(\"\\nTrain Metrics:\")\n",
        "    print(f\"R² (Train): {r2_train:.4f}\")\n",
        "    print(f\"RMSE (Train): {rmse_train:.4f}\")\n",
        "    print(f\"MBD (Train): {mbd_train:.4f}\")\n",
        "\n",
        "    # Return the best parameters if available (for grid search models)\n",
        "    try:\n",
        "        return model.best_params_\n",
        "    except AttributeError:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Regression Model Training"
      ],
      "metadata": {
        "id": "6SKmPLCBim2l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9on2RJsH3NMi"
      },
      "source": [
        "### Explanation of the Code: Decision Tree Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The objective of this code is to identify the best hyperparameters for a **DecisionTreeRegressor** by testing various combinations of maximum tree depth (`max_depth`) and the minimum number of samples required to split a node (`min_samples_split`). The optimal parameters are evaluated using the `evaluation_model` function.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "- A grid of hyperparameters is created for tuning:\n",
        "  - **`max_depth`**: Specifies how deep the tree can grow. Smaller depths (e.g., `3`) reduce the risk of overfitting but may lead to underfitting, while larger depths (e.g., `10`) increase the complexity of the model, potentially overfitting the data.\n",
        "  - **`min_samples_split`**: Defines the minimum number of samples required to split a node. Higher values prevent overfitting by limiting the growth of the tree.\n",
        "\n",
        "#### 2. **Set Up GridSearchCV**\n",
        "- **GridSearchCV** systematically tests all combinations of the hyperparameter grid:\n",
        "  - The **DecisionTreeRegressor** model is used as the base estimator.\n",
        "  - A 3-fold cross-validation strategy (`cv=3`) evaluates each parameter combination on multiple data splits.\n",
        "  - Parallel processing (`n_jobs=-1`) is used to speed up the search process by utilizing all available CPU cores.\n",
        "\n",
        "#### 3. **Evaluate Model Performance**\n",
        "- The `evaluation_model` function:\n",
        "  - Trains the model with the specified hyperparameter combinations.\n",
        "  - Computes evaluation metrics (R², RMSE, MBD) for both training and testing datasets.\n",
        "  - Calculates a **custom metric** to balance prediction accuracy, overfitting, and underfitting risks.\n",
        "\n",
        "#### 4. **Output the Best Parameters**\n",
        "- After completing the grid search, the best combination of `max_depth` and `min_samples_split` is selected based on performance metrics.\n",
        "- The selected parameters are displayed along with the evaluation metrics for the DecisionTreeRegressor.\n",
        "\n",
        "---\n",
        "\n",
        "### **Purpose of the Custom Metric**\n",
        "- The custom metric is designed to:\n",
        "  - Penalize models with large discrepancies between training and testing metrics (indicating overfitting or underfitting).\n",
        "  - Reward models with balanced performance and high predictive accuracy.\n",
        "  - Incorporate RMSE and MBD differences to capture both variance and bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUpSNEKWvrYp",
        "outputId": "46ceb876-b7c0-479c-8bf6-62438e26b6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7678\n",
            "RMSE (Test): 72.8262\n",
            "MBD (Test): 2.1821\n",
            "Custom Metric: 0.0571\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7167\n",
            "RMSE (Train): 76.2822\n",
            "MBD (Train): -0.0000\n",
            "Best Parameters for DecisionTreeRegressor: {'max_depth': 3, 'min_samples_split': 13}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid\n",
        "tree_params = {\n",
        "    'max_depth': [1, 3, 5, 7, 10, 13, None],  # Depth of the tree\n",
        "    'min_samples_split': [2, 5, 7, 10, 13]    # Minimum samples to split\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for DecisionTreeRegressor on the smaller tuning set\n",
        "tree_tune = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=tree_params,\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Save the best parameters to `best_params_three`\n",
        "best_params_three =  evaluation_model(tree_tune, X_train_select, x_test_select, y_train_select, y_test_select) # Evaluate the final model\n",
        "print(f\"Best Parameters for DecisionTreeRegressor: {best_params_three}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQDczaBE3aBi"
      },
      "source": [
        "### Explanation of RandomForestRegressor Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The objective of this process is to find the optimal hyperparameters for a **RandomForestRegressor** model by systematically exploring a grid of possible configurations. The final model is evaluated using the `evaluation_model` function, which calculates key metrics like R², RMSE, MBD, and a custom metric.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "- The following hyperparameters are tuned:\n",
        "  - **`n_estimators`**: The number of decision trees in the random forest. More trees generally improve performance but increase computational cost.\n",
        "  - **`max_depth`**: The maximum depth of each tree. A smaller depth reduces the risk of overfitting, while a larger depth allows the model to capture more complexity in the data.\n",
        "  - **`min_samples_split`**: The minimum number of samples required to split a node. Larger values prevent the tree from growing too complex.\n",
        "\n",
        "#### 2. **Set Up GridSearchCV**\n",
        "- **GridSearchCV** tests all combinations of hyperparameters in the specified grid:\n",
        "  - The **RandomForestRegressor** model is used as the estimator.\n",
        "  - A 3-fold cross-validation strategy (`cv=3`) ensures the model is evaluated on different data splits to assess its generalizability.\n",
        "  - Parallel processing (`n_jobs=-1`) speeds up the grid search by utilizing all available CPU cores.\n",
        "\n",
        "#### 3. **Evaluate Model Performance**\n",
        "- The `evaluation_model` function:\n",
        "  - Trains the model with each parameter combination on the training data.\n",
        "  - Computes evaluation metrics for both training and testing datasets:\n",
        "    - **R² (Coefficient of Determination)**: Measures how well the predictions fit the actual data.\n",
        "    - **RMSE (Root Mean Squared Error)**: Quantifies the average prediction error.\n",
        "    - **MBD (Mean Bias Deviation)**: Indicates systematic bias in predictions.\n",
        "    - **Custom Metric**: Balances overfitting, underfitting, and prediction accuracy.\n",
        "  - The model with the best combination of parameters is selected.\n",
        "\n",
        "#### 4. **Output the Best Parameters**\n",
        "- The best hyperparameter combination is saved and displayed:\n",
        "  - `max_depth`: Optimal depth for each decision tree.\n",
        "  - `min_samples_split`: Ideal minimum number of samples for splitting a node.\n",
        "  - `n_estimators`: Best number of trees in the forest.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwGkX9A8wfgC",
        "outputId": "084e868e-463c-43ca-d2b7-6eed925f574e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7733\n",
            "RMSE (Test): 71.9485\n",
            "MBD (Test): 1.7146\n",
            "Custom Metric: 0.0232\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.8794\n",
            "RMSE (Train): 49.7679\n",
            "MBD (Train): -0.1684\n",
            "Best Parameters for RandomForestRegressor: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid with an additional parameter\n",
        "rf_params = {\n",
        "    'n_estimators': [10,50, 100,200],         # Number of trees in the forest\n",
        "    'max_depth': [None, 10,50],           # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10]    # Minimum samples required to split an internal node\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for RandomForestRegressor on the tuning set\n",
        "rf_tune = GridSearchCV(\n",
        "    RandomForestRegressor(n_jobs=-1, random_state=42),  # Enable parallel processing\n",
        "    param_grid=rf_params,\n",
        "    cv=3,\n",
        "    scoring = 'r2'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Save the best parameters to `best_params_rf`\n",
        "best_params_rf = evaluation_model(rf_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters for RandomForestRegressor: {best_params_rf}\")\n",
        "\n",
        "# Evaluate the model using the tuning subset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcG_pY--7z8r"
      },
      "source": [
        "### Explanation of GradientBoostingRegressor Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The goal of this process is to optimize the hyperparameters for a **GradientBoostingRegressor** model to achieve the best predictive performance. The `evaluation_model` function is used to compute performance metrics, balancing overfitting and underfitting, and selecting the best configuration.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "- **`n_estimators`**: Number of boosting stages. Controls the complexity of the model by increasing the number of weak learners.\n",
        "- **`learning_rate`**: Shrinks the contribution of each weak learner. Lower values improve generalization but require more boosting stages.\n",
        "- **`max_depth`**: Maximum depth of individual decision trees. Controls the ability of the model to capture relationships in the data.\n",
        "\n",
        "#### 2. **Set Up GridSearchCV**\n",
        "- **GridSearchCV** is used to test all combinations of hyperparameters:\n",
        "  - The estimator is **GradientBoostingRegressor**, a powerful ensemble method.\n",
        "  - **2-fold cross-validation** (`cv=2`) ensures the model's generalization is evaluated.\n",
        "  - Parallel processing (`n_jobs=-1`) speeds up computations.\n",
        "\n",
        "#### 3. **Evaluate Model Performance**\n",
        "- The `evaluation_model` function:\n",
        "  - Fits the model on the training data for each parameter combination.\n",
        "  - Evaluates the model's performance using key metrics:\n",
        "    - **R² (Coefficient of Determination)**: Measures the proportion of variance explained by the model.\n",
        "    - **RMSE (Root Mean Squared Error)**: Indicates the average magnitude of prediction errors.\n",
        "    - **MBD (Mean Bias Deviation)**: Identifies systematic over- or under-predictions.\n",
        "    - **Custom Metric**: A composite measure balancing overfitting, underfitting, and prediction accuracy.\n",
        "  - Returns the best parameter combination.\n",
        "\n",
        "#### 4. **Output the Best Parameters**\n",
        "- The best combination of hyperparameters is determined based on the evaluation metrics:\n",
        "  - `learning_rate`: Optimal step size for boosting.\n",
        "  - `max_depth`: Maximum depth for individual decision trees.\n",
        "  - `n_estimators`: Ideal number of boosting stages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fg7MZTwycLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47ab8d0-41df-48f2-b162-c2d694724646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7147\n",
            "RMSE (Test): 80.7215\n",
            "MBD (Test): 2.4164\n",
            "Custom Metric: 0.0045\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.9582\n",
            "RMSE (Train): 29.3045\n",
            "MBD (Train): -0.0000\n",
            "Best Parameters for GradientBoostingRegressor: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid\n",
        "gbr_params = {\n",
        "    'n_estimators': [10, 50,100,200],          # Number of boosting stages\n",
        "    'learning_rate': [0.01, 0.1, 1],  # Learning rate\n",
        "    'max_depth': [None, 10]           # Maximum depth of individual estimators\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for GradientBoostingRegressor on the tuning set\n",
        "gbr_tune = GridSearchCV(\n",
        "    GradientBoostingRegressor(random_state=42),\n",
        "    param_grid=gbr_params,\n",
        "    cv=2,  # 2-fold cross-validation\n",
        "    n_jobs=-1,  # Parallel processing\n",
        "    scoring = 'r2'\n",
        ")\n",
        "\n",
        "\n",
        "# Save the best parameters dynamically as `best_params_gbr`\n",
        "best_params_gbr = evaluation_model(gbr_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters for GradientBoostingRegressor: {best_params_gbr}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wipWAaK8nDL"
      },
      "source": [
        "### Explanation of SVR Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The goal of this process is to optimize the hyperparameters of the **Support Vector Regressor (SVR)** to achieve optimal performance on both training and testing datasets. The `evaluation_model` function calculates performance metrics to assess model accuracy and generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "- **`C`**: Regularization parameter. Controls the trade-off between achieving a low error on training data and minimizing model complexity to improve generalization.\n",
        "- **`epsilon`**: Defines the epsilon-tube within which no penalty is given for predictions. Affects model sensitivity to small variations in the target variable.\n",
        "- **`gamma`**: Kernel coefficient. Determines how far-reaching the influence of a single training example is.\n",
        "- **`kernel`**: Specifies the kernel type used in the algorithm. Options:\n",
        "  - `linear`: A linear kernel.\n",
        "  - `rbf`: A radial basis function kernel.\n",
        "\n",
        "#### 2. **Set Up GridSearchCV**\n",
        "- **GridSearchCV** systematically tests combinations of hyperparameters:\n",
        "  - The estimator is **SVR (Support Vector Regressor)**.\n",
        "  - **2-fold cross-validation** (`cv=2`) ensures model evaluation on unseen data.\n",
        "  - Parallel processing (`n_jobs=-1`) speeds up computations.\n",
        "\n",
        "#### 3. **Evaluate Model Performance**\n",
        "- The `evaluation_model` function:\n",
        "  - Fits the model to the training dataset for each parameter combination.\n",
        "  - Evaluates performance using the following metrics:\n",
        "    - **R² (Coefficient of Determination)**: Indicates how well the model explains the variance in the data.\n",
        "    - **RMSE (Root Mean Squared Error)**: Measures the average magnitude of prediction errors.\n",
        "    - **MBD (Mean Bias Deviation)**: Highlights systematic over- or under-predictions.\n",
        "    - **Custom Metric**: Evaluates the balance between overfitting, underfitting, and predictive accuracy.\n",
        "  - Returns the best parameter combination based on these metrics.\n",
        "\n",
        "#### 4. **Output the Best Parameters**\n",
        "- The hyperparameter combination that produces the best results is selected:\n",
        "  - `C`: Controls model regularization.\n",
        "  - `epsilon`: Adjusts the model's tolerance for error.\n",
        "  - `gamma`: Sets the kernel's influence range.\n",
        "  - `kernel`: Defines the type of decision boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8ImC2XzOUp",
        "outputId": "c3c92a5d-7839-4944-b360-72693c46e2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7077\n",
            "RMSE (Test): 81.7081\n",
            "MBD (Test): 3.2296\n",
            "Custom Metric: 0.0024\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.9951\n",
            "RMSE (Train): 10.0449\n",
            "MBD (Train): 0.0000\n",
            "Best Parameters for SVR: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid\n",
        "SVR_params = {\n",
        "    'C': [0.5, 10],              # Regularization parameter\n",
        "    'epsilon': [0.1, 1],         # Epsilon-tube within which no penalty is associated\n",
        "    'gamma': ['scale'],          # Kernel coefficient\n",
        "    'kernel': ['linear', 'rbf']  # Kernel types\n",
        "}\n",
        "\n",
        "# Step 1: Perform GridSearchCV for tuning on the subset\n",
        "svr_tune = GridSearchCV(\n",
        "    SVR(),\n",
        "    param_grid=SVR_params,\n",
        "    cv=2,  # 2-fold cross-validation\n",
        "    n_jobs=-1  # Parallel processing\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Extract the best parameters from GridSearchCV\n",
        "best_params_svr = evaluation_model(gbr_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters for SVR: {best_params_svr}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gpA7ReD9H-j"
      },
      "source": [
        "### Explanation of XGBRegressor Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The objective is to optimize the hyperparameters of **XGBRegressor** to improve its performance for regression tasks. Using the `evaluation_model` function, the performance of the model is evaluated based on multiple metrics, including a custom metric designed to balance overfitting and underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "The hyperparameter grid specifies the values to test during the tuning process:\n",
        "- **`n_estimator`**: Number of boosting rounds (trees).\n",
        "- **`max_depth`**: Maximum depth of each tree, controlling model complexity.\n",
        "- **`learning_rate`**: Step size shrinkage to prevent overfitting.\n",
        "- **`subsample`**: Fraction of samples used for training each tree, controlling randomness and reducing overfitting.\n",
        "\n",
        "#### 2. **Set Up GridSearchCV**\n",
        "- **GridSearchCV** is used to systematically test different combinations of hyperparameters:\n",
        "  - The estimator is **XGBRegressor**.\n",
        "  - **2-fold cross-validation** ensures validation on unseen data for better generalization.\n",
        "  - Parallel processing (`n_jobs=-1`) is enabled to speed up computations.\n",
        "\n",
        "#### 3. **Model Evaluation with `evaluation_model`**\n",
        "The `evaluation_model` function:\n",
        "- Trains the model using each hyperparameter combination.\n",
        "- Evaluates performance on training and testing datasets with the following metrics:\n",
        "  - **R² (Coefficient of Determination)**: Measures the proportion of variance explained by the model.\n",
        "  - **RMSE (Root Mean Squared Error)**: Quantifies the average magnitude of prediction errors.\n",
        "  - **MBD (Mean Bias Deviation)**: Highlights systematic over- or under-predictions.\n",
        "  - **Custom Metric**: Penalizes models with large differences between training and testing performance while rewarding accuracy.\n",
        "\n",
        "#### 4. **Select Best Parameters**\n",
        "The best combination of hyperparameters is selected based on the results of the custom metric and overall model performance:\n",
        "- **`learning_rate`**: Step size for boosting iterations.\n",
        "- **`max_depth`**: Tree depth for controlling overfitting.\n",
        "- **`n_estimator`**: Number of boosting rounds.\n",
        "- **`subsample`**: Fraction of samples used for tree training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTMHhPjf0NKC",
        "outputId": "23eeb7c8-cff8-4cb5-a87a-0cbce39231ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7280\n",
            "RMSE (Test): 78.8100\n",
            "MBD (Test): 4.0198\n",
            "Custom Metric: 0.0021\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.9959\n",
            "RMSE (Train): 9.1409\n",
            "MBD (Train): -0.0093\n",
            "Best Parameters for XGBRegressor: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimator': 50, 'subsample': 1}\n"
          ]
        }
      ],
      "source": [
        "xgb_params={'n_estimator':[50,100],'max_depth':[5,10],'learning_rate':[0.01,0.5],'subsample':[0.5,1]}\n",
        "xgb_tune=GridSearchCV(XGBRegressor(),param_grid=xgb_params,cv=2)\n",
        "\n",
        "best_params=evaluation_model(xgb_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters for XGBRegressor: {best_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3jj-U0K9gZk"
      },
      "source": [
        "### BayesianRidge Hyperparameter Tuning with RandomizedSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "The goal is to optimize the hyperparameters of the **BayesianRidge** regression model. This model assumes a probabilistic approach and incorporates prior distributions over the model parameters, making it effective in handling multicollinearity and small datasets.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Define the Hyperparameter Grid**\n",
        "The hyperparameters for BayesianRidge are as follows:\n",
        "- **`alpha_1`** and **`alpha_2`**:\n",
        "  - Hyperpriors on the precision of the weights.\n",
        "  - Control the strength of the prior over the model parameters.\n",
        "- **`lambda_1`** and **`lambda_2`**:\n",
        "  - Hyperpriors on the precision of the noise.\n",
        "  - Influence the distribution of noise in the model.\n",
        "\n",
        "#### 2. **Use RandomizedSearchCV**\n",
        "- **Why RandomizedSearchCV?**\n",
        "  - Instead of testing all combinations, a random subset of parameter combinations is evaluated for faster results.\n",
        "- Key configurations:\n",
        "  - **`n_iter`**: Number of random parameter combinations to evaluate (set to 4).\n",
        "  - **`cv`**: Number of cross-validation folds (set to 2 to reduce computation time).\n",
        "  - **`n_jobs`**: Parallel processing to speed up the search.\n",
        "  - **`random_state`**: Ensures reproducibility.\n",
        "\n",
        "#### 3. **Evaluate the Model**\n",
        "The **`evaluation_model`** function:\n",
        "- Trains the model using each parameter combination.\n",
        "- Computes the following metrics:\n",
        "  - **R² (Coefficient of Determination)**: Measures how well the predictions fit the actual data.\n",
        "  - **RMSE (Root Mean Squared Error)**: Quantifies the average prediction error.\n",
        "  - **MBD (Mean Bias Deviation)**: Indicates systematic over- or under-prediction.\n",
        "  - **Custom Metric**: Balances accuracy and generalization while penalizing overfitting and underfitting.\n",
        "\n",
        "#### 4. **Extract Best Parameters**\n",
        "The best combination of hyperparameters is determined based on performance metrics, with the following optimal values:\n",
        "- **`alpha_1`**: 1e-6\n",
        "- **`alpha_2`**: 1e-6\n",
        "- **`lambda_1`**: 1e-6\n",
        "- **`lambda_2`**: 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfMbjTvs4ykA",
        "outputId": "e253f034-32aa-4deb-a519-1cc81427a448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.1388\n",
            "RMSE (Test): 140.2418\n",
            "MBD (Test): -5.9520\n",
            "Custom Metric: 0.0029\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.1601\n",
            "RMSE (Train): 131.3404\n",
            "MBD (Train): 0.0000\n",
            "Best Parameters for BayesianRidge: {'lambda_2': 1e-05, 'lambda_1': 1e-06, 'alpha_2': 1e-06, 'alpha_1': 1e-06}\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid for Bayesian Ridge\n",
        "bayesian_params = {\n",
        "    'alpha_1': [1e-6, 1e-5],  # Hyperprior on alpha\n",
        "    'alpha_2': [1e-6, 1e-5],  # Hyperprior on alpha\n",
        "    'lambda_1': [1e-6, 1e-5], # Hyperprior on lambda\n",
        "    'lambda_2': [1e-6, 1e-5]  # Hyperprior on lambda\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV for faster parameter tuning\n",
        "bayesian_model_tune = RandomizedSearchCV(\n",
        "    BayesianRidge(),\n",
        "    param_distributions=bayesian_params,\n",
        "    n_iter=4,  # Randomly test 4 parameter combinations\n",
        "    cv=2,  # Reduced cross-validation folds\n",
        "    n_jobs=-1,  # Parallel processing\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n",
        "\n",
        "# Extract and print the best parameters\n",
        "best_params_bayesian = evaluation_model(bayesian_model_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters for BayesianRidge: {best_params_bayesian}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSXLFeyc9t-S"
      },
      "source": [
        "### Polynomial Regression with Pipeline and GridSearchCV\n",
        "\n",
        "#### **Purpose**\n",
        "This script evaluates polynomial regression models of varying degrees to identify the optimal degree for minimizing prediction errors. It uses a pipeline to streamline preprocessing and model fitting, combined with GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Pipeline Definition**\n",
        "A pipeline is constructed with two steps:\n",
        "- **`PolynomialFeatures`**: Expands the feature set by including polynomial terms of the original features.\n",
        "- **`LinearRegression`**: Fits a linear regression model to the expanded feature set.\n",
        "\n",
        "#### 2. **Parameter Grid**\n",
        "The **`param_grid`** defines the range of polynomial degrees to evaluate:\n",
        "- **`poly__degree`**: Specifies the degrees (3, 5, and 8) to include in the GridSearchCV.\n",
        "\n",
        "#### 3. **GridSearchCV**\n",
        "- **Purpose**: Automatically evaluates polynomial models with different degrees and selects the degree that minimizes the mean squared error (MSE).\n",
        "- **Key Configurations**:\n",
        "  - **`scoring`**: Uses MSE (negative because GridSearchCV maximizes scores).\n",
        "  - **`cv`**: Employs 3-fold cross-validation to ensure robust model evaluation.\n",
        "  - **`n_jobs`**: Utilizes all available CPU cores for parallel processing.\n",
        "\n",
        "#### 4. **Fit the GridSearchCV**\n",
        "The grid search is performed on the training dataset (`X_train_select` and `y_train_select`). The pipeline ensures that polynomial feature generation and model fitting occur seamlessly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbLBmsxk55Lp",
        "outputId": "cb849072-a44a-4d50-b079-fa5b4e5174d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Polynomial Degree: 3\n",
            "Best CV MSE: 52253.4409\n",
            "Select Data Test MSE: 15033.5402\n"
          ]
        }
      ],
      "source": [
        "# Define a pipeline with PolynomialFeatures and LinearRegression\n",
        "pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures()),  # Step to generate polynomial features\n",
        "    ('linear', LinearRegression())   # Step to fit linear regression\n",
        "])\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'poly__degree': [3, 5, 8]  # Degrees to tune\n",
        "}\n",
        "\n",
        "# Use GridSearchCV for tuning\n",
        "grid = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=make_scorer(mean_squared_error, greater_is_better=False),  # Minimize MSE\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    n_jobs=-1  # Use all CPU cores\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV on the select training data\n",
        "grid.fit(X_train_select, y_train_select)\n",
        "\n",
        "# Print best degree and best score\n",
        "print(f\"Best Polynomial Degree: {grid.best_params_['poly__degree']}\")\n",
        "print(f\"Best CV MSE: {-grid.best_score_:.4f}\")  # Negate to show positive MSE\n",
        "\n",
        "# Evaluate the best model on select test data\n",
        "best_model = grid.best_estimator_\n",
        "y_test_pred = best_model.predict(x_test_select)\n",
        "test_mse = mean_squared_error(y_test_select, y_test_pred)\n",
        "print(f\"Select Data Test MSE: {test_mse:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzzBJjF4-XbZ"
      },
      "source": [
        "### K-Nearest Neighbors Regression with Hyperparameter Tuning\n",
        "\n",
        "#### **Purpose**\n",
        "This script evaluates and tunes the hyperparameters of the K-Nearest Neighbors (KNN) regressor. The goal is to find the optimal combination of the number of neighbors and weighting strategy to minimize prediction errors and maximize model performance.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Parameter Grid**\n",
        "The **`knn_params`** grid defines the hyperparameters to evaluate:\n",
        "- **`n_neighbors`**: Specifies the number of neighbors to consider for predictions (values: 3, 5, and 10).\n",
        "- **`weights`**: Defines the weighting strategy for predictions:\n",
        "  - **`uniform`**: All neighbors have equal weight.\n",
        "  - **`distance`**: Closer neighbors are assigned higher weights.\n",
        "\n",
        "#### 2. **GridSearchCV for Hyperparameter Tuning**\n",
        "- **Purpose**: Automates the evaluation of all combinations of `n_neighbors` and `weights` in the parameter grid.\n",
        "- **Key Configurations**:\n",
        "  - **`cv`**: Uses 3-fold cross-validation for robust evaluation.\n",
        "  - **`n_jobs`**: Utilizes all available CPU cores for parallel processing.\n",
        "\n",
        "#### 3. **Fit GridSearchCV**\n",
        "The grid search is performed on the training dataset (`X_train_select` and `y_train_select`) to identify the best parameter combination that minimizes prediction errors.\n",
        "\n",
        "#### 4. **Extract Best Parameters**\n",
        "- The best hyperparameters are extracted from the grid search results:\n",
        "  - **`best_params_knn`**: Contains the optimal combination of `n_neighbors` and `weights`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aN6n-B-6s7S",
        "outputId": "adbd1caf-ae44-4104-ddff-a6eea30c3943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.6031\n",
            "RMSE (Test): 95.2031\n",
            "MBD (Test): -6.3691\n",
            "Custom Metric: 0.0005\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 1.0000\n",
            "RMSE (Train): 0.0000\n",
            "MBD (Train): 0.0000\n",
            "Best Parameters: {'n_neighbors': 10, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "knn_params = {\n",
        "    'n_neighbors': [3, 5, 10],  # Number of neighbors\n",
        "    'weights': ['uniform', 'distance']  # Weighting strategy\n",
        "}\n",
        "\n",
        "# Step 1: Perform hyperparameter tuning on the select data\n",
        "knn_tune = GridSearchCV(\n",
        "    KNeighborsRegressor(),\n",
        "    param_grid=knn_params,\n",
        "    cv=3,  # Cross-validation folds\n",
        "    n_jobs=-1  # Enable parallel processing\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Extract the best parameters\n",
        "best_params_knn = evaluation_model(knn_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters: {best_params_knn}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NOZGyFk-mQj"
      },
      "source": [
        "### CatBoost Regression with Hyperparameter Tuning\n",
        "\n",
        "#### **Purpose**\n",
        "This script evaluates and tunes the hyperparameters of the CatBoost Regressor using GridSearchCV. The objective is to identify the best combination of parameters that maximize predictive performance on the target regression task.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps Explained**\n",
        "\n",
        "#### 1. **Parameter Grid**\n",
        "The **`catboost_params`** defines a comprehensive range of hyperparameters:\n",
        "- **`iterations`**: Number of boosting iterations to perform.\n",
        "- **`depth`**: Maximum depth of the decision trees.\n",
        "- **`learning_rate`**: Step size for the gradient boosting process.\n",
        "- **`l2_leaf_reg`**: L2 regularization term to reduce overfitting.\n",
        "- **`min_data_in_leaf`**: Minimum number of data samples required in a leaf.\n",
        "- **`bagging_temperature`**: Controls the Bayesian sampling process for bagging.\n",
        "\n",
        "#### 2. **GridSearchCV for Hyperparameter Tuning**\n",
        "- **Purpose**: Systematically evaluates all parameter combinations in the grid to identify the optimal set.\n",
        "- **Key Configurations**:\n",
        "  - **`cv`**: Uses 3-fold cross-validation for reliable performance estimation.\n",
        "  - **`scoring`**: Optimizes the model based on the R² score.\n",
        "  - **`n_jobs`**: Utilizes all CPU cores for faster computations.\n",
        "  - **`silent=True`**: Suppresses verbose logs from CatBoost.\n",
        "\n",
        "#### 3. **Fit the Model**\n",
        "The grid search is performed on the training dataset (`X_train_select` and `y_train_select`), testing various parameter combinations to minimize prediction errors.\n",
        "\n",
        "#### 4. **Extract Best Parameters**\n",
        "- **`best_params_catboost`**: Captures the optimal parameter set identified by GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-faFpYj6vVQ",
        "outputId": "9e19b1e2-eb1e-4f96-d205-aaeca9be3fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): 0.7841\n",
            "RMSE (Test): 70.2211\n",
            "MBD (Test): 2.1823\n",
            "Custom Metric: 0.3468\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7743\n",
            "RMSE (Train): 68.0910\n",
            "MBD (Train): -0.2155\n",
            "Best Parameters: {'bagging_temperature': 0.1, 'depth': 4, 'iterations': 100, 'l2_leaf_reg': 10, 'learning_rate': 0.1, 'min_data_in_leaf': 1}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define hyperparameter grid\n",
        "catboost_params = {\n",
        "    'iterations': [ 100, 200,300],  # Number of boosting iterations\n",
        "    'depth': [1, 4, 8],         # Depth of trees\n",
        "    'learning_rate': [0.05, 0.1, 1],  # Step size for boosting\n",
        "    'l2_leaf_reg': [3, 7,10],  # L2 regularization\n",
        "    'min_data_in_leaf': [1, 10, 50],  # Minimum number of data points in a leaf\n",
        "    'bagging_temperature': [0.1, 0.5, 1]  # Temperature for Bayesian sampling in bagging\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize GridSearchCV with CatBoostRegressor\n",
        "catboost_tune = GridSearchCV(\n",
        "    CatBoostRegressor(silent=True, random_state=42),  # Silent mode to avoid verbose logging\n",
        "    param_grid=catboost_params,\n",
        "    cv=3,  # Reduced cross-validation folds for efficiency\n",
        "    n_jobs=-1,  # Enable parallel processing\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "\n",
        "# Get the best parameters from tuning\n",
        "best_params_catboost = evaluation_model(catboost_tune, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "print(f\"Best Parameters: {best_params_catboost}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAbzOpJ4-y5y"
      },
      "source": [
        "### Gaussian Process Regressor with Custom Kernel\n",
        "\n",
        "This document outlines the process of configuring, training, and evaluating a **Gaussian Process Regressor (GPR)** using a custom kernel. The aim is to utilize Gaussian processes for regression tasks and assess the model's performance on a subset of the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Defining the Kernel**\n",
        "- A kernel function specifies the covariance structure between data points in Gaussian Processes:\n",
        "  - **`ConstantKernel (C)`**:\n",
        "    - Represents a constant component of the kernel, scaled by a hyperparameter.\n",
        "    - Allows the model to adjust the overall magnitude of predictions.\n",
        "    - The range for the constant is set between `1e-3` and `1e3` to provide flexibility.\n",
        "  - **`Radial Basis Function (RBF)`**:\n",
        "    - Captures smooth, non-linear relationships in the data.\n",
        "    - Includes a length scale parameter to control the influence of individual data points.\n",
        "    - The range for the length scale is also set between `1e-3` and `1e3`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Initializing the Gaussian Process Regressor**\n",
        "- The **GaussianProcessRegressor** is configured with the custom kernel:\n",
        "  - The kernel combines the constant and RBF components to model both global trends and local variations.\n",
        "  - **`n_restarts_optimizer=10`**:\n",
        "    - Refines the hyperparameters of the kernel by restarting the optimization process 10 times, improving model accuracy.\n",
        "  - **`random_state=42`**:\n",
        "    - Ensures reproducibility by fixing the random seed for stochastic processes.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Training the Model**\n",
        "- The GPR model is trained on a smaller subset of the training dataset:\n",
        "  - The subset (`X_train_select`, `y_train_select`) ensures computational efficiency while maintaining data representativeness.\n",
        "  - During training, the model learns the covariance structure of the data, enabling probabilistic predictions.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Model Evaluation**\n",
        "- The trained GPR model is evaluated on the subset of test data:\n",
        "  - Predictions are generated using the learned kernel and parameters.\n",
        "  - Evaluation metrics include:\n",
        "    - **R² (Coefficient of Determination)**:\n",
        "      - Measures the proportion of variance in the target variable explained by the model.\n",
        "    - **RMSE (Root Mean Squared Error)**:\n",
        "      - Represents the average magnitude of prediction errors.\n",
        "    - **MAPE (Mean Absolute Percentage Error)**:\n",
        "      - Indicates the percentage error in predictions relative to actual values.\n",
        "    - **MBD (Mean Bias Deviation)**:\n",
        "      - Captures the average bias in predictions, revealing tendencies to over- or underpredict.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Insights from Evaluation**\n",
        "- **Training Metrics**:\n",
        "  - High R² with low RMSE and MAPE indicates that the model effectively captures patterns in the training data.\n",
        "  - MBD close to zero reflects minimal prediction bias on the training set.\n",
        "- **Test Metrics**:\n",
        "  - Metrics comparable to the training subset suggest that the model generalizes well to unseen data.\n",
        "  - Significant differences between training and test metrics may indicate overfitting or underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Expected Outcomes**\n",
        "- **Custom Kernel**:\n",
        "  - Combines global trends (via `ConstantKernel`) with smooth, localized relationships (via `RBF`) to effectively model the data.\n",
        "- **Performance Metrics**:\n",
        "  - Comprehensive evaluation of the model’s predictive accuracy and generalization capabilities.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example Results**\n",
        "- **Training Metrics**:\n",
        "  - High R² with low RMSE and MAPE indicate good model accuracy.\n",
        "  - MBD near zero suggests unbiased predictions on the training subset.\n",
        "- **Test Metrics**:\n",
        "  - Comparable R², RMSE, and MAPE values confirm generalization to unseen data.\n",
        "  - MBD near zero highlights minimal bias in predictions on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "quWiIeIYbHFw",
        "outputId": "e84d88bd-4e65-4a7d-8711-24cab6539965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sum team mate  sum team opponent  number of wins  Type  Gender  \\\n",
              "0         151.028046         221.846948             364     0       0   \n",
              "1         116.145696         153.524269             364     0       0   \n",
              "2         112.889448         152.355429             364     0       0   \n",
              "3         112.889448         106.416181             364     0       0   \n",
              "4         112.889448         100.614929             364     0       0   \n",
              "...              ...                ...             ...   ...     ...   \n",
              "35681      58.111437          30.926471              28     3       0   \n",
              "35682      18.329607         117.884663              83     2       0   \n",
              "35683     117.964467          59.177502             440     1       0   \n",
              "35684       1.051244          11.080450               3     2       0   \n",
              "35685       8.834284           2.065272              16     2       0   \n",
              "\n",
              "       total_wins  team_experience  opponent_total_wins  opponent_experience  \n",
              "0             705              582                  268                  477  \n",
              "1             705              582                  268                  477  \n",
              "2             705              582                  268                  477  \n",
              "3             705              582                  249                  505  \n",
              "4             705              582                  249                  505  \n",
              "...           ...              ...                  ...                  ...  \n",
              "35681          30               77                   33                   78  \n",
              "35682         100              159                  104                  255  \n",
              "35683         462              899                  396                  954  \n",
              "35684          13               14                   16                   34  \n",
              "35685          37               34                    3                   14  \n",
              "\n",
              "[35686 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eceade66-17f0-4738-ae9a-cab60c01357e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151.028046</td>\n",
              "      <td>221.846948</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>116.145696</td>\n",
              "      <td>153.524269</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>152.355429</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>268</td>\n",
              "      <td>477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>106.416181</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>112.889448</td>\n",
              "      <td>100.614929</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>705</td>\n",
              "      <td>582</td>\n",
              "      <td>249</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35681</th>\n",
              "      <td>58.111437</td>\n",
              "      <td>30.926471</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>77</td>\n",
              "      <td>33</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35682</th>\n",
              "      <td>18.329607</td>\n",
              "      <td>117.884663</td>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>159</td>\n",
              "      <td>104</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35683</th>\n",
              "      <td>117.964467</td>\n",
              "      <td>59.177502</td>\n",
              "      <td>440</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>462</td>\n",
              "      <td>899</td>\n",
              "      <td>396</td>\n",
              "      <td>954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35684</th>\n",
              "      <td>1.051244</td>\n",
              "      <td>11.080450</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35685</th>\n",
              "      <td>8.834284</td>\n",
              "      <td>2.065272</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35686 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eceade66-17f0-4738-ae9a-cab60c01357e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eceade66-17f0-4738-ae9a-cab60c01357e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eceade66-17f0-4738-ae9a-cab60c01357e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3cf7e07-abcc-4930-a6c3-07f1fd3a5165\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3cf7e07-abcc-4930-a6c3-07f1fd3a5165')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3cf7e07-abcc-4930-a6c3-07f1fd3a5165 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8018a274-9874-4153-b7f9-6d67dcaee517\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x_kernel')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8018a274-9874-4153-b7f9-6d67dcaee517 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x_kernel');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_kernel",
              "summary": "{\n  \"name\": \"x_kernel\",\n  \"rows\": 35686,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.00151957238577,\n        \"min\": 0.0,\n        \"max\": 544.7364157800768,\n        \"num_unique_values\": 26751,\n        \"samples\": [\n          4.464577863439122,\n          17.964335437573876,\n          39.96826782529196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87.2436055375471,\n        \"min\": 0.0,\n        \"max\": 602.3700120746582,\n        \"num_unique_values\": 26729,\n        \"samples\": [\n          147.14934075342754,\n          30.481900521875897,\n          104.2117605087649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          37,\n          56,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 206,\n        \"min\": 0,\n        \"max\": 705,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          176,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          405,\n          108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 659,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          19,\n          282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 0,\n        \"max\": 1127,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          57,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n1Bu3wX_bUBA",
        "outputId": "fe445c4f-cb02-4215-fa42-5439b456e4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sum team mate  sum team opponent  number of wins      Type    Gender  \\\n",
              "0           0.641238           1.389239        2.153023 -2.137727 -0.468189   \n",
              "1           0.249302           0.606103        2.153023 -2.137727 -0.468189   \n",
              "2           0.212715           0.592705        2.153023 -2.137727 -0.468189   \n",
              "3           0.212715           0.066135        2.153023 -2.137727 -0.468189   \n",
              "4           0.212715          -0.000361        2.153023 -2.137727 -0.468189   \n",
              "...              ...                ...             ...       ...       ...   \n",
              "35681      -0.402766          -0.799152       -0.503399  0.978654 -0.468189   \n",
              "35682      -0.849751           0.197590       -0.068568 -0.060140 -0.468189   \n",
              "35683       0.269738          -0.475330        2.753881 -1.098933 -0.468189   \n",
              "35684      -1.043890          -1.026634       -0.701049 -0.060140 -0.468189   \n",
              "35685      -0.956440          -1.129968       -0.598271 -0.060140 -0.468189   \n",
              "\n",
              "       total_wins  team_experience  opponent_total_wins  opponent_experience  \n",
              "0        2.443300         1.592254             1.394046             1.162349  \n",
              "1        2.443300         1.592254             1.394046             1.162349  \n",
              "2        2.443300         1.592254             1.394046             1.162349  \n",
              "3        2.443300         1.592254             1.243831             1.276991  \n",
              "4        2.443300         1.592254             1.243831             1.276991  \n",
              "...           ...              ...                  ...                  ...  \n",
              "35681   -0.823743        -0.475382            -0.463869            -0.471288  \n",
              "35682   -0.484938        -0.139647             0.097459             0.253408  \n",
              "35683    1.267165         2.890156             2.406016             3.115344  \n",
              "35684   -0.906024        -0.733325            -0.598271            -0.651438  \n",
              "35685   -0.789862        -0.651438            -0.701049            -0.733325  \n",
              "\n",
              "[35686 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6657b88-9a9b-44f4-a6df-d203b32da89c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum team mate</th>\n",
              "      <th>sum team opponent</th>\n",
              "      <th>number of wins</th>\n",
              "      <th>Type</th>\n",
              "      <th>Gender</th>\n",
              "      <th>total_wins</th>\n",
              "      <th>team_experience</th>\n",
              "      <th>opponent_total_wins</th>\n",
              "      <th>opponent_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.641238</td>\n",
              "      <td>1.389239</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.249302</td>\n",
              "      <td>0.606103</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>0.592705</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.394046</td>\n",
              "      <td>1.162349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>0.066135</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.243831</td>\n",
              "      <td>1.276991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.212715</td>\n",
              "      <td>-0.000361</td>\n",
              "      <td>2.153023</td>\n",
              "      <td>-2.137727</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>2.443300</td>\n",
              "      <td>1.592254</td>\n",
              "      <td>1.243831</td>\n",
              "      <td>1.276991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35681</th>\n",
              "      <td>-0.402766</td>\n",
              "      <td>-0.799152</td>\n",
              "      <td>-0.503399</td>\n",
              "      <td>0.978654</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.823743</td>\n",
              "      <td>-0.475382</td>\n",
              "      <td>-0.463869</td>\n",
              "      <td>-0.471288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35682</th>\n",
              "      <td>-0.849751</td>\n",
              "      <td>0.197590</td>\n",
              "      <td>-0.068568</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.484938</td>\n",
              "      <td>-0.139647</td>\n",
              "      <td>0.097459</td>\n",
              "      <td>0.253408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35683</th>\n",
              "      <td>0.269738</td>\n",
              "      <td>-0.475330</td>\n",
              "      <td>2.753881</td>\n",
              "      <td>-1.098933</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>1.267165</td>\n",
              "      <td>2.890156</td>\n",
              "      <td>2.406016</td>\n",
              "      <td>3.115344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35684</th>\n",
              "      <td>-1.043890</td>\n",
              "      <td>-1.026634</td>\n",
              "      <td>-0.701049</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.906024</td>\n",
              "      <td>-0.733325</td>\n",
              "      <td>-0.598271</td>\n",
              "      <td>-0.651438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35685</th>\n",
              "      <td>-0.956440</td>\n",
              "      <td>-1.129968</td>\n",
              "      <td>-0.598271</td>\n",
              "      <td>-0.060140</td>\n",
              "      <td>-0.468189</td>\n",
              "      <td>-0.789862</td>\n",
              "      <td>-0.651438</td>\n",
              "      <td>-0.701049</td>\n",
              "      <td>-0.733325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35686 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6657b88-9a9b-44f4-a6df-d203b32da89c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6657b88-9a9b-44f4-a6df-d203b32da89c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6657b88-9a9b-44f4-a6df-d203b32da89c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ed18342-fcb3-4304-8b7c-d629a52d35d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ed18342-fcb3-4304-8b7c-d629a52d35d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ed18342-fcb3-4304-8b7c-d629a52d35d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8f4c5bf3-bb55-44eb-85e1-f78c6c56f59c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8f4c5bf3-bb55-44eb-85e1-f78c6c56f59c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 35686,\n  \"fields\": [\n    {\n      \"column\": \"sum team mate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.000014011391266,\n        \"min\": -1.055701402422755,\n        \"max\": 5.0649137388961005,\n        \"num_unique_values\": 26388,\n        \"samples\": [\n          -0.931960649180483,\n          -0.7148686158366735,\n          -0.2924776250991563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum team opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912575,\n        \"min\": -1.1536412683494022,\n        \"max\": 5.7509157866354785,\n        \"num_unique_values\": 26400,\n        \"samples\": [\n          0.2648525991314305,\n          0.4588607040779317,\n          -1.0059535663478494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number of wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.00001401139128,\n        \"min\": -0.7247671164966706,\n        \"max\": 4.485298647086373,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          -0.432244456022357,\n          -0.28203011685987167,\n          -0.3927143667690714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113914018,\n        \"min\": -2.137726979845088,\n        \"max\": 3.056241061410925,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -2.137726979845088,\n          -1.0989333715938856,\n          3.056241061410925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912743,\n        \"min\": -0.46818858020543347,\n        \"max\": 2.135891481080586,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.135891481080586,\n          -0.46818858020543347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912943,\n        \"min\": -0.9689445959178532,\n        \"max\": 2.4433001283012623,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          -0.11709343072272659,\n          -0.8285827561982017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912295,\n        \"min\": -0.7906452615725718,\n        \"max\": 3.8236628314719816,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          0.8675577354842553,\n          -0.3484577956907512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_total_wins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912819,\n        \"min\": -0.7247671164966706,\n        \"max\": 4.485298647086373,\n        \"num_unique_values\": 244,\n        \"samples\": [\n          -0.5745527773341852,\n          1.5047299173886381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000140113912281,\n        \"min\": -0.7906452615725718,\n        \"max\": 3.8236628314719816,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          -0.5572685434682776,\n          -0.3402691389151619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oVyA4Q-w6-QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a38d19-849a-4ccd-f8f6-288823d43be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "R² (Test): -1.6869\n",
            "RMSE (Test): 247.7085\n",
            "MBD (Test): -185.8448\n",
            "Custom Metric: -0.0000\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 1.0000\n",
            "RMSE (Train): 0.0000\n",
            "MBD (Train): -0.0000\n",
            "Best Parameters: Not applicable for GaussianProcessRegressor\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the kernel for Gaussian Process\n",
        "kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-3, 1e3))\n",
        "\n",
        "# Step 2: Initialize the GaussianProcessRegressor\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
        "\n",
        "\n",
        "# Step 4: Evaluate the model using select test data\n",
        "evaluation_model(gpr, Xk_train_select, xk_test_select, yk_train_select, yk_test_select)\n",
        "\n",
        "print(\"Best Parameters: Not applicable for GaussianProcessRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-zNqClH_Fyj"
      },
      "source": [
        "# Function: `evaluation_model2`\n",
        "\n",
        "## Overview\n",
        "The `evaluation_model2` function is designed to evaluate regression models using a custom metric that incorporates three key components:\n",
        "1. **R² (Coefficient of Determination)**: Measures how well the model explains the variance in the target data.\n",
        "2. **RMSE (Root Mean Squared Error)**: Captures the average magnitude of prediction errors.\n",
        "3. **MBD (Mean Bias Deviation)**: Quantifies systematic bias in the model's predictions.\n",
        "\n",
        "The custom metric combines these components using user-defined weights, allowing for flexibility in prioritizing different aspects of model performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Parameters\n",
        "- **`model`**: The regression model to be evaluated. Must implement `fit()` and `predict()` methods.\n",
        "- **`X_train`**: Features for training the model.\n",
        "- **`X_test`**: Features for testing the model.\n",
        "- **`y_train`**: Target values corresponding to `X_train`.\n",
        "- **`y_test`**: Target values corresponding to `X_test`.\n",
        "- **`weight_r2`** *(default=0.4)*: Weight assigned to the R² component in the custom metric.\n",
        "- **`weight_rmse`** *(default=0.4)*: Weight assigned to the RMSE component in the custom metric.\n",
        "- **`weight_mbd`** *(default=0.2)*: Weight assigned to the MBD component in the custom metric.\n",
        "\n",
        "---\n",
        "\n",
        "## Function Steps\n",
        "1. **Model Training**:\n",
        "   - The function fits the input model on the training data (`X_train`, `y_train`).\n",
        "\n",
        "2. **Generate Predictions**:\n",
        "   - Predictions are made for both the training and testing datasets.\n",
        "\n",
        "3. **Compute Metrics**:\n",
        "   - **R² (Train and Test)**:\n",
        "     - Evaluates the proportion of variance in the target explained by the model.\n",
        "   - **RMSE (Train and Test)**:\n",
        "     - Measures the average magnitude of the error.\n",
        "   - **MBD (Train and Test)**:\n",
        "     - Calculates the mean bias in predictions, using absolute deviation for robustness.\n",
        "\n",
        "4. **Custom Operations**:\n",
        "   - **Adjusted R² (`r_op`)**: Combines test and train R²:\n",
        "   $$\n",
        "   r_{\\text{op}} = \\frac{2 \\cdot R^2_{\\text{test}} - R^2_{\\text{train}}}{3}\n",
        "   $$\n",
        "   - **Adjusted RMSE (`rmse_op`)**: Combines test and train RMSE:\n",
        "   $$\n",
        "   \\text{RMSE}_{\\text{op}} = \\frac{2 \\cdot \\text{RMSE}_{\\text{test}} + \\text{RMSE}_{\\text{train}}}{3}\n",
        "   $$\n",
        "   - **Adjusted MBD (`mbd_op`)**: Combines test and train MBD:\n",
        "   $$\n",
        "   \\text{MBD}_{\\text{op}} = \\frac{2 \\cdot |\\text{MBD}_{\\text{test}}| + |\\text{MBD}_{\\text{train}}|}{3}\n",
        "   $$\n",
        "\n",
        "5. **Metric Differences**:\n",
        "   - Calculates the absolute differences between training and testing values for R², RMSE, and MBD:\n",
        "$$\n",
        "R^2_{\\text{diff}} = |R^2_{\\text{test}} - R^2_{\\text{train}}|\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{RMSE}_{\\text{diff}} = |\\text{RMSE}_{\\text{test}} - \\text{RMSE}_{\\text{train}}|\n",
        "$$\n",
        "\n",
        "$$\n",
        "     \\text{MBD}_{\\text{diff}} = |\\text{MBD}_{\\text{test}} - \\text{MBD}_{\\text{train}}|\n",
        "$$\n",
        "\n",
        "6. **Check for Invalid Combinations**:\n",
        "   - Returns `'error'` if any metric difference is zero, as division by zero would occur in the custom metric calculation.\n",
        "\n",
        "7. **Custom Metric Calculation**:\n",
        "   - Combines the weighted components into a single score:\n",
        "   $$\n",
        "   \\text{Custom Metric2} = \\frac{\\text{weight}_{R^2} \\cdot \\left(\\frac{r_{\\text{op}}}{(R^2_{\\text{diff}})^{1/4}}\\right)}{\\text{weight}_{\\text{RMSE}} \\cdot (\\text{RMSE}_{\\text{op}} \\cdot (\\text{RMSE}_{\\text{diff}})^{1/4}) \\cdot \\text{weight}_{\\text{MBD}} \\cdot (\\text{MBD}_{\\text{op}} \\cdot (\\text{MBD}_{\\text{diff}})^{1/4})}\n",
        "   $$\n",
        "\n",
        "8. **Exception Handling**:\n",
        "   - Returns an error message if model fitting or predictions fail due to any issue.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "- **Custom Metric (float)**: A weighted score representing the model's performance.\n",
        "- **Error (str)**: Returns `'error'` for invalid metric combinations (e.g., zero differences between train and test metrics).\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "1. **Adjustable Weights**:\n",
        "   - The function allows for customization of the importance of R², RMSE, and MBD in the final metric calculation.\n",
        "   \n",
        "2. **Bias-Variance Tradeoff**:\n",
        "   - Incorporates R² to capture variance and RMSE/MBD for error and bias, ensuring a comprehensive evaluation of the model.\n",
        "\n",
        "3. **Validation Check**:\n",
        "   - Identifies invalid configurations, ensuring robustness in metric calculation.\n",
        "\n",
        "---\n",
        "\n",
        "## Limitations\n",
        "1. **Sensitivity to Weights**:\n",
        "   - The results heavily depend on the chosen weights (`weight_r2`, `weight_rmse`, `weight_mbd`).\n",
        "2. **Zero Differences**:\n",
        "   - If any of the differences (e.g., $ R^2_{\\text{diff}} $) are zero, the function cannot compute the custom metric and returns `'error'`.\n",
        "\n",
        "---\n",
        "\n",
        "## Example Use Case\n",
        "### Scenario:\n",
        "You want to evaluate a regression model's performance using a balanced metric that prioritizes R² and RMSE equally, while assigning less importance to MBD. You use `evaluation_model2` with default weights to compute the custom metric for comparison. For me R2 and RMSE are eqully importent and more than MBD\n",
        "\n",
        "### Expected Output:\n",
        "The function returns a single custom score that combines the weighted contributions of R², RMSE, and MBD, helping us identify the best-performing model in your pipeline.this is best if we have many models but if we have few model first custom metric is better.\n",
        "\n",
        "---\n",
        "\n",
        "### Recommendations\n",
        "\n",
        "1. **Weight Tuning**:\n",
        "   - The weights assigned for evaluation were **0.4**, **0.4**, and **0.2** for **R²**, **RMSE**, and **MBD**, respectively.\n",
        "   - These weights reflect **my personal priorities**, emphasizing:\n",
        "     - **High importance on accuracy** (R²) and minimizing overall error (RMSE).\n",
        "     - **Lower priority on over-prediction or under-prediction bias** (MBD).\n",
        "   - These weights can and should be adjusted based on the specific needs of the client or project requirements. For me:\n",
        "     - Accuracy across variables and minimized errors are paramount.\n",
        "     - Bias (MBD) is less critical, which is why it was assigned a lower weight.\n",
        "   - This choice of weights is subjective and may vary for other users or use cases based on individual goals or client expectations.\n",
        "\n",
        "   \n",
        "2. **Debugging**:\n",
        "   - Use diagnostic outputs to identify invalid configurations causing metric errors.\n",
        "\n",
        "3. **Cross-Validation**:\n",
        "   - Incorporate cross-validation to ensure the computed metric generalizes well across different data splits.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluation_model2(model, X_train, X_test, y_train, y_test, weight_r2=0.4, weight_rmse=0.4, weight_mbd=0.2):\n",
        "    \"\"\"\n",
        "    Evaluate a model using custom metric with weighted R², RMSE, and MBD. The wights are based on pritizeing their importence you (who ever are reading this expet me :) ) can change.this can also difned based on clients needs since this is personal so its all on me\n",
        "    I want a model that have acuracy all along with diffent varibles and also less error for overall score difrence but over preidcting or undre prediction is less importent than those two\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fit the model on the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions for train and test data\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        # R² Scores\n",
        "        r2_test = r2_score(y_test, y_test_pred)\n",
        "        r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "        # RMSE (Root Mean Squared Error)\n",
        "        rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "        # MBD (Mean Bias Deviation) with Absolute Value\n",
        "        mbd_test = np.abs(np.mean(y_test_pred - y_test))\n",
        "        mbd_train = np.abs(np.mean(y_train_pred - y_train))\n",
        "\n",
        "        # Custom Operations\n",
        "        r_op = (2 * r2_test - r2_train) / 3\n",
        "        rmse_op = (2*rmse_test + rmse_train) / 3\n",
        "        mbd_op = (2* np.abs(mbd_test) + np.abs(mbd_train)) / 3\n",
        "\n",
        "        # Calculate differences between train and test metrics\n",
        "        r2_diff = abs(r2_test - r2_train)\n",
        "        rmse_diff = abs(rmse_test - rmse_train)\n",
        "        mbd_diff = abs(mbd_test - mbd_train)\n",
        "\n",
        "        # Avoid division by zero or invalid metrics\n",
        "        if r2_diff == 0 or rmse_diff == 0 or mbd_diff == 0:\n",
        "            return 'error' # Invalid combination\n",
        "\n",
        "        # Weighted Custom Metric\n",
        "        custom_metric = (weight_r2 * (r_op / np.power(r2_diff, 1 / 4))) /((weight_rmse * (rmse_op * np.power(rmse_diff, 1 / 4)))*(weight_mbd * (mbd_op * np.power(mbd_diff, 1 / 4))))\n",
        "\n",
        "        return custom_metric\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating model: {e}\")\n",
        "        return -np.inf\n"
      ],
      "metadata": {
        "id": "suA1TFO1x1lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking Model Selection and Evaluation\n",
        "\n",
        "## Overview\n",
        "This document describes a process for evaluating stacking regressors by combining different base models and experimenting with various configurations of final estimators. The goal is to identify the top-performing models using a custom evaluation metric.\n",
        "\n",
        "---\n",
        "\n",
        "## Components\n",
        "\n",
        "### Base Models\n",
        "The base models used in the stacking process include:\n",
        "- **Decision Tree Regressor**: A shallow decision tree with a limited depth.\n",
        "- **Random Forest Regressor**: An ensemble of decision trees trained with bagging.\n",
        "- **CatBoost Regressor**: A gradient boosting model optimized for handling categorical features.\n",
        "- **Gradient Boosting Regressor**: A traditional gradient boosting regressor.\n",
        "\n",
        "***note:the catboost is always included since it was best single model***\n",
        "\n",
        "---\n",
        "\n",
        "### Stacking Configuration\n",
        "The stacking regressor is configured with:\n",
        "\n",
        "#### Final Estimators\n",
        "These include:\n",
        "- **Ridge Regression**: Tested with regularization strengths $\\alpha \\in \\{0.01, 0.1, 1, 5\\} $.\n",
        "- **Lasso Regression**: Tested with regularization strengths $ \\alpha \\in \\{0.01, 0.1, 1, 5\\} $.\n",
        "- **Support Vector Regressor (SVR)**: Using a linear kernel and tested with regularization parameters $ C \\in \\{0.01, 0.1, 1, 5\\} $.\n",
        "\n",
        "#### Passthrough Option\n",
        "The passthrough setting determines whether the base model predictions are concatenated with the original features for the final estimator. Possible values:\n",
        "- **True**\n",
        "- **False**\n",
        "\n",
        "---\n",
        "\n",
        "## Dynamic Top Model Selection\n",
        "\n",
        "### Top `K` Models\n",
        "The script dynamically tracks the top `K` models, where:\n",
        "$$\n",
        "\\text{TOP_K} = \\left\\lfloor \\frac{\\text{Total Tests}}{10} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "### Metrics Stored\n",
        "- **Best Scores**: The top custom metric values.\n",
        "- **Best Combinations**: The combinations of base models.\n",
        "- **Best Models**: The stacking model configurations.\n",
        "- **Best Configurations**: The parameters of the final estimator and passthrough setting.\n",
        "\n",
        "---\n",
        "\n",
        "## Workflow\n",
        "\n",
        "### Base Model Combinations\n",
        "All combinations of the base models are evaluated, but only those that include **CatBoost** are considered valid for testing.\n",
        "\n",
        "### Stacking Regressor Configurations\n",
        "For each combination of base models, the script evaluates all configurations of:\n",
        "- Final estimators with their respective hyperparameters.\n",
        "- Passthrough options.\n",
        "\n",
        "### Evaluation Process\n",
        "Each stacking model is evaluated using a custom metric that combines:\n",
        "- **R² (Coefficient of Determination)**: To measure explained variance.\n",
        "- **RMSE (Root Mean Squared Error)**: To capture error magnitude.\n",
        "- **MBD (Mean Bias Deviation)**: To quantify systematic prediction bias.\n",
        "\n",
        "The custom metric incorporates these metrics with user-defined weights.\n",
        "\n",
        "---\n",
        "\n",
        "## Logging\n",
        "Each evaluation step is logged with the following details:\n",
        "- Combination of base models.\n",
        "- Parameters of the final estimator.\n",
        "- Passthrough setting.\n",
        "- The resulting custom metric score.\n",
        "\n",
        "### Example Log Output\n",
        "```plaintext\n",
        "106/192, 10/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n"
      ],
      "metadata": {
        "id": "-1h3-AMva2XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define potential base models\n",
        "base_models = {\n",
        "    'decision_tree': DecisionTreeRegressor(max_depth=3, min_samples_split=13),\n",
        "    'random_forest': RandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=200),\n",
        "    'catboost': CatBoostRegressor(bagging_temperature=0.1, depth=4, iterations=100, l2_leaf_reg=10,\n",
        "                                  learning_rate=0.1, min_data_in_leaf=1, silent=True),\n",
        "    'gradient_boosting': GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=200)\n",
        "}\n",
        "\n",
        "# Configuration for the stacking regressor with varied alpha values\n",
        "stacking_config = {\n",
        "    \"final_estimators\": [\n",
        "        Ridge(alpha=alpha) for alpha in [0.01, 0.1, 1, 5]\n",
        "    ] + [\n",
        "        Lasso(alpha=alpha) for alpha in [0.01, 0.1, 1, 5]\n",
        "    ] + [\n",
        "        SVR(kernel='linear', C=c) for c in [0.01, 0.1, 1, 5]\n",
        "    ],\n",
        "    \"passthrough_options\": [False, True]  # Toggle passthrough for experiments\n",
        "}\n",
        "\n",
        "# Initialize storage for the top k configurations\n",
        "\n",
        "\n",
        "num_final_estimators=24\n",
        "total_tests = num_final_estimators * np.power(2,  (len(base_models.items())-1))\n",
        "\n",
        "TOP_K = int(total_tests/10) +1\n",
        "\n",
        "best_scores = [-float('inf')] * TOP_K\n",
        "best_combinations = [None] * TOP_K\n",
        "best_models = [None] * TOP_K\n",
        "best_configs = [None] * TOP_K  # Store configurations\n",
        "\n",
        "\n",
        "z = 1  # Global counter for total configurations\n",
        "\n",
        "# Iterate through all combinations of base models\n",
        "for r in range(1, len(base_models) + 1):\n",
        "    for combo in combinations(base_models.items(), r):\n",
        "        # Check if 'catboost' is in the combination\n",
        "        if 'catboost' not in [name for name, _ in combo]:\n",
        "            continue  # Skip combinations without 'catboost'\n",
        "\n",
        "        # Define the estimators for the current combination\n",
        "        estimators = [(name, model) for name, model in combo]\n",
        "\n",
        "        d = 1  # Counter for stacking configurations per combination\n",
        "        # Experiment with different stacking configurations\n",
        "        for final_estimator in stacking_config[\"final_estimators\"]:\n",
        "            for passthrough in stacking_config[\"passthrough_options\"]:\n",
        "                # Create the stacking regressor\n",
        "                stack = StackingRegressor(\n",
        "                    estimators=estimators,\n",
        "                    final_estimator=final_estimator,\n",
        "                    n_jobs=-1,\n",
        "                    passthrough=passthrough\n",
        "                )\n",
        "\n",
        "                # Evaluate the stacked model\n",
        "                custom_metric = evaluation_model2(stack, X_train_select, x_test_select, y_train_select, y_test_select)\n",
        "                print(f\"{z}/{total_tests}, {d}/{num_final_estimators}: |{custom_metric:.2f}| <== {[name for name, _ in combo]}, \"\n",
        "                      f\"Final Estimator: {type(final_estimator).__name__}, Params: {final_estimator.get_params()}, Passthrough: {passthrough}\")\n",
        "                z += 1\n",
        "                d += 1\n",
        "\n",
        "                # Update the top k models dynamically\n",
        "                for i in range(TOP_K):\n",
        "                    if custom_metric > best_scores[i]:\n",
        "                        # Insert the new top score and associated data\n",
        "                        best_scores.insert(i, custom_metric)\n",
        "                        best_combinations.insert(i, estimators)\n",
        "                        best_models.insert(i, stack)\n",
        "                        best_configs.insert(i, {\n",
        "                            \"final_estimator\": type(final_estimator).__name__,\n",
        "                            \"params\": final_estimator.get_params(),\n",
        "                            \"passthrough\": passthrough\n",
        "                        })\n",
        "\n",
        "                        # Keep only the top k items\n",
        "                        best_scores = best_scores[:TOP_K]\n",
        "                        best_combinations = best_combinations[:TOP_K]\n",
        "                        best_models = best_models[:TOP_K]\n",
        "                        best_configs = best_configs[:TOP_K]\n",
        "                        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfasw3QBXCg_",
        "outputId": "d2bbaf74-36ef-4abb-b1e5-7857d30af7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/192, 1/24: |0.05| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "2/192, 2/24: |0.03| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "3/192, 3/24: |0.05| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "4/192, 4/24: |0.03| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "5/192, 5/24: |0.05| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "6/192, 6/24: |0.03| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "7/192, 7/24: |0.05| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "8/192, 8/24: |0.03| <== ['catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "9/192, 9/24: |0.05| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "10/192, 10/24: |0.03| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "11/192, 11/24: |0.05| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "12/192, 12/24: |0.03| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "13/192, 13/24: |0.05| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "14/192, 14/24: |0.03| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "15/192, 15/24: |0.05| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "16/192, 16/24: |0.05| <== ['catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "17/192, 17/24: |0.08| <== ['catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "18/192, 18/24: |0.06| <== ['catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "19/192, 19/24: |0.07| <== ['catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "20/192, 20/24: |0.06| <== ['catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "21/192, 21/24: |0.07| <== ['catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "22/192, 22/24: |0.06| <== ['catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "23/192, 23/24: |0.07| <== ['catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "24/192, 24/24: |0.05| <== ['catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "25/192, 1/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "26/192, 2/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "27/192, 3/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "28/192, 4/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "29/192, 5/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "30/192, 6/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "31/192, 7/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "32/192, 8/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "33/192, 9/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "34/192, 10/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "35/192, 11/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "36/192, 12/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "37/192, 13/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "38/192, 14/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "39/192, 15/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "40/192, 16/24: |0.03| <== ['decision_tree', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "41/192, 17/24: |0.01| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "42/192, 18/24: |0.01| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "43/192, 19/24: |0.02| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "44/192, 20/24: |0.01| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "45/192, 21/24: |0.02| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "46/192, 22/24: |0.01| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "47/192, 23/24: |0.01| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "48/192, 24/24: |0.02| <== ['decision_tree', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "49/192, 1/24: |0.05| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "50/192, 2/24: |0.03| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "51/192, 3/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "52/192, 4/24: |0.03| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "53/192, 5/24: |0.03| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "54/192, 6/24: |0.03| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "55/192, 7/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "56/192, 8/24: |0.07| <== ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "57/192, 9/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "58/192, 10/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "59/192, 11/24: |0.05| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "60/192, 12/24: |0.05| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "61/192, 13/24: |0.05| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "62/192, 14/24: |0.03| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "63/192, 15/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "64/192, 16/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "65/192, 17/24: |0.01| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "66/192, 18/24: |0.01| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "67/192, 19/24: |0.01| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "68/192, 20/24: |0.02| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "69/192, 21/24: |0.01| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "70/192, 22/24: |0.05| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "71/192, 23/24: |0.01| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "72/192, 24/24: |0.04| <== ['random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "73/192, 1/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "74/192, 2/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "75/192, 3/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "76/192, 4/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "77/192, 5/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "78/192, 6/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "79/192, 7/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "80/192, 8/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "81/192, 9/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "82/192, 10/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "83/192, 11/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "84/192, 12/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "85/192, 13/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "86/192, 14/24: |0.03| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "87/192, 15/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "88/192, 16/24: |0.04| <== ['catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "89/192, 17/24: |0.06| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "90/192, 18/24: |0.07| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "91/192, 19/24: |0.06| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "92/192, 20/24: |0.06| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "93/192, 21/24: |0.05| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "94/192, 22/24: |0.08| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "95/192, 23/24: |0.07| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "96/192, 24/24: |0.06| <== ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "97/192, 1/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "98/192, 2/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "99/192, 3/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "100/192, 4/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "101/192, 5/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "102/192, 6/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "103/192, 7/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "104/192, 8/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "105/192, 9/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "106/192, 10/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "107/192, 11/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "108/192, 12/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "109/192, 13/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "110/192, 14/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "111/192, 15/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "112/192, 16/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "113/192, 17/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "114/192, 18/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "115/192, 19/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "116/192, 20/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "117/192, 21/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "118/192, 22/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "119/192, 23/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "120/192, 24/24: |0.02| <== ['decision_tree', 'random_forest', 'catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "121/192, 1/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "122/192, 2/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "123/192, 3/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "124/192, 4/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "125/192, 5/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "126/192, 6/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "127/192, 7/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "128/192, 8/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "129/192, 9/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "130/192, 10/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "131/192, 11/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "132/192, 12/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "133/192, 13/24: |0.05| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "134/192, 14/24: |0.04| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "135/192, 15/24: |0.06| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "136/192, 16/24: |0.05| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "137/192, 17/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "138/192, 18/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "139/192, 19/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "140/192, 20/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "141/192, 21/24: |0.03| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "142/192, 22/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "143/192, 23/24: |0.02| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "144/192, 24/24: |0.01| <== ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "145/192, 1/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "146/192, 2/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "147/192, 3/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "148/192, 4/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "149/192, 5/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "150/192, 6/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "151/192, 7/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "152/192, 8/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "153/192, 9/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "154/192, 10/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "155/192, 11/24: |0.05| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "156/192, 12/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "157/192, 13/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "158/192, 14/24: |0.03| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "159/192, 15/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "160/192, 16/24: |0.05| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "161/192, 17/24: |0.01| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "162/192, 18/24: |0.07| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "163/192, 19/24: |0.06| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "164/192, 20/24: |0.06| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "165/192, 21/24: |0.01| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "166/192, 22/24: |0.01| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "167/192, 23/24: |0.04| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "168/192, 24/24: |0.05| <== ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "169/192, 1/24: |0.05| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "170/192, 2/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "171/192, 3/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "172/192, 4/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "173/192, 5/24: |0.05| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "174/192, 6/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "175/192, 7/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: False\n",
            "176/192, 8/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "177/192, 9/24: |0.07| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "178/192, 10/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "179/192, 11/24: |0.05| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "180/192, 12/24: |0.03| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "181/192, 13/24: |0.04| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "182/192, 14/24: |0.06| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "183/192, 15/24: |0.05| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "184/192, 16/24: |0.05| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "185/192, 17/24: |0.02| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "186/192, 18/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "187/192, 19/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "188/192, 20/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "189/192, 21/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "190/192, 22/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "191/192, 23/24: |0.01| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "192/192, 24/24: |0.02| <== ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Evaluate Regression Model"
      ],
      "metadata": {
        "id": "l9MT8U7pi3oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outputting the Top 5 Models and Their Configurations\n",
        "\n",
        "## Workflow\n",
        "\n",
        "### Steps:\n",
        "1. **Iterate Through Top Models**:\n",
        "   - Each of the top models is retrieved along with its score, combination of base models, configuration, and final stacking regressor.\n",
        "\n",
        "2. **Evaluation on Unseen Test Data**:\n",
        "   - Each model is evaluated using:\n",
        "     - `evaluation_model`: The primary evaluation metric.\n",
        "     - `evaluation_model2`: The custom metric incorporating R², RMSE, and MBD with specified weights.\n",
        "\n",
        "3. **Display Results**:\n",
        "   - Metrics such as R² (Test and Train), RMSE (Test and Train), MBD (Test and Train), and the custom metric are displayed for each model.\n",
        "\n",
        "---\n",
        "\n",
        "## Example Output\n",
        "\n",
        "### Top 20 Model\n",
        "**Model Combination**:  \n",
        "`['decision_tree', 'random_forest', 'catboost', 'gradient_boosting']`\n",
        "\n",
        "**Final Estimator**:  \n",
        "`Lasso`\n",
        "\n",
        "**Final Estimator Parameters**:  \n",
        "```plaintext\n",
        "Top 1 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
        "Test Metrics:\n",
        "R² (Test): 0.7951\n",
        "RMSE (Test): 63.3989\n",
        "MBD (Test): -1.6756\n",
        "Custom Metric: 0.3285\n",
        "\n",
        "Train Metrics:\n",
        "R² (Train): 0.7788\n",
        "RMSE (Train): 67.4039\n",
        "MBD (Train): -0.7186\n",
        "Metrics2 for Top 1 Model: 0.0308082568086704\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "\n",
        "## Overview\n",
        "This section presents the results for the top models identified during the evaluation process. Each model is described in terms of its configuration and performance metrics on unseen test data and training data.\n",
        "\n",
        "---\n",
        "\n",
        "## Model Details and Metrics\n",
        "###**example:**\n",
        "### **Top 20 Model Combination**\n",
        "- **Base Models**: `['catboost']`\n",
        "- **Final Estimator**: Support Vector Regressor (SVR)\n",
        "- **Estimator Parameters**:\n",
        "  - \\( C \\): 0.01\n",
        "  - Kernel: Linear\n",
        "  - Gamma: Scale\n",
        "  - Epsilon: 0.1\n",
        "  - Max Iterations: -1 (default)\n",
        "- **Passthrough Setting**: Enabled (`True`)\n",
        "\n",
        "#### Performance Metrics\n",
        "**Unseen Test Data**:\n",
        "- **R² (Test)**: \\( 0.7956 \\)\n",
        "- **RMSE (Test)**: \\( 63.3199 \\)\n",
        "- **MBD (Test)**: \\( -1.4400 \\)\n",
        "- **Custom Metric**: \\( 0.3802 \\)\n",
        "\n",
        "**Training Data**:\n",
        "- **R² (Train)**: \\( 0.7791 \\)\n",
        "- **RMSE (Train)**: \\( 67.3565 \\)\n",
        "- **MBD (Train)**: \\( -0.5098 \\)\n",
        "\n",
        "---\n",
        "\n",
        "## General Observations\n",
        "- **Similarity Among Top Models**: Across the top configurations, the metrics are relatively similar, reflecting consistent generalization. However, subtle differences in \\( R^2 \\), RMSE, and train-test alignment allow us to rank the models.\n",
        "  \n",
        "- **Criteria for Top Three Selection**:\n",
        "  1. Models with **RMSE less than 63** are prioritized, indicating smaller prediction errors.\n",
        "  2. Models with **minimal \\( R^2 \\) difference between training and testing** are preferred, suggesting reduced overfitting or underfitting.\n",
        "  3. Preference is given to configurations where training and testing performance are closely aligned, indicating better generalization.\n",
        "\n",
        "## Next Steps\n",
        "- Focus on the top three out of top 20 configurations models performence on unseen data,  that meet the above criteria for further refinement.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cSKOTO_Le0IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the top 5 models and their configurations\n",
        "for idx, (score, combination, model, config) in enumerate(zip(best_scores, best_combinations, best_models, best_configs)):\n",
        "    if combination is not None:\n",
        "        print(f\"Top {idx + 1} Model Combination: {[name for name, _ in combination]}, \"\n",
        "              f\"Final Estimator: {config['final_estimator']}, Params: {config['params']}, Passthrough: {config['passthrough']}\")\n",
        "        final_metrics = evaluation_model(model, X_train_select, X_test_unseen , y_train_select, y_test_unseen)\n",
        "        final_metrics2 = evaluation_model2(model, X_train_select, X_test_unseen , y_train_select, y_test_unseen)\n",
        "        print(f\"Metrics2 for Top {idx + 1} Model: {final_metrics2}\")\n",
        "        print('-----' * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMtPgp9ukJ2C",
        "outputId": "47ed1d0e-5ebe-4a6d-9d5e-948fb692324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7951\n",
            "RMSE (Test): 63.3989\n",
            "MBD (Test): -1.6756\n",
            "Custom Metric: 0.3285\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7788\n",
            "RMSE (Train): 67.4039\n",
            "MBD (Train): -0.7186\n",
            "Metrics2 for Top 1 Model: 0.0308082568086704\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 2 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7965\n",
            "RMSE (Test): 63.1737\n",
            "MBD (Test): -1.3142\n",
            "Custom Metric: 1.3492\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7880\n",
            "RMSE (Train): 65.9798\n",
            "MBD (Train): -1.1388\n",
            "Metrics2 for Top 2 Model: 0.059286059065271984\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 3 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7945\n",
            "RMSE (Test): 63.4914\n",
            "MBD (Test): -1.6962\n",
            "Custom Metric: 0.4823\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7830\n",
            "RMSE (Train): 66.7657\n",
            "MBD (Train): -0.7461\n",
            "Metrics2 for Top 3 Model: 0.037024899993849635\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 4 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7947\n",
            "RMSE (Test): 63.4607\n",
            "MBD (Test): -1.5688\n",
            "Custom Metric: 0.5617\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7837\n",
            "RMSE (Train): 66.6445\n",
            "MBD (Train): -0.6709\n",
            "Metrics2 for Top 4 Model: 0.03898523386929208\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 5 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7953\n",
            "RMSE (Test): 63.3608\n",
            "MBD (Test): -1.5942\n",
            "Custom Metric: 0.3405\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7789\n",
            "RMSE (Train): 67.3813\n",
            "MBD (Train): -0.6076\n",
            "Metrics2 for Top 5 Model: 0.032728118909671616\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 6 Model Combination: ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7992\n",
            "RMSE (Test): 62.7522\n",
            "MBD (Test): -0.8010\n",
            "Custom Metric: 2.5294\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7875\n",
            "RMSE (Train): 66.0640\n",
            "MBD (Train): -0.7761\n",
            "Metrics2 for Top 6 Model: 0.44676131504355615\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 7 Model Combination: ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.8014\n",
            "RMSE (Test): 62.4142\n",
            "MBD (Test): -1.0884\n",
            "Custom Metric: 0.1686\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7583\n",
            "RMSE (Train): 70.4580\n",
            "MBD (Train): -0.2247\n",
            "Metrics2 for Top 7 Model: 0.041590907471902853\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 8 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7953\n",
            "RMSE (Test): 63.3607\n",
            "MBD (Test): -1.5728\n",
            "Custom Metric: 0.3452\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7789\n",
            "RMSE (Train): 67.3814\n",
            "MBD (Train): -0.5865\n",
            "Metrics2 for Top 8 Model: 0.033289678633788955\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 9 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7953\n",
            "RMSE (Test): 63.3575\n",
            "MBD (Test): -1.5340\n",
            "Custom Metric: 0.3536\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7790\n",
            "RMSE (Train): 67.3797\n",
            "MBD (Train): -0.5458\n",
            "Metrics2 for Top 9 Model: 0.03435957120155778\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 10 Model Combination: ['random_forest', 'catboost'], Final Estimator: Ridge, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7986\n",
            "RMSE (Test): 62.8473\n",
            "MBD (Test): -0.6759\n",
            "Custom Metric: 1.8146\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7888\n",
            "RMSE (Train): 65.8641\n",
            "MBD (Train): -0.2690\n",
            "Metrics2 for Top 10 Model: 0.06269992538720548\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 11 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 5, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7962\n",
            "RMSE (Test): 63.2197\n",
            "MBD (Test): -1.3767\n",
            "Custom Metric: 3.2883\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7888\n",
            "RMSE (Train): 65.8592\n",
            "MBD (Train): -1.3842\n",
            "Metrics2 for Top 11 Model: 0.13192256137570763\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 12 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7956\n",
            "RMSE (Test): 63.3199\n",
            "MBD (Test): -1.4400\n",
            "Custom Metric: 0.3802\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7791\n",
            "RMSE (Train): 67.3565\n",
            "MBD (Train): -0.5098\n",
            "Metrics2 for Top 12 Model: 0.03713510184645142\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 13 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.01, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7943\n",
            "RMSE (Test): 63.5222\n",
            "MBD (Test): -1.6555\n",
            "Custom Metric: 0.7120\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7860\n",
            "RMSE (Train): 66.2975\n",
            "MBD (Train): -0.6863\n",
            "Metrics2 for Top 13 Model: 0.04028727479657075\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 14 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7944\n",
            "RMSE (Test): 63.5039\n",
            "MBD (Test): -1.6586\n",
            "Custom Metric: 0.6731\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7857\n",
            "RMSE (Train): 66.3406\n",
            "MBD (Train): -0.6802\n",
            "Metrics2 for Top 14 Model: 0.039766678571984224\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 15 Model Combination: ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.8021\n",
            "RMSE (Test): 62.3079\n",
            "MBD (Test): -0.9490\n",
            "Custom Metric: 0.2248\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7633\n",
            "RMSE (Train): 69.7215\n",
            "MBD (Train): -0.1561\n",
            "Metrics2 for Top 15 Model: 0.05769960815531011\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 16 Model Combination: ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7979\n",
            "RMSE (Test): 62.9548\n",
            "MBD (Test): -0.4924\n",
            "Custom Metric: 8.9067\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.8016\n",
            "RMSE (Train): 63.8286\n",
            "MBD (Train): -0.9188\n",
            "Metrics2 for Top 16 Model: 0.10174880970099386\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 17 Model Combination: ['catboost'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7962\n",
            "RMSE (Test): 63.2320\n",
            "MBD (Test): -1.3295\n",
            "Custom Metric: 0.4773\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7794\n",
            "RMSE (Train): 67.3168\n",
            "MBD (Train): -0.8521\n",
            "Metrics2 for Top 17 Model: 0.04213181197689993\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 18 Model Combination: ['random_forest', 'catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.7992\n",
            "RMSE (Test): 62.7624\n",
            "MBD (Test): -0.1052\n",
            "Custom Metric: 14.7159\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7894\n",
            "RMSE (Train): 65.7657\n",
            "MBD (Train): 0.0631\n",
            "Metrics2 for Top 18 Model: 0.3430159708182069\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 19 Model Combination: ['decision_tree', 'catboost', 'gradient_boosting'], Final Estimator: Lasso, Params: {'alpha': 5, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}, Passthrough: False\n",
            "Test Metrics:\n",
            "R² (Test): 0.8004\n",
            "RMSE (Test): 62.5702\n",
            "MBD (Test): -1.1854\n",
            "Custom Metric: 0.1580\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7592\n",
            "RMSE (Train): 70.3196\n",
            "MBD (Train): -0.2073\n",
            "Metrics2 for Top 19 Model: 0.033256181679121664\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Top 20 Model Combination: ['catboost', 'gradient_boosting'], Final Estimator: SVR, Params: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}, Passthrough: True\n",
            "Test Metrics:\n",
            "R² (Test): 0.7961\n",
            "RMSE (Test): 63.2374\n",
            "MBD (Test): -1.2818\n",
            "Custom Metric: 0.8195\n",
            "\n",
            "Train Metrics:\n",
            "R² (Train): 0.7857\n",
            "RMSE (Train): 66.3446\n",
            "MBD (Train): -0.7207\n",
            "Metrics2 for Top 20 Model: 0.051714565047007395\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Top 20 Model Combinations\n",
        "\n",
        "## Overview\n",
        "This section presents the performance of the top 20 stacking models evaluated using RMSE, \\(R^2\\), and MBD metrics for both training and testing datasets. The models are ranked based on their performance on the test set.\n",
        "\n",
        "---\n",
        "\n",
        "## Results Summary\n",
        "\n",
        "| **Rank** | **Model Combination**                        | **Final Estimator**         | **Passthrough** | **Train \\(R^2\\)** | **Train RMSE** | **Train MBD** | **Test \\(R^2\\)** | **Test RMSE** | **Test MBD** |\n",
        "|----------|----------------------------------------------|-----------------------------|------------------|-------------------|----------------|---------------|------------------|---------------|--------------|\n",
        "| **1**    | ['catboost']                                 | SVR (\\(C=0.01\\))            | False           | 0.7788            | 67.4039        | -0.7186       | 0.7951           | 63.3989       | -1.6756      |\n",
        "| **2**    | ['catboost', 'gradient_boosting']            | SVR (\\(C=1\\))               | True            | 0.7880            | 65.9798        | -1.1388       | 0.7965           | 63.1737       | -1.3142      |\n",
        "| **3**    | ['catboost', 'gradient_boosting']            | SVR (\\(C=5\\))               | False           | 0.7830            | 66.7657        | -0.7461       | 0.7945           | 63.4914       | -1.6962      |\n",
        "| **4**    | ['catboost', 'gradient_boosting']            | SVR (\\(C=0.01\\))            | True            | 0.7837            | 66.6445        | -0.6709       | 0.7947           | 63.4607       | -1.5688      |\n",
        "| **5**    | ['catboost']                                 | SVR (\\(C=0.1\\))             | False           | 0.7789            | 67.3813        | -0.6076       | 0.7953           | 63.3608       | -1.5942      |\n",
        "| **6**    | ['random_forest', 'catboost', 'gradient_boosting'] | SVR (\\(C=0.01\\))            | True            | 0.7875            | 66.0640        | -0.7761       | 0.7992           | 62.7522       | -0.8010      |\n",
        "| **7**    | ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'] | Lasso (\\(\\alpha=0.01\\))      | False           | 0.7583            | 70.4580        | -0.2247       | 0.8014           | 62.4142       | -1.0884      |\n",
        "| **8**    | ['catboost']                                 | SVR (\\(C=1\\))               | False           | 0.7789            | 67.3814        | -0.5865       | 0.7953           | 63.3607       | -1.5728      |\n",
        "| **9**    | ['catboost']                                 | SVR (\\(C=5\\))               | False           | 0.7790            | 67.3797        | -0.5458       | 0.7953           | 63.3575       | -1.5340      |\n",
        "| **10**   | ['random_forest', 'catboost']                | Ridge (\\(\\alpha=5\\))        | True            | 0.7888            | 65.8641        | -0.2690       | 0.7986           | 62.8473       | -0.6759      |\n",
        "| **11**   | ['catboost', 'gradient_boosting']            | SVR (\\(C=5\\))               | True            | 0.7888            | 65.8592        | -1.3842       | 0.7962           | 63.2197       | -1.3767      |\n",
        "| **12**   | ['catboost']                                 | SVR (\\(C=0.01\\))            | True            | 0.7791            | 67.3565        | -0.5098       | 0.7956           | 63.3199       | -1.4400      |\n",
        "| **13**   | ['catboost', 'gradient_boosting']            | SVR (\\(C=0.01\\))            | False           | 0.7860            | 66.2975        | -0.6863       | 0.7943           | 63.5222       | -1.6555      |\n",
        "| **14**   | ['catboost', 'gradient_boosting']            | SVR (\\(C=0.1\\))             | False           | 0.7857            | 66.3406        | -0.6802       | 0.7944           | 63.5039       | -1.6586      |\n",
        "| **15**   | ['decision_tree', 'random_forest', 'catboost', 'gradient_boosting'] | Lasso (\\(\\alpha=1\\))         | True            | 0.7633            | 69.7215        | -0.1561       | 0.8021           | 62.3079       | -0.9490      |\n",
        "| **16**   | ['random_forest', 'catboost', 'gradient_boosting'] | SVR (\\(C=0.1\\))             | True            | 0.8016            | 63.8286        | -0.9188       | 0.7979           | 62.9548       | -0.4924      |\n",
        "| **17**   | ['catboost']                                 | SVR (\\(C=0.1\\))             | True            | 0.7794            | 67.3168        | -0.8521       | 0.7962           | 63.2320       | -1.3295      |\n",
        "| **18**   | ['random_forest', 'catboost', 'gradient_boosting'] | SVR (\\(C=0.1\\))             | False           | 0.7894            | 65.7657        | 0.0631        | 0.7992           | 62.7624       | -0.1052      |\n",
        "| **19**   | ['decision_tree', 'catboost', 'gradient_boosting'] | Lasso (\\(\\alpha=5\\))        | False           | 0.7592            | 70.3196        | -0.2073       | 0.8004           | 62.5702       | -1.1854      |\n",
        "| **20**   | ['catboost', 'gradient_boosting']            | SVR (\\(C=0.1\\))             | True            | 0.7857            | 66.3446        | -0.7207       | 0.7961           | 63.2374       | -1.2818      |\n",
        "\n",
        "---\n",
        "\n",
        "## Observations\n",
        "1. **Top Models**:\n",
        "   - The **top-performing models** are dominated by combinations involving **CatBoost** and **SVR** as the final estimator.\n",
        "   - Model combinations with lower test RMSE and smaller \\(R^2\\) differences indicate less overfitting.\n",
        "\n",
        "2. **Rank 1 Model**:\n",
        "   - **CatBoost + SVR (\\(C=0.01\\))** with no passthrough stands out with a **test RMSE of 63.3989** and **test \\(R^2\\) of 0.7951**.\n",
        "\n",
        "3. **Combination Insights**:\n",
        "   - Including **Gradient Boosting** as an additional base model improves the overall \\(R^2\\) for several models.\n",
        "   - Models using **Ridge** or **Lasso** as the final estimator demonstrate slightly lower \\(R^2\\) but maintain competitive test RMSE.\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "1. **Retrain and Validate**:\n",
        "   - Retrain the top-ranked models using the entire dataset and validate on unseen data.\n",
        "2. **Deployment**:\n",
        "   - Choose the best-performing model based on generalization to unseen data and deploy for real-world usage.\n"
      ],
      "metadata": {
        "id": "6zvjL8qdjV4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logic and Process Explanation\n",
        "\n",
        "## Overview\n",
        "This script evaluates three pre-selected top models (`Model 18`, `Model 6`, and `Model 10`) using a systematic approach. Metrics are computed for training, testing, and unseen datasets, as well as through cross-validation. The final goal is to identify the model that generalizes best on unseen data while minimizing bias.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps and Logic\n",
        "\n",
        "### 1. **Top Models Definition**\n",
        "- **Top Models**: Pre-defined configurations that specify:\n",
        "  - A **combination of base regressors** (e.g., Random Forest, CatBoost, Gradient Boosting).\n",
        "  - A **final estimator** (e.g., SVR, Ridge Regression) that aggregates base model predictions.\n",
        "  - A **passthrough option** indicating whether original features are included along with predictions from base models.\n",
        "\n",
        "#### Example Models:\n",
        "- **Model 18**:\n",
        "  - Base Models: Random Forest, CatBoost, Gradient Boosting.\n",
        "  - Final Estimator: Support Vector Regressor (\\(C = 0.1\\), linear kernel).\n",
        "  - Passthrough: Disabled.\n",
        "- **Model 6**:\n",
        "  - Base Models: Random Forest, CatBoost, Gradient Boosting.\n",
        "  - Final Estimator: Support Vector Regressor (\\(C = 0.01\\), linear kernel).\n",
        "  - Passthrough: Enabled.\n",
        "- **Model 10**:\n",
        "  - Base Models: Random Forest, CatBoost.\n",
        "  - Final Estimator: Ridge Regression (\\(\\alpha = 5\\)).\n",
        "  - Passthrough: Enabled.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Base Models Initialization**\n",
        "- **Random Forest**: Ensemble of decision trees with depth and sample-split controls.\n",
        "- **CatBoost**: Gradient boosting model with advanced handling of categorical data.\n",
        "- **Gradient Boosting**: A classic gradient boosting regressor optimized for generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Metrics Definition**\n",
        "The evaluation process uses three primary metrics:\n",
        "1. **RMSE (Root Mean Squared Error)**:\n",
        "   - Measures the magnitude of prediction errors (lower is better).\n",
        "2. **\\(R^2\\) (Coefficient of Determination)**:\n",
        "   - Quantifies variance explained by the model (higher is better).\n",
        "3. **MBD (Mean Bias Deviation)**:\n",
        "   - Indicates systematic bias (values closer to zero are better).\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Workflow**\n",
        "\n",
        "#### For Each Model:\n",
        "1. **Initialize Stacking Regressor**:\n",
        "   - Combine selected base models.\n",
        "   - Configure the final estimator and passthrough option.\n",
        "\n",
        "2. **Train the Model**:\n",
        "   - Train the model on the training dataset.\n",
        "\n",
        "3. **Evaluate Performance**:\n",
        "   - **Training Dataset**:\n",
        "     - Calculate RMSE, \\(R^2\\), and MBD to check model fit.\n",
        "   - **Testing Dataset**:\n",
        "     - Assess generalization using RMSE, \\(R^2\\), and MBD.\n",
        "   - **Unseen Dataset**:\n",
        "     - Evaluate performance on entirely new data for real-world relevance.\n",
        "\n",
        "4. **Cross-Validation**:\n",
        "   - Perform 5-fold cross-validation on the training set.\n",
        "   - Calculate mean and standard deviation for RMSE.\n",
        "   - why not for \\(R^2)\\: infrusture limmits and time and more, here models are showing very similar \\(R^2)\\ but may have diffrence in RMSE.\n",
        "\n",
        "5. **Log Metrics**:\n",
        "   - Print metrics for training, testing, unseen datasets, and cross-validation.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Final Comparison**\n",
        "- The model with the best performance on unseen data is chosen based on:\n",
        "  - Lowest **RMSE**.\n",
        "  - Highest **\\(R^2\\)**.\n",
        "  - Minimal **MBD**.\n",
        "- Cross-validation results are used to confirm consistency and robustness.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "klNYlhyFkuQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "top_models = [\n",
        "    {\n",
        "        \"name\": \"Model 18\",\n",
        "        \"combination\": ['random_forest', 'catboost', 'gradient_boosting'],\n",
        "        \"final_estimator\": SVR(kernel='linear', C=0.1),\n",
        "        \"passthrough\": False\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 6\",\n",
        "        \"combination\": ['random_forest', 'catboost', 'gradient_boosting'],\n",
        "        \"final_estimator\": SVR(kernel='linear', C=0.01),\n",
        "        \"passthrough\": True\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Model 10\",\n",
        "        \"combination\": ['random_forest', 'catboost'],\n",
        "        \"final_estimator\": Ridge(alpha=5),\n",
        "        \"passthrough\": True\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize base models\n",
        "base_models = {\n",
        "    'random_forest': RandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=200, random_state=42),\n",
        "    'catboost': CatBoostRegressor(bagging_temperature=0.1, depth=4, iterations=100, l2_leaf_reg=10,\n",
        "                                  learning_rate=0.1, min_data_in_leaf=1, silent=True, random_state=42),\n",
        "    'gradient_boosting': GradientBoostingRegressor(learning_rate=0.01, max_depth=10, n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mbd = np.mean(y_pred - y_true)\n",
        "    return rmse, r2, mbd\n",
        "\n",
        "X_cv_subset = X_train.sample(frac=0.1, random_state=42)\n",
        "y_cv_subset = y_train.loc[X_cv_subset.index]\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "# Train, evaluate, and cross-validate each model\n",
        "for model_info in top_models:\n",
        "    print(f\"Training, evaluating, and cross-validating {model_info['name']}\")\n",
        "\n",
        "    # Create the stacking regressor\n",
        "    estimators = [(name, base_models[name]) for name in model_info[\"combination\"]]\n",
        "    model = StackingRegressor(\n",
        "        estimators=estimators,\n",
        "        final_estimator=model_info[\"final_estimator\"],\n",
        "        passthrough=model_info[\"passthrough\"],\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on train set\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_rmse, train_r2, train_mbd = calculate_metrics(y_train, train_pred)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_rmse, test_r2, test_mbd = calculate_metrics(y_test, test_pred)\n",
        "\n",
        "    # Predict on unseen data\n",
        "    unseen_pred = model.predict(X_test_unseen)\n",
        "    unseen_rmse, unseen_r2, unseen_mbd = calculate_metrics(y_test_unseen, unseen_pred)\n",
        "\n",
        "\n",
        "    cv_r2_scores = cross_val_score(model, X_cv_subset, y_cv_subset, cv=kf, scoring='r2',n_jobs=-1)\n",
        "    cv_rmse_scores = cross_val_score(model, X_cv_subset, y_cv_subset, cv=kf, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
        "\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Metrics for {model_info['name']}:\")\n",
        "    print(f\"Train - RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}, MBD: {train_mbd:.4f}\")\n",
        "    print(f\"Test  - RMSE: {test_rmse:.4f}, R²: {test_r2:.4f}, MBD: {test_mbd:.4f}\")\n",
        "    print(f\"Unseen - RMSE: {unseen_rmse:.4f}, R²: {unseen_r2:.4f}, MBD: {unseen_mbd:.4f}\")\n",
        "    print(f\"Cross-Validation - Mean R²: {cv_r2_scores.mean():.4f}, Std R²: {cv_r2_scores.std():.4f}\")\n",
        "    print(f\"Cross-Validation - Mean RMSE: {-cv_rmse_scores.mean():.4f}, Std RMSE: {cv_rmse_scores.std():.4f}\")\n",
        "    print('-----' * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQgiJuUAgK44",
        "outputId": "9b1d7c46-0892-4097-dcd3-7348c3a8c338"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training, evaluating, and cross-validating Model 18\n",
            "Metrics for Model 18:\n",
            "Train - RMSE: 63.9418, R²: 0.7913, MBD: 2.5891\n",
            "Test  - RMSE: 69.4156, R²: 0.7602, MBD: 1.2350\n",
            "Unseen - RMSE: 62.2375, R²: 0.8025, MBD: -0.3445\n",
            "Cross-Validation - Mean R²: 0.7517, Std R²: 0.0150\n",
            "Cross-Validation - Mean RMSE: 71.3858, Std RMSE: 0.6695\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Training, evaluating, and cross-validating Model 6\n",
            "Metrics for Model 6:\n",
            "Train - RMSE: 63.9089, R²: 0.7916, MBD: 2.5869\n",
            "Test  - RMSE: 69.4527, R²: 0.7599, MBD: 1.2258\n",
            "Unseen - RMSE: 62.2741, R²: 0.8023, MBD: -0.4550\n",
            "Cross-Validation - Mean R²: 0.7520, Std R²: 0.0150\n",
            "Cross-Validation - Mean RMSE: 71.3416, Std RMSE: 0.6432\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Training, evaluating, and cross-validating Model 10\n",
            "Metrics for Model 10:\n",
            "Train - RMSE: 65.6707, R²: 0.7799, MBD: 0.0096\n",
            "Test  - RMSE: 69.4387, R²: 0.7600, MBD: -1.3052\n",
            "Unseen - RMSE: 62.3451, R²: 0.8018, MBD: -2.8479\n",
            "Cross-Validation - Mean R²: 0.7531, Std R²: 0.0145\n",
            "Cross-Validation - Mean RMSE: 71.2006, Std RMSE: 0.7164\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Results: Model Training, Evaluation, and Selection\n",
        "\n",
        "## Overview\n",
        "This section summarizes the training, evaluation, and prediction process for the top three selected models. Metrics on unseen data are used to identify the best-performing model.\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation Results Table\n",
        "\n",
        "| **Model**   | **Base Models**                                   | **Final Estimator**                     | **Passthrough** | **RMSE (Train)** | **\\(R^2\\) (Train)** | **MBD (Train)** | **RMSE (Test)** | **\\(R^2\\) (Test)** | **MBD (Test)** | **RMSE (Unseen)** | **\\(R^2\\) (Unseen)** | **MBD (Unseen)** |\n",
        "|-------------|---------------------------------------------------|------------------------------------------|-----------------|------------------|---------------------|-----------------|-----------------|--------------------|----------------|-------------------|----------------------|-----------------|\n",
        "| **Model 18** | Random Forest, CatBoost, Gradient Boosting       | SVR (kernel: linear, \\(C = 0.1\\))        | No              | 63.9418          | 0.7913              | 2.5891          | 69.4156         | 0.7602             | 1.2350         | 62.2375          | 0.8025               | -0.3445         |\n",
        "| **Model 6**  | Random Forest, CatBoost, Gradient Boosting       | SVR (kernel: linear, \\(C = 0.01\\))       | Yes             | 63.9089          | 0.7916              | 2.5869          | 69.4527         | 0.7599             | 1.2258         | 62.2741          | 0.8023               | -0.4550         |\n",
        "| **Model 10** | Random Forest, CatBoost                         | Ridge Regression (\\(\\alpha = 5\\))       | Yes             | 65.6707          | 0.7799              | 0.0096          | 69.4387         | 0.7600             | -1.3052        | 62.3451          | 0.8018               | -2.8479         |\n",
        "\n",
        "---\n",
        "\n",
        "## Cross-Validation Summary\n",
        "\n",
        "| **Model**   | **Cross-Validation Mean \\(R^2\\)** | **Std \\(R^2\\)** | **Cross-Validation Mean RMSE** | **Std RMSE** |\n",
        "|-------------|-----------------------------------|-----------------|---------------------------------|--------------|\n",
        "| **Model 18** | 0.7517                           | 0.0150          | 71.3858                         | 0.6695       |\n",
        "| **Model 6**  | 0.7520                           | 0.0150          | 71.3416                         | 0.6432       |\n",
        "| **Model 10** | 0.7531                           | 0.0145          | 71.2006                         | 0.7164       |\n",
        "\n",
        "---\n",
        "\n",
        "## Selection Criteria\n",
        "\n",
        "1. **Lowest RMSE on Unseen Data**:\n",
        "   - Ensures the model generates the most accurate predictions on new samples.\n",
        "   \n",
        "2. **Highest \\(R^2\\) on Unseen Data**:\n",
        "   - Reflects the model’s ability to explain the variance in target variables effectively.\n",
        "\n",
        "3. **Minimal MBD on Unseen Data**:\n",
        "   - Indicates reduced systematic bias and more balanced predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## Selected Model\n",
        "### **Model 18**\n",
        "- **Reason**:\n",
        "  - Best RMSE on unseen data (\\(62.2375\\)).\n",
        "  - Highest \\(R^2\\) on unseen data (\\(0.8025\\)).\n",
        "  - MBD closest to zero (\\(-0.3445\\)) compared to other models.\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Model Deployment**:\n",
        "   - Deploy **Model 18** in a real-world environment.\n",
        "   - Monitor key metrics (e.g., RMSE, \\(R^2\\), MBD) to ensure consistent performance.\n",
        "\n",
        "2. **Continuous Model Recalibration**:\n",
        "   - Retrain the model periodically with updated datasets to maintain robustness.\n",
        "   - Reassess feature importance and model architecture for evolving data trends.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "a0XiwStnlGTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 7: Logistic Regression: Data Exploration and Feature Importance"
      ],
      "metadata": {
        "id": "7pQImKKBjDOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In this step, the dataset is prepared for model training and evaluation by splitting it into multiple subsets. The goal is to ensure robust model evaluation while keeping a dedicated portion of the data unseen for final testing.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Data Preprocessing**\n",
        "- The dataset `data_win_p` is refined by dropping unnecessary columns:\n",
        "  - **Dropped Columns**: `Score`, `Unnamed: 0`, `Team`.\n",
        "- **Feature Selection**:\n",
        "  - `X`: Contains all columns except `is_winner`.\n",
        "  - `y`: The target variable, `is_winner`.\n",
        "\n",
        "- **Standardization**:\n",
        "  - The features are standardized using `StandardScaler` to ensure that all variables have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Splitting the Data**\n",
        "The dataset is split into several subsets for training, tuning, and evaluation:\n",
        "\n",
        "1. **Initial Split:**\n",
        "   - **`X_train_seen`** and **`X_test_unseen`**:\n",
        "     - `X_train_seen`: 99% of the data used for training models on seen data.\n",
        "     - `X_test_unseen`: 1% of the data reserved for final evaluation on unseen data.\n",
        "   - Corresponding splits for `y_train_seen` and `y_test_unseen`.\n",
        "\n",
        "2. **Train-Test Split for Seen Data:**\n",
        "   - From `X_train_seen`, a further split:\n",
        "     - **`X_train`**: 80% of the seen training data for model training.\n",
        "     - **`X_test`**: 20% of the seen training data for validation.\n",
        "   - Corresponding splits for `y_train` and `y_test`.\n",
        "\n",
        "3. **Subset for Hyperparameter Tuning:**\n",
        "   - A small subset (`5%` of `X_train`) is selected for hyperparameter tuning:\n",
        "     - **`X_select`**: 4% of the entire data.\n",
        "   - Splits for tuning:\n",
        "     - **`X_train_select`**: 80% of `X_select` for tuning.\n",
        "     - **`x_test_select`**: 20% of `X_select` for tuning validation.\n",
        "   - Corresponding splits for `y_train_select` and `y_test_select`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Data Verification**\n",
        "The shapes of all splits are printed to verify correctness:\n",
        "- **Seen Training and Testing Data**:\n",
        "  - `X_train_seen`, `y_train_seen`\n",
        "  - `X_test_unseen`, `y_test_unseen`\n",
        "- **Train-Test Split**:\n",
        "  - `X_train`, `y_train`\n",
        "  - `X_test`, `y_test`\n",
        "- **Subset for Hyperparameter Tuning**:\n",
        "  - `X_train_select`, `y_train_select`\n",
        "  - `x_test_select`, `y_test_select`\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Validation of Splits**\n",
        "To ensure data integrity, checks are performed:\n",
        "1. Verify the total number of records for `X` and `y`:\n",
        "   - `X = X_test_unseen + X_train_seen`\n",
        "   - `y = y_test_unseen + y_train_seen`\n",
        "2. Verify the total number of records in `X_train_seen` and `y_train_seen`:\n",
        "   - `X_train_seen = X_train + X_test`\n",
        "   - `y_train_seen = y_train + y_test`\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "This step ensures:\n",
        "- **Robust Data Splitting**: Creates subsets for training, validation, and unseen testing.\n",
        "- **Hyperparameter Tuning**: Selects a smaller subset for computational efficiency during tuning.\n",
        "- **Data Integrity**: Verifies consistency in splits to avoid data leakage or errors.\n"
      ],
      "metadata": {
        "id": "H0laV3KSSLlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9cfc8e-5cd0-4acb-d999-da3f046ab6b8",
        "id": "5MIH9_kAcKTZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seen shape: (35329, 10)\n",
            "y_tarin_seen shape: (35329,)\n",
            "\n",
            "x_test_unseen shape: (357, 10)\n",
            "y_test_unseen shape: (357,)\n",
            "\n",
            "X_train shape: (28263, 10)\n",
            "y_train shape: (28263,)\n",
            "\n",
            "X_test shape: (7066, 10)\n",
            "y_test shape: (7066,)\n",
            "\n",
            "X_train_select shape: (1130, 10)\n",
            "y_tarin_select shape: (1130,)\n",
            "\n",
            "x_test_select shape: (283, 10)\n",
            "y_test_select shape: (283,)\n",
            "\n",
            "whole records of X (35686) are X = X_test_unseen + X_train_seen = 357 + 35329 = 35686 = 35686 \n",
            "Whole records of Y (35686) are Y = y_test_unseen + y_train_seen = 357 +  35329 = 35686 = 35686 \n",
            "\n",
            "whole records of X_train_seen (35329) are X_train_seen = X_train + X_test = 28263 + 7066 = 35329 = 35329 \n",
            "whole records of y_train_seen (35329) are y_train_seen = y_train + y_test = 28263 + 7066 = 35329 = 35329 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_win_p = data_win_p.drop(columns=['Score', 'Unnamed: 0','Team'])\n",
        "\n",
        "\n",
        "X = data_win_p.drop(columns=['is_winner'])  # Features (all columns except 'Score')\n",
        "y = data_win_p['is_winner']  # Target variable\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "z_scores = scaler.fit_transform(X)\n",
        "\n",
        "X = pd.DataFrame(z_scores, columns=X.columns)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_seen, X_test_unseen, y_train_seen, y_test_unseen = train_test_split(X, y, test_size=0.01, random_state=85) # 99% train for seen data, 1% test for unseen\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_seen,y_train_seen, test_size=0.2, random_state=99) # 80% train, 20% test\n",
        "X_select, _ , y_select, _ = train_test_split(X_train, y_train, test_size=0.95, random_state=42) # since we have a large scale data we get 5 of training data for selcting and tuning  (4 percent of whole data)\n",
        "\n",
        "# Select a subset for hyperparameter tuning\n",
        "X_train_select, x_test_select, y_train_select, y_test_select = train_test_split(X_select, y_select, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now you can use X_train, X_test, y_train, and y_test for model training and evaluation\n",
        "print(f\"X_train_seen shape: {X_train_seen.shape}\")\n",
        "print(f\"y_tarin_seen shape: {y_train_seen.shape}\\n\")\n",
        "print(f\"x_test_unseen shape: {X_test_unseen.shape}\")\n",
        "print(f\"y_test_unseen shape: {y_test_unseen.shape}\\n\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\\n\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\\n\")\n",
        "print(f\"X_train_select shape: {X_train_select.shape}\")\n",
        "print(f\"y_tarin_select shape: {y_train_select.shape}\\n\")\n",
        "print(f\"x_test_select shape: {x_test_select.shape}\")\n",
        "print(f\"y_test_select shape: {y_test_select.shape}\\n\")\n",
        "\n",
        "print(f\"whole records of X ({X.shape[0]}) are X = X_test_unseen + X_train_seen = {X_test_unseen.shape[0]} + {X_train_seen.shape[0]} = {X_train_seen.shape[0] + X_test_unseen.shape[0]} = {X.shape[0]} \")\n",
        "print(f\"Whole records of Y ({y.shape[0]}) are Y = y_test_unseen + y_train_seen = {y_test_unseen.shape[0]} +  {y_train_seen.shape[0]} = {y_train_seen.shape[0] + y_test_unseen.shape[0]} = {y.shape[0]} \\n\")\n",
        "\n",
        "print(f\"whole records of X_train_seen ({X_train_seen.shape[0]}) are X_train_seen = X_train + X_test = {X_train.shape[0]} + {X_test.shape[0]} = {X_train.shape[0] + X_test.shape[0]} = {X_train_seen.shape[0]} \")\n",
        "print(f\"whole records of y_train_seen ({y_train_seen.shape[0]}) are y_train_seen = y_train + y_test = {y_train.shape[0]} + {y_test.shape[0]} = {y_train.shape[0] + y_test.shape[0]} = {y_train_seen.shape[0]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Define Logistic Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "xksyE4RwjHpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this step, we define a custom evaluation function, `evaluate_logistic_model`, to assess the performance of logistic regression models. The function calculates key metrics to evaluate the model's ability to classify winners and non-winners.\n",
        "\n",
        "---\n",
        "\n",
        "### **Function Purpose**\n",
        "The `evaluate_logistic_model` function:\n",
        "- Trains a logistic regression model on the training dataset.\n",
        "- Evaluates its performance on both training and test datasets.\n",
        "- Provides detailed metrics to understand the model's classification performance, including its ability to generalize and avoid overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Metrics Computed**\n",
        "1. **Accuracy**:\n",
        "   - Measures the proportion of correct predictions over total predictions.\n",
        "   - Indicates the overall performance of the model.\n",
        "\n",
        "2. **Precision**:\n",
        "   - Proportion of true positive predictions among all positive predictions.\n",
        "   - Useful for understanding false positive rates.\n",
        "\n",
        "3. **Recall**:\n",
        "   - Proportion of true positives correctly identified out of all actual positives.\n",
        "   - Important for minimizing false negatives.\n",
        "\n",
        "4. **F1 Score**:\n",
        "   - Harmonic mean of precision and recall.\n",
        "   - Provides a balanced measure, especially for imbalanced datasets.\n",
        "\n",
        "5. **Confusion Matrix**:\n",
        "   - Displays true positives, false positives, true negatives, and false negatives.\n",
        "   - Gives a granular view of model performance.\n",
        "\n",
        "---\n",
        "\n",
        "### **Evaluation Process**\n",
        "1. **Model Training**:\n",
        "   - The model is trained on `x_train` and `y_train`.\n",
        "\n",
        "2. **Predictions**:\n",
        "   - Predictions are made on both training (`x_train`) and test (`x_test`) datasets.\n",
        "\n",
        "3. **Metric Calculation**:\n",
        "   - For both train and test sets:\n",
        "     - Accuracy, precision, recall, and F1 score are calculated.\n",
        "     - The confusion matrix is generated.\n",
        "\n",
        "4. **Comparison of Train and Test Metrics**:\n",
        "   - By comparing the metrics, we assess the model's ability to generalize:\n",
        "     - Large differences suggest overfitting or underfitting.\n",
        "     - Similar metrics indicate good generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### **Output**\n",
        "- **Test Metrics**:\n",
        "  - Accuracy, precision, recall, F1 score, and confusion matrix for test data.\n",
        "- **Train Metrics**:\n",
        "  - Accuracy, precision, recall, F1 score, and confusion matrix for training data.\n",
        "- **Best Parameters**:\n",
        "  - If the model is part of a hyperparameter tuning process (e.g., GridSearchCV), the best parameters are returned.\n",
        "\n",
        "---\n",
        "\n",
        "### **Importance of the Custom Function**\n",
        "This function provides a structured way to evaluate logistic regression models comprehensively. It ensures:\n",
        "- Consistency in evaluation across different models.\n",
        "- Identification of overfitting or underfitting through train-test metric comparison.\n",
        "- Insights into model effectiveness for real-world classification tasks.\n",
        "\n",
        "By systematically using this function, we can refine models and improve their predictive performance while maintaining generalization across datasets.\n"
      ],
      "metadata": {
        "id": "_HDqHccgSbUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_logistic_model(model, x_train, x_test, y_train, y_test):\n",
        "    # Fit the model on training data\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Predictions for train and test sets\n",
        "    y_pred_test = model.predict(x_test)\n",
        "    y_pred_train = model.predict(x_train)\n",
        "\n",
        "    # Accuracy, Precision, Recall, and F1 Score\n",
        "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "    precision_test = precision_score(y_test, y_pred_test, average='binary')\n",
        "    recall_test = recall_score(y_test, y_pred_test, average='binary')\n",
        "    f1_test = f1_score(y_test, y_pred_test, average='binary')\n",
        "    conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "    precision_train = precision_score(y_train, y_pred_train, average='binary')\n",
        "    recall_train = recall_score(y_train, y_pred_train, average='binary')\n",
        "    f1_train = f1_score(y_train, y_pred_train, average='binary')\n",
        "    conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "    # Print Evaluation Metrics for Test Data\n",
        "    print(\"Test Metrics:\")\n",
        "    print(f\"Accuracy (Test): {accuracy_test:.4f}\")\n",
        "    print(f\"Precision (Test): {precision_test:.4f}\")\n",
        "    print(f\"Recall (Test): {recall_test:.4f}\")\n",
        "    print(f\"F1 Score (Test): {f1_test:.4f}\")\n",
        "    print(\"Confusion Matrix (Test):\")\n",
        "    print(conf_matrix_test)\n",
        "\n",
        "    # Print Evaluation Metrics for Train Data\n",
        "    print(\"\\nTrain Metrics:\")\n",
        "    print(f\"Accuracy (Train): {accuracy_train:.4f}\")\n",
        "    print(f\"Precision (Train): {precision_train:.4f}\")\n",
        "    print(f\"Recall (Train): {recall_train:.4f}\")\n",
        "    print(f\"F1 Score (Train): {f1_train:.4f}\")\n",
        "    print(\"Confusion Matrix (Train):\")\n",
        "    print(conf_matrix_train)\n",
        "\n",
        "    # Return best parameters if available\n",
        "    try:\n",
        "        return model.best_params_\n",
        "    except AttributeError:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "5fx7qEyRjJTO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Logistic Regression Training"
      ],
      "metadata": {
        "id": "kPC-J4UJzEuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comprehensive Model Training and Evaluation Overview\n",
        "\n",
        "#### **Objective**\n",
        "The goal is to evaluate multiple machine learning models for a binary classification problem, using precision as the primary metric. The process includes hyperparameter tuning and a custom metric to balance model generalization and performance.\n",
        "\n",
        "---\n",
        "\n",
        "### **Models and Hyperparameter Grids**\n",
        "1. **Logistic Regression**:\n",
        "   - `C`: Regularization strength.\n",
        "   - `solver`: Optimization algorithm.\n",
        "\n",
        "2. **Random Forest**:\n",
        "   - `n_estimators`: Number of trees.\n",
        "   - `max_depth`: Depth of the trees.\n",
        "\n",
        "3. **Gradient Boosting**:\n",
        "   - `n_estimators`: Number of boosting stages.\n",
        "   - `learning_rate`: Step size for weight updates.\n",
        "   - `max_depth`: Depth of individual trees.\n",
        "\n",
        "4. **XGBoost**:\n",
        "   - `n_estimators`: Number of boosting stages.\n",
        "   - `learning_rate`: Learning rate.\n",
        "   - `max_depth`: Depth of individual trees.\n",
        "\n",
        "5. **K-Nearest Neighbors (KNN)**:\n",
        "   - `n_neighbors`: Number of neighbors.\n",
        "   - `weights`: Weighting strategy.\n",
        "\n",
        "6. **CatBoost**:\n",
        "   - `iterations`: Number of boosting iterations.\n",
        "   - `depth`: Depth of individual trees.\n",
        "   - `learning_rate`: Step size for boosting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Custom Metric**\n",
        "The custom metric is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Custom Metric} = \\left(\\frac{\\text{F1 (Test)}}{\\text{F1 Difference}}\\right) \\times \\left(\\frac{\\text{Accuracy (Test)}}{\\text{Accuracy Difference}}\\right)\n",
        "$$\n",
        "\n",
        "- **F1 Difference**: Absolute difference between F1 scores for test and train data.\n",
        "- **Accuracy Difference**: Absolute difference between accuracies for test and train data.\n",
        "- The metric rewards models with balanced performance and penalizes those with high overfitting or underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Model Training Process**\n",
        "1. **Hyperparameter Tuning**:\n",
        "   - GridSearchCV is used with cross-validation (`cv=3`) for each model to identify optimal hyperparameters.\n",
        "\n",
        "2. **Evaluation Metrics**:\n",
        "   - **F1 Score**: Combines precision and recall to assess classification performance.\n",
        "   - **Accuracy**: Measures overall correctness of predictions.\n",
        "   - **Custom Metric**: Balances model generalization and predictive power.\n",
        "\n",
        "3. **Train-Test Metric Comparison**:\n",
        "   - Metrics are calculated for both training and test datasets to detect overfitting or underfitting.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i207Nx3TSxEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter grids\n",
        "log_reg_params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['lbfgs', 'saga']\n",
        "}\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30]\n",
        "}\n",
        "gbr_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "knn_params = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "catboost_params = {\n",
        "    'iterations': [100, 200],\n",
        "    'depth': [4, 6],\n",
        "    'learning_rate': [0.1, 0.01]\n",
        "}\n",
        "\n",
        "# Update GridSearchCV objects to use F1 scoring\n",
        "models = {\n",
        "    'Logistic Regression': GridSearchCV(LogisticRegression(max_iter=1000), log_reg_params, cv=3, scoring='precision', n_jobs=-1),\n",
        "    'Random Forest': GridSearchCV(RandomForestClassifier(), rf_params, cv=3, scoring='precision', n_jobs=-1),\n",
        "    'Gradient Boosting': GridSearchCV(GradientBoostingClassifier(), gbr_params, cv=3, scoring='precision', n_jobs=-1),\n",
        "    'XGBoost': GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, cv=3, scoring='precision', n_jobs=-1),\n",
        "    'K-Nearest Neighbors': GridSearchCV(KNeighborsClassifier(), knn_params, cv=3, scoring='precision', n_jobs=-1),\n",
        "    'CatBoost': GridSearchCV(CatBoostClassifier(verbose=0), catboost_params, cv=3, scoring='precision', n_jobs=-1)\n",
        "}\n",
        "\n",
        "def custom_metric(f1_test, f1_train, accuracy_test, accuracy_train):\n",
        "    epsilon = 1e-6  # Small constant to prevent division by zero\n",
        "    f1_diff = abs(f1_test - f1_train) + epsilon\n",
        "    accuracy_diff = abs(accuracy_test - accuracy_train) + epsilon\n",
        "    return (f1_test / f1_diff) * (accuracy_test / accuracy_diff)\n",
        "\n",
        "model_performance = {}\n",
        "\n",
        "for name, grid_model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    grid_model.fit(X_train_select, y_train_select)  # Perform the fitting process\n",
        "\n",
        "    best_model = grid_model.best_estimator_\n",
        "\n",
        "    y_pred_test = best_model.predict(x_test_select)\n",
        "    y_pred_train = best_model.predict(X_train_select)  # Define y_pred_train after fitting\n",
        "\n",
        "    accuracy_test = accuracy_score(y_test_select, y_pred_test)\n",
        "    accuracy_train = accuracy_score(y_train_select, y_pred_train)\n",
        "    f1_test = f1_score(y_test_select, y_pred_test)\n",
        "    f1_train = f1_score(y_train_select, y_pred_train)\n",
        "\n",
        "    custom_metric_value = custom_metric(f1_test, f1_train, accuracy_test, accuracy_train)\n",
        "\n",
        "    model_performance[name] = {\n",
        "        'Best Parameters': grid_model.best_params_,\n",
        "        'Accuracy Test': accuracy_test,\n",
        "        'F1 Test': f1_test,\n",
        "        'F1 Train': f1_train,\n",
        "        'Custom Metric': custom_metric_value\n",
        "    }\n",
        "\n",
        "    print(f\"Best Parameters for {name}: {grid_model.best_params_}\")\n",
        "    print(f\"Test Accuracy: {accuracy_test:.4f}, Test F1: {f1_test:.4f}, Train F1: {f1_train:.4f}, Custom Metric: {custom_metric_value:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_3ZXUKzzGV_",
        "outputId": "3e79c77a-91bd-442e-b72e-3add443eaeeb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Best Parameters for Logistic Regression: {'C': 0.1, 'solver': 'lbfgs'}\n",
            "Test Accuracy: 0.5618, Test F1: 0.4746, Train F1: 0.5153, Custom Metric: 108.5378\n",
            "Training Random Forest...\n",
            "Best Parameters for Random Forest: {'max_depth': 10, 'n_estimators': 100}\n",
            "Test Accuracy: 0.5724, Test F1: 0.5292, Train F1: 0.9588, Custom Metric: 1.8060\n",
            "Training Gradient Boosting...\n",
            "Best Parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "Test Accuracy: 0.5654, Test F1: 0.4766, Train F1: 0.5919, Custom Metric: 17.7091\n",
            "Training XGBoost...\n",
            "Best Parameters for XGBoost: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "Test Accuracy: 0.5724, Test F1: 0.4851, Train F1: 0.5817, Custom Metric: 24.0298\n",
            "Training K-Nearest Neighbors...\n",
            "Best Parameters for K-Nearest Neighbors: {'n_neighbors': 3, 'weights': 'uniform'}\n",
            "Test Accuracy: 0.5512, Test F1: 0.5348, Train F1: 0.7819, Custom Metric: 4.7967\n",
            "Training CatBoost...\n",
            "Best Parameters for CatBoost: {'depth': 4, 'iterations': 100, 'learning_rate': 0.01}\n",
            "Test Accuracy: 0.5442, Test F1: 0.3828, Train F1: 0.4634, Custom Metric: 27.7964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results Table**\n",
        "\n",
        "| **Model**              | **Best Parameters**                                   | **Test Accuracy** | **Test F1** | **Train F1** | **Custom Metric** |\n",
        "|-------------------------|------------------------------------------------------|-------------------|-------------|--------------|-------------------|\n",
        "| Logistic Regression     | `{'C': 0.1, 'solver': 'lbfgs'}`                      | 0.5618            | 0.4746      | 0.5153       | 108.5378          |\n",
        "| Random Forest           | `{'max_depth': 10, 'n_estimators': 100}`             | 0.5724            | 0.5292      | 0.9588       | 1.8060            |\n",
        "| Gradient Boosting       | `{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}` | 0.5654 | 0.4766      | 0.5919       | 17.7091           |\n",
        "| XGBoost                 | `{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}` | 0.5724 | 0.4851      | 0.5817       | 24.0298           |\n",
        "| K-Nearest Neighbors     | `{'n_neighbors': 3, 'weights': 'uniform'}`           | 0.5512            | 0.5348      | 0.7819       | 4.7967            |\n",
        "| CatBoost                | `{'depth': 4, 'iterations': 100, 'learning_rate': 0.01}` | 0.5442 | 0.3828      | 0.4634       | 27.7964           |\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Insights**\n",
        "\n",
        "1. **Selected Model: Logistic Regression**:\n",
        "   - Logistic Regression was chosen for higher custom metric becuase of less overfit and also easier deployment due to its simplicity and interpretability.\n",
        "   - It provides moderate generalization with:\n",
        "     - ***custom metric: 108.5378***\n",
        "     - Test Accuracy: \\(0.5618\\)\n",
        "     - Test F1 Score: \\(0.4746\\)\n",
        "\n",
        "2. **Justification for Choice**:\n",
        "   - While other models (e.g., Random Forest, XGBoost) show slightly higher accuracy or F1 scores, Logistic Regression offers:\n",
        "     - A low-complexity approach, making it faster to train and deploy.\n",
        "     - Transparency in decision-making, critical for understanding predictions.\n",
        "   - ***The high Custom Metric (\\(108.5378\\)) reflects a focus on generalization rather than overfitting.***\n",
        "\n",
        "---\n",
        "\n",
        "### **Comparison to Other Models**:\n",
        "- **Random Forest**:\n",
        "  - Higher Test Accuracy (\\(0.5724\\)) and Test F1 Score (\\(0.5292\\)) but shows signs of overfitting with Train F1 of \\(0.9588\\).\n",
        "- **Gradient Boosting and XGBoost**:\n",
        "  - Similar performance to Random Forest but at the cost of higher complexity and longer training times.\n",
        "- **K-Nearest Neighbors**:\n",
        "  - Moderate performance but lacks the interpretability of Logistic Regression.\n",
        "- **CatBoost**:\n",
        "  - Poorer generalization compared to Logistic Regression, as seen in its lower Test F1 (\\(0.3828\\)).\n",
        "\n",
        "---\n",
        "\n",
        "### **Next step**\n",
        "1. **Deploy Logistic Regression**:\n",
        "   - Begin with Logistic Regression for its interpretability and computational efficiency.\n",
        "2. **Monitor Performance**:\n",
        "   - Evaluate real-world outcomes to ensure consistent performance.\n",
        "3. **fine-tuning**:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GLRG0JGBrU-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10: Evaluating Logistic Regression\n",
        "\n",
        "### Step: Evaluating **Logistic Regression**\n",
        "\n",
        "In this step, we focus exclusively on the performance of **Logistic Regression** using an extended hyperparameter grid search. The evaluation involves:\n",
        "\n",
        "- **Traditional Metrics**: Accuracy, Precision, Recall, and F1-score.\n",
        "- **Custom Metric**: Designed to assess model consistency and generalization across training, test, and unseen datasets.\n",
        "\n",
        "---\n",
        "\n",
        "### Objective:\n",
        "The primary focus is to evaluate whether the **custom metric** provides deeper insights into model performance compared to traditional metrics like precision. We aim to understand how well Logistic Regression generalizes to unseen data and its prediction confidence for winners and non-winners.\n",
        "\n",
        "---\n",
        "\n",
        "### Approach:\n",
        "1. **Extended Hyperparameter Tuning**:\n",
        "   - Perform a comprehensive grid search for Logistic Regression, testing a wide range of hyperparameters (e.g., regularization strength, solvers, and penalties) to ensure the model achieves its optimal configuration.\n",
        "\n",
        "2. **Evaluation Criteria**:\n",
        "   - **Density of Predictions**: Analyze the distribution of predicted probabilities for both winners and non-winners, focusing on the confidence and spread of predictions.\n",
        "   - **Whole Dataset Performance**: Evaluate traditional metrics and the custom metric on training, test, and unseen datasets to assess the model's ability to generalize effectively.\n",
        "\n",
        "3. **Visual Analysis**:\n",
        "   - Visualize the probability distributions of winners and non-winners to determine how well the model distinguishes between the two classes.\n",
        "   - Assess how many predictions exceed or fall below the decision threshold of 0.5 for winners and non-winners, respectively.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps:\n",
        "- Evaluate the Logistic Regression model’s performance using the defined metrics.\n",
        "- Analyze the density plots of predicted probabilities to verify the decision boundary and confidence levels.\n",
        "\n"
      ],
      "metadata": {
        "id": "JugYLnH7S8BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a more comprehensive set of hyperparameters\n",
        "log_reg_params = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Extending the range of C\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Including all common solvers\n",
        "    'penalty': ['l2', 'none']  # Additional regularization options, applicable to solvers\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with the extended parameters\n",
        "grid_log_reg = GridSearchCV(\n",
        "    LogisticRegression(max_iter=10000, random_state=42),\n",
        "    log_reg_params,\n",
        "    cv=5,  # Using 5-fold cross-validation\n",
        "    scoring='precision',  # Can change to 'f1' or another metric depending on the focus here for wining probility it is better to be Precision\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best model\n",
        "best_logreg = grid_log_reg.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = best_logreg.predict(X_train)\n",
        "y_pred_test = best_logreg.predict(X_test)\n",
        "y_pred_unseen = best_logreg.predict(X_test_unseen)\n",
        "\n",
        "# Predict probabilities for detailed insights\n",
        "probabilities_train = best_logreg.predict_proba(X_train)[:, 1]\n",
        "probabilities_test = best_logreg.predict_proba(X_test)[:, 1]\n",
        "probabilities_unseen = best_logreg.predict_proba(X_test_unseen)[:, 1]\n",
        "probabilities = best_logreg.predict_proba(X)[:, 1]\n",
        "\n",
        "# Metrics calculation\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "precision_train = precision_score(y_train, y_pred_train, average='binary')\n",
        "recall_train = recall_score(y_train, y_pred_train, average='binary')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='binary')\n",
        "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "accuracy_seen = accuracy_score(y_test, y_pred_test)\n",
        "precision_seen = precision_score(y_test, y_pred_test, average='binary')\n",
        "recall_seen = recall_score(y_test, y_pred_test, average='binary')\n",
        "f1_seen = f1_score(y_test, y_pred_test, average='binary')\n",
        "conf_matrix_seen = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "accuracy_unseen = accuracy_score(y_test_unseen, y_pred_unseen)\n",
        "precision_unseen = precision_score(y_test_unseen, y_pred_unseen, average='binary')\n",
        "recall_unseen = recall_score(y_test_unseen, y_pred_unseen, average='binary')\n",
        "f1_unseen = f1_score(y_test_unseen, y_pred_unseen, average='binary')\n",
        "conf_matrix_unseen = confusion_matrix(y_test_unseen, y_pred_unseen)\n",
        "\n",
        "# Print best parameters and metrics\n",
        "print(\"Best Parameters:\", grid_log_reg.best_params_)\n",
        "print(\"Metrics for Training Data:\")\n",
        "print(f\"Accuracy: {accuracy_train:.4f}, Precision: {precision_train:.4f}, Recall: {recall_train:.4f}, F1 Score: {f1_train:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_train)\n",
        "\n",
        "print(\"\\nMetrics for Seen Test Data:\")\n",
        "print(f\"Accuracy: {accuracy_seen:.4f}, Precision: {precision_seen:.4f}, Recall: {recall_seen:.4f}, F1 Score: {f1_seen:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_seen)\n",
        "\n",
        "print(\"\\nMetrics for Unseen Test Data:\")\n",
        "print(f\"Accuracy: {accuracy_unseen:.4f}, Precision: {precision_unseen:.4f}, Recall: {recall_unseen:.4f}, F1 Score: {f1_unseen:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_unseen)\n",
        "\n",
        "# Combined distribution for Train, Test, and Unseen Test\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Subplot 1: Distribution of Train, Test, and Unseen Test probabilities\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(probabilities_train, bins=100, color='blue', alpha=0.5, label='Train', density=True)\n",
        "plt.hist(probabilities_test, bins=100, color='green', alpha=0.5, label='Test', density=True)\n",
        "plt.hist(probabilities_unseen, bins=100, color='red', alpha=0.5, label='Unseen Test', density=True)\n",
        "plt.title('Distribution of Predicted Probabilities for \"Win\"')\n",
        "plt.xlabel('Probability of Win')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Combined predicted probabilities with threshold\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(probabilities, bins=1000, color='purple', alpha=0.7, density=True)\n",
        "plt.title('Combined Predicted Probabilities with Threshold')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.5, color='black', linestyle='--', label='Threshold (0.5)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WdUZxtKjsraI",
        "outputId": "fb4ca0f3-0b98-4d7e-b0e9-fadebff27236"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Metrics for Training Data:\n",
            "Accuracy: 0.6105, Precision: 0.6287, Recall: 0.3805, F1 Score: 0.4741\n",
            "Confusion Matrix:\n",
            "[[12294  2930]\n",
            " [ 8078  4961]]\n",
            "\n",
            "Metrics for Seen Test Data:\n",
            "Accuracy: 0.5986, Precision: 0.6189, Recall: 0.3551, F1 Score: 0.4512\n",
            "Confusion Matrix:\n",
            "[[3064  718]\n",
            " [2118 1166]]\n",
            "\n",
            "Metrics for Unseen Test Data:\n",
            "Accuracy: 0.5714, Precision: 0.6040, Recall: 0.3506, F1 Score: 0.4436\n",
            "Confusion Matrix:\n",
            "[[143  40]\n",
            " [113  61]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Model Evaluation and Results\n",
        "\n",
        "---\n",
        "\n",
        "#### **Overview**\n",
        "Logistic Regression is a widely used binary classification algorithm. This project evaluated a Logistic Regression model by optimizing hyperparameters, analyzing its performance on training, seen test, and unseen test datasets, and visualizing predicted probabilities for the \"Win\" class.\n",
        "\n",
        "---\n",
        "\n",
        "### **Hyperparameter Tuning**\n",
        "| **Parameter**  | **Values Tested**                                   |\n",
        "|----------------|-----------------------------------------------------|\n",
        "| **`C`**        | [0.01, 0.1, 1, 10, 100]                            |\n",
        "| **`solver`**   | ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  |\n",
        "| **`penalty`**  | ['l2', 'none']                                      |\n",
        "\n",
        "- **Cross-Validation**: A 5-fold cross-validation approach ensured robust generalization during hyperparameter tuning.\n",
        "- **Best Parameters**:\n",
        "  - **`C`**: 0.01\n",
        "  - **`penalty`**: 'l2'\n",
        "  - **`solver`**: 'saga'\n",
        "\n",
        "---\n",
        "\n",
        "### **Performance Metrics**\n",
        "\n",
        "| **Dataset**      | **Accuracy** | **Precision** | **Recall** | **F1 Score** |\n",
        "|-------------------|--------------|---------------|------------|--------------|\n",
        "| **Training**      | 0.6105       | 0.6287        | 0.3805     | 0.4741       |\n",
        "| **Seen Test**     | 0.5986       | 0.6189        | 0.3551     | 0.4512       |\n",
        "| **Unseen Test**   | 0.5714       | 0.6040        | 0.3506     | 0.4436       |\n",
        "\n",
        "---\n",
        "\n",
        "### **Probability Distribution Analysis**\n",
        "The predicted probabilities for the \"Win\" class (`is_winner=1`) were visualized as histograms:\n",
        "- **Training Data**: Blue histogram.\n",
        "- **Seen Test Data**: Green histogram.\n",
        "- **Unseen Test Data**: Red histogram.\n",
        "\n",
        "#### Key Observations:\n",
        "1. **Overlap in Distributions**:\n",
        "   - Substantial overlap across training, test, and unseen test data indicates the model struggles to clearly separate winners and non-winners.\n",
        "2. **Generalization**:\n",
        "   - The similarity between training and test distributions shows the model generalizes moderately well but highlights limited predictive power for unseen scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Observations**\n",
        "\n",
        "#### **Model Tuning**:\n",
        "- Optimal parameters (**`C=0.01`**, **`penalty='l2'`**, **`solver='saga'`**) balanced bias and variance effectively during training.\n",
        "\n",
        "#### **Performance**:\n",
        "1. The **F1 Score** decreased from **0.4741** (training) to **0.4512** (seen test), and further to unseen datasets (**0.4436**), suggesting a slight overfitting issue.\n",
        "2. The **Accuracy**, **Precision**, and **Recall** metrics reflect moderate predictive power but indicate challenges in effectively predicting winners.\n",
        "\n",
        "#### **Probability Distributions**:\n",
        "- Overlapping histograms emphasize the need for further improvement in model discrimination between winners and non-winners.\n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps**\n",
        "\n",
        "1. **Threshold Tuning**:\n",
        "   - Adjust the classification threshold (0.5) for the \"Win\" class to improve recall without sacrificing precision.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "nWfdMW_8UQA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Note**:\n",
        "While next analysis focuses on maximizing the algorithm's theoretical power, in real-world applications, predictions for new data must consider consistent preprocessing, especially scaling. Scaling subsets independently or inconsistently can distort predictions. The next section elaborates on this consideration and how it impacts practical deployments.\n",
        "\n",
        "***next cell scale varibles sepratly and next cell after this scale whole once. scaling one class make it is easier for a class this approach is to know strength of model***"
      ],
      "metadata": {
        "id": "_Vq9tueuHNF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winners=data_win_p[data_win_p['is_winner']==1]\n",
        "not_winners=data_win_p[data_win_p['is_winner']==0]\n",
        "\n",
        "X_winners = winners.drop('is_winner', axis=1)\n",
        "x_not_winners = not_winners.drop('is_winner', axis=1)\n",
        "\n",
        "scaler.transform(X_winners)\n",
        "scaler.transform(x_not_winners)\n",
        "\n",
        "# Predict probabilities for winners\n",
        "probabilities_winners_logreg = best_logreg.predict_proba(X_winners)[:, 1]\n",
        "probabilities_non_winners_logreg = best_logreg.predict_proba(x_not_winners)[:, 1]\n",
        "\n",
        "probabilities_winners_and_not_winners = np.concatenate((probabilities_winners_logreg, probabilities_non_winners_logreg))\n",
        "\n",
        "\n",
        "# Calculate the percentage of predictions above 0.5 for winners and below 0.5 for non-winners\n",
        "percentage_correct_winners_logreg = (probabilities_winners_logreg > 0.5).mean() * 100\n",
        "percentage_correct_non_winners_logreg = (probabilities_non_winners_logreg < 0.5).mean() * 100\n",
        "\n",
        "# Output the results\n",
        "print(f\"Percentage of correct predictions for winners (prob > 0.5): {percentage_correct_winners_logreg:.2f}%\")\n",
        "print(f\"Percentage of correct predictions for non-winners (prob < 0.5): {percentage_correct_non_winners_logreg:.2f}%\")\n",
        "\n",
        "# Plotting the distribution of probabilities\n",
        "plt.figure(figsize=(21, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(probabilities_winners_logreg, bins=20, color='green', alpha=0.5, density=True)\n",
        "plt.title('Predicted Probabilities for Winners: Logistic Regression')\n",
        "plt.xlabel('Probability of Being a Winner')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.5, color='black', linestyle='--')\n",
        "plt.annotate(f'{percentage_correct_winners_logreg:.2f}% > 0.5', xy=(0.55, max(plt.gca().get_ylim())*0.95), color='black')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.hist(probabilities_non_winners_logreg, bins=20, color='red', alpha=0.5, density=True)\n",
        "plt.title('Predicted Probabilities for Non-Winners: Logistic Regression')\n",
        "plt.xlabel('Probability of Being a Winner')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.5, color='black', linestyle='--')\n",
        "plt.annotate(f'{percentage_correct_non_winners_logreg:.2f}% < 0.5', xy=(0.45, max(plt.gca().get_ylim())*0.95), color='black', horizontalalignment='right')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(probabilities_winners_and_not_winners, bins=20, color='purple', alpha=0.5, density=True)\n",
        "plt.title('Combined Predicted Probabilities: Logistic Regression')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.5, color='black', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "7aUch5P_tQUY",
        "outputId": "6550c66b-4827-47a9-9bdf-b9062222c175"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of correct predictions for winners (prob > 0.5): 53.31%\n",
            "Percentage of correct predictions for non-winners (prob < 0.5): 68.30%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2100x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression: Predicted Probabilities Analysis\n",
        "\n",
        "This analysis investigates how well a logistic regression model predicts the probabilities of winners and non-winners, using a threshold of 0.5 to classify each.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Results**\n",
        "\n",
        "| **Metric**                             | **Percentage (%)** |\n",
        "|----------------------------------------|---------------------|\n",
        "| **Correct Predictions for Winners**    | **53.31**           |\n",
        "| **Correct Predictions for Non-Winners**| **68.30**           |\n",
        "\n",
        "---\n",
        "\n",
        "### **Graphical Insights**\n",
        "\n",
        "1. **Left Plot**: Predicted Probabilities for Winners\n",
        "   - The histogram illustrates the density of predicted probabilities for true winners (`is_winner=1`).\n",
        "   - A **vertical dashed line** at the threshold of **0.5** indicates the cutoff for classifying a team as a \"winner.\"\n",
        "   - **53.31%** of true winners are classified correctly (probability > 0.5), while the remaining fall below the threshold, leading to misclassification.\n",
        "\n",
        "2. **Right Plot**: Predicted Probabilities for Non-Winners\n",
        "   - The histogram shows the density of predicted probabilities for true non-winners (`is_winner=0`).\n",
        "   - A **vertical dashed line** at the threshold of **0.5** serves as the cutoff for classifying a team as a \"non-winner.\"\n",
        "   - **68.30%** of true non-winners are correctly classified (probability < 0.5), indicating better performance for this class.\n",
        "\n",
        "---\n",
        "\n",
        "### **Observations**\n",
        "\n",
        "#### **Model Strength**:\n",
        "- The model is more effective at identifying **non-winners**, with a higher percentage of correct predictions (**68.30%**) compared to winners (**53.31%**).\n",
        "\n",
        "#### **Model Weakness**:\n",
        "- The model struggles to accurately classify winners, as a significant proportion of true winners receive probabilities below the threshold of 0.5.\n",
        "\n",
        "---\n",
        "\n",
        "### **Assumptions and Context**\n",
        "\n",
        "#### Why Winner Prediction is Challenging:\n",
        "- **Non-winners are easier to identify**:\n",
        "  - Teams with poor performance indicators are more likely to be classified as non-winners.\n",
        "- **Winners are harder to predict**:\n",
        "  - Factors such as unexpected performance, coaching decisions, and external influences make predicting winners inherently more complex.\n",
        "\n",
        "#### Model Context:\n",
        "- The **53.31% accuracy for winners** may appear low but reflects the realistic difficulty of classifying winners in uncertain conditions.\n",
        "- The model’s ability to separate winners and non-winners is limited, as evident from the overlapping distributions in the histograms.\n",
        "\n",
        "---\n",
        "\n",
        "### **Implications**\n",
        "\n",
        "#### 1. **Threshold Adjustment**:\n",
        "- Modifying the classification threshold lower from **0.5** may help improve the recall for winners, trading off some precision.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        ".\n"
      ],
      "metadata": {
        "id": "GZpDsgvgVXrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.concat([X, y], axis=1)\n",
        "\n",
        "winners=final_data[final_data['is_winner']==1]\n",
        "not_winners=final_data[final_data['is_winner']==0]\n",
        "\n",
        "X_winners = winners.drop('is_winner', axis=1)\n",
        "x_not_winners = not_winners.drop('is_winner', axis=1)\n",
        "\n",
        "# Predict probabilities for winners\n",
        "probabilities_winners_logreg = best_logreg.predict_proba(X_winners)[:, 1]\n",
        "probabilities_non_winners_logreg = best_logreg.predict_proba(x_not_winners)[:, 1]\n",
        "\n",
        "probabilities_winners_and_not_winners = np.concatenate((probabilities_winners_logreg, probabilities_non_winners_logreg))\n",
        "\n",
        "\n",
        "# Calculate the percentage of predictions above 0.45 for winners and below 0.35 for non-winners\n",
        "percentage_correct_winners_logreg = (probabilities_winners_logreg > 0.45).mean() * 100\n",
        "percentage_correct_non_winners_logreg = (probabilities_non_winners_logreg < 0.45).mean() * 100\n",
        "\n",
        "percentage_correct_winners_logreg_standard = (probabilities_winners_logreg > 0.5).mean() * 100\n",
        "percentage_correct_non_winners_logreg_standard = (probabilities_non_winners_logreg < 0.5).mean() * 100\n",
        "\n",
        "# Output the results\n",
        "print(f\"Percentage of correct predictions for winners (prob > 0.45): {percentage_correct_winners_logreg:.2f}%\")\n",
        "print(f\"Percentage of correct predictions for non-winners (prob < 0.45): {percentage_correct_non_winners_logreg:.2f}%\")\n",
        "print(f\"Percentage of correct predictions for winners standard (prob > 0.5): {percentage_correct_winners_logreg_standard:.2f}%\")\n",
        "print(f\"Percentage of correct predictions for non-winners standard (prob < 0.5): {percentage_correct_non_winners_logreg_standard:.2f}%\")\n",
        "\n",
        "# Plotting the distribution of probabilities\n",
        "plt.figure(figsize=(21, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(probabilities_winners_logreg, bins=20, color='green', alpha=0.5, density=True)\n",
        "plt.title('Predicted Probabilities for Winners: Logistic Regression')\n",
        "plt.xlabel('Probability of Being a Winner')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.45, color='black', linestyle='--')\n",
        "plt.annotate(f'{percentage_correct_winners_logreg:.2f}% > 0.45', xy=(0.45, max(plt.gca().get_ylim())*0.95), color='black',horizontalalignment='right')\n",
        "\n",
        "plt.axvline(x=0.5, color='purple', linestyle='-')\n",
        "plt.annotate(f'{percentage_correct_winners_logreg_standard:.2f}% > 0.5', xy=(0.55, max(plt.gca().get_ylim())*0.95), color='purple', horizontalalignment='left')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.hist(probabilities_non_winners_logreg, bins=20, color='red', alpha=0.5, density=True)\n",
        "plt.title('Predicted Probabilities for Non-Winners: Logistic Regression')\n",
        "plt.xlabel('Probability of Being a Winner')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.45, color='black', linestyle='--')\n",
        "plt.annotate(f'{percentage_correct_non_winners_logreg:.2f}% < 0.45', xy=(0.45, max(plt.gca().get_ylim())*0.95), color='black', horizontalalignment='right')\n",
        "\n",
        "plt.axvline(x=0.5, color='purple', linestyle='-')\n",
        "plt.annotate(f'{percentage_correct_non_winners_logreg_standard:.2f}% < 0.5', xy=(0.55, max(plt.gca().get_ylim())*0.95), color='purple', horizontalalignment='left')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(probabilities_winners_and_not_winners, bins=20, color='purple', alpha=0.5, density=True)\n",
        "plt.title('Combined Predicted Probabilities: Logistic Regression')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=0.45, color='black', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "DcFrFvlqE-DX",
        "outputId": "34c5f468-49b3-420f-bb34-8adaecbdfa27"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of correct predictions for winners (prob > 0.45): 67.78%\n",
            "Percentage of correct predictions for non-winners (prob < 0.45): 52.10%\n",
            "Percentage of correct predictions for winners standard (prob > 0.5): 37.51%\n",
            "Percentage of correct predictions for non-winners standard (prob < 0.5): 80.78%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2100x600 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAJOCAYAAAB7+nR7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADID0lEQVR4nOzdd3gU5drH8V+ym16oCaGEAKF3BOkQmnQEpEhRqggCAhZ8jUeFCJIDiKKgFEXgiIgUQVQQRIrSuwIC0nvvSUif9w9O9rBkEzYQdon5fq4rV2Znn525p9/77DPPuBiGYQgAAAAAAAAAAAAAAMABXJ0dAAAAAAAAAAAAAAAAyD5oqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGFoqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKiALKVIkSLq1auX5fXatWvl4uKitWvXOi2me90bo7P16tVLvr6+mTpNFxcXDR48+L7lZs2aJRcXFx0/ftwyrkGDBmrQoIHl9fHjx+Xi4qJZs2bZPe+RI0dmLOCHdOHCBXXs2FF58uSRi4uLJk6c6ND5Z9Tjtg/+0927Tz8stl/mc8Z5A0D2QG6aceSmDy+r5aaPq5EjR8rFxcXZYWQbto6/h8H2y3y9evVSkSJFnB0GgGwsI3miM7/nZ3Y90KNiT+7rbJmdHzyslO8CH3zwQaZNMyVnuXz58n3L2vP9MiPX6+yeL2X29/PHbX/9J8ju+yjuoKEC7JZyIk758/T0VMmSJTV48GBduHDB2eFlyLJly5z+o9Xd69LV1VUFChRQ06ZNH6uKbWd5HLbP3V555RWtWLFC4eHh+uqrr9S8efNHMp+kpCT5+/urbdu2qd776KOP5OLiop49e6Z6791335WLi4v+/vvvRxJXVpFyjtq+fbuzQ7mvjRs3auTIkbp+/fojnU+RIkWszjU+Pj6qXr26/vOf/zzS+QKAI5CbZi5y07Q9Dtvnbo7KTVOk7BcTJkxI9Z6z8q+BAwfK1dVVV69etRp/9epVubq6ysPDQ7GxsVbvHT16VC4uLnrrrbccGepjyd7GPc4WExOjkSNHPvLzUEoFacqfm5ubihQpoiFDhjzyfB0AnOnIkSPq37+/ihUrJk9PT/n7+6tOnTr6+OOPdfv2bWeHl+XdWycTGBioevXqafHixc4OLUMcdT1Oz73Xam9vb5UtW1Zvv/22bt686bS4HgePw/axR5EiRdS6dWtnh2GXMWPGaMmSJY90HvfWZ5jNZhUsWFC9evXSmTNnHum8gceN2dkBIOt57733VLRoUcXGxmr9+vWaMmWKli1bpr1798rb29uhsdSvX1+3b9+Wu7t7hj63bNkyffrpp06vcHzqqafUo0cPGYahY8eO6bPPPlOjRo30008/qUWLFk6NLTM8//zz6tKlizw8PNIsExISotu3b8vNzc0yLr3tc/v2bZnNjj11rV69Wm3bttXrr7/+SOdjMplUs2ZNbdy4MdV7GzZskNls1oYNG2y+FxgYqJIlS0qSDh48KFdX2qE5ysqVKzP8mY0bNyoiIkK9evVSzpw5rd7L7O1XuXJlvfbaa5Kkc+fO6YsvvlDPnj0VFxenfv36Zdp8HmfOOG8AcBxy08xDbkpump7x48frpZdecvhxZUvdunU1ZcoUbdiwQW3atLGM37hxo1xdXZWQkKDt27erbt26lvdS8uiUcW+//bbefPNNxwaejdlz/N0rJiZGERERkpTq7s9Hsf2mTJkiX19fRUdH69dff9WkSZO0c+dOrV+/PlPn87j6/PPPlZyc7OwwADjITz/9pE6dOsnDw0M9evRQ+fLlFR8fr/Xr12v48OHat2+fpk+f7uww05RVvuffXSdz9uxZTZs2Tc8884ymTJmiAQMGODyeB6nDSu967Ggp1+qoqCitXLlS77//vlavXq0NGzb8I+7KtqdO8N7rtaPzpazkQb+fjxkzRh07dlS7du2sxj9IPns/d9dnbN68WbNmzdL69eu1d+9eeXp6Ztp8HlfZfR/FHY//1RyPnRYtWqhatWqSpBdeeEF58uTRhx9+qO+//15du3a1+Zno6Gj5+Phkeiyurq5Z+oRdsmRJPffcc5bX7du3V8WKFTVx4sQ0K4NjY2Pl7u6eJX6INplMMplM6ZZJuQPSXs7Y3hcvXkz1Y/LDSG8b1q1bV7/88ov279+vMmXKWMZv2LBBnTt31ty5c3X+/HkFBQVJkhITE7VlyxY1bdrUUjYzk6VHITExUcnJyRlOEh9Xmb0cmb39ChYsaHWe6dWrl4oVK6aPPvrI4Q0VHtW14H6y8nUCwP2Rm2YeclNy07RUrlxZu3fv1tSpU/Xqq69m2rwfVEpjg/Xr11s1VNiwYYMqVqyo27dva/369VYNFdavXy9XV1fVrl1bkmQ2mx/7HzhiYmIei4YhmcGe4y8jHsX269ixo/LmzStJ6t+/v7p06aJvv/1WW7duVfXq1TN1XulJTk5WfHy8w88vdzfQAvDPduzYMXXp0kUhISFavXq18ufPb3lv0KBBOnz4sH766ScnRnh/WSXnvrdOpkePHipevLg++uijNBsqPMp6s6xeF3f3tXrAgAHq0KGDvvvuO23evFm1atWy+ZmslE/ZUyeYket1Vsh3H6XM/n6e2fmslLo+I2/evBo7dqyWLl2qzp07Z+q80mMYhmJjY+Xl5eWweUrso7jj8a9NwmOvUaNGku4kudL/nid25MgRtWzZUn5+furevbukO1+4J06cqHLlysnT01P58uVT//79de3aNatpGoah0aNHq1ChQvL29lbDhg21b9++VPNO6zlDW7ZsUcuWLZUrVy75+PioYsWK+vjjjy3xffrpp5Ksu7hNkdkxZkSFChWUN29ey7pMWb558+bp7bffVsGCBeXt7W3p0mrBggWqWrWqvLy8lDdvXj333HNpdg109OhRNWvWTD4+PipQoIDee+89GYZhVeaDDz5Q7dq1lSdPHnl5ealq1apauHBhmvF+/fXXKlWqlDw9PVW1alX99ttvVu/b89yme58DfL/tY+sZdGfOnFGfPn2UL18+eXh4qFy5cvryyy9TzWvSpEkqV66cvL29lStXLlWrVk1z585NM7aU+A3D0KeffpoqlqNHj6pTp07KnTu3vL29VbNmzVRf5O63De+VUpl6d88JR48e1fnz5zV48GB5enpavbd7925FR0dbVcLe+zyzlOXYsGGDXn31VQUEBMjHx0ft27fXpUuXrOaf0g3X+vXrVb16dXl6eqpYsWI2HxVw/fp1DRs2TMHBwfLw8FDx4sU1duxYq1a9dz/bbeLEiQoNDZWHh4f++usvu7fJgQMHdPLkSZvr60Hs2rVLLVq0kL+/v3x9fdW4cWNt3rw5Vbk///xTYWFh8vLyUqFChTR69GjNnDnTruf7pbdcI0eO1PDhwyVJRYsWtexXKdO09Szx69ev65VXXlGRIkXk4eGhQoUKqUePHnY93+5eAQEBKl26tI4cOWI13t5zX3JyskaOHKkCBQpYzn1//fVXmvvdunXrNHDgQAUGBqpQoUKW95cvX6569erJx8dHfn5+atWqVapz6Pnz59W7d28VKlRIHh4eyp8/v9q2bWu1/rdv365mzZopb9688vLyUtGiRdWnTx+r6dg6b9izH2Tk2AHw+CA3JTclN8283DRFnTp11KhRI40bN86urqBXr15tuc7nzJlTbdu21f79+63KpHThe/jwYUsvUzly5FDv3r0VExOT7vQLFy6s4ODgVL2NbdiwQXXq1FHt2rVtvleuXDlLIw9bz0NNeSTCkiVLVL58ecv2+/nnnx8q9jlz5liOjdy5c6tLly46deqUVZkGDRqofPny2rFjh+rXry9vb2/LYyrsyXfOnTunAwcOKCEhId11Z6/o6Gi99tprlly/VKlS+uCDD1Idp7dv39aQIUOUN29e+fn56emnn9aZM2dSHRu2jr/0luv48eMKCAiQJEVERFj295RppvU82zlz5qh69eqW46p+/foPdPeoJNWrV0+SUuXNW7ZsUfPmzZUjRw55e3srLCzMZs93a9euVbVq1eTp6anQ0FBNmzYt3f3u66+/Vrly5eTh4WHZ5zLrfHLr1i0NGzbM8n0iMDBQTz31lHbu3GkpY+uZ1/buB/YeOwAeD+PGjVNUVJRmzJhh1UghRfHixTV06FDL68TERI0aNcpSp1OkSBG99dZbiouLs/pcSp1SyvnPy8tLFSpUsOTG3333nSpUqGDJ1Xbt2mUzPnvyxHuvM4/i2ixJ06dPV2hoqLy8vFS9enX9/vvvaa5XewQFBalMmTKW/Pp+9WYHDhxQx44dlTt3bnl6eqpatWpaunRpqunu27dPjRo1sqrDstVLjq06rNjYWI0cOVIlS5aUp6en8ufPr2eeeUZHjhy57/X4UcSYEfd+90svn7p48aL69u2rfPnyydPTU5UqVdLs2bPTnPZHH32kkJAQeXl5KSwsTHv37rV6/88//7TcDOTp6amgoCD16dNHV65csTm9y5cvq3PnzvL391eePHk0dOjQVI8qs1UneK+7r9cPky/db/8/dOiQOnTooKCgIHl6eqpQoULq0qWLbty4YbVMBw4cuG/ubi97zzX21k3a+n5+v+VycXFRdHS0Zs+ebVmfKdNM6/vk8uXLFRYWJj8/P/n7++vJJ59M93tdetLKP+09zuytz045X69YscJyvp42bZok++r8JWnevHmqWrWqZbkrVKhgqeeQpISEBEVERKhEiRLy9PRUnjx5LDdpprC1j2b0mmPP7xh4vNFUBQ8t5aSZJ08ey7jExEQ1a9ZMdevW1QcffGBptdi/f3/NmjVLvXv31pAhQ3Ts2DFNnjxZu3bt0oYNGywtAt99912NHj1aLVu2VMuWLbVz5041bdpU8fHx943nl19+UevWrZU/f34NHTpUQUFB2r9/v3788UcNHTpU/fv319mzZ/XLL7/oq6++SvV5R8SYlmvXrunatWsqXry41fhRo0bJ3d1dr7/+uuLi4uTu7m6J8cknn1RkZKQuXLigjz/+WBs2bNCuXbus7rJKSkpS8+bNVbNmTY0bN04///yzRowYocTERL333nuWch9//LGefvppde/eXfHx8Zo3b546deqkH3/8Ua1atbKKad26dfr22281ZMgQeXh46LPPPlPz5s21detWlS9f/oHXwf22z70uXLigmjVrWipGAgICtHz5cvXt21c3b97UsGHDJN3pFmvIkCHq2LGjJRH8888/tWXLFnXr1s3mtOvXr6+vvvpKzz//vKUr5LvnW7t2bcXExGjIkCHKkyePZs+eraeffloLFy5U+/btraZlaxvaUrNmTZnNZq1fv14vvPCCpDuVqj4+PnryySdVrVo1bdiwQR06dLC8J8mqoUJaXn75ZeXKlUsjRozQ8ePHNXHiRA0ePFjffvutVbnDhw+rY8eO6tu3r3r27Kkvv/xSvXr1UtWqVVWuXDlJd1ojh4WF6cyZM+rfv78KFy6sjRs3Kjw8XOfOndPEiROtpjlz5kzFxsbqxRdflIeHh3Lnzm33NilTpozCwsIy5Vlr+/btU7169eTv76833nhDbm5umjZtmho0aKB169apRo0aku5UCDZs2FAuLi4KDw+Xj4+PvvjiC7taNt9vuZ555hn9/fff+uabb/TRRx9ZWoKnfLG4V1RUlOrVq6f9+/erT58+euKJJ3T58mUtXbpUp0+ftnzeXomJiTp9+rRy5cplNd7ec194eLjGjRunNm3aqFmzZvrjjz/UrFmzVF+uUgwcOFABAQF69913FR0dLUn66quv1LNnTzVr1kxjx45VTEyMpkyZorp162rXrl2WL1wdOnTQvn379PLLL6tIkSK6ePGifvnlF508edLyumnTpgoICNCbb76pnDlz6vjx4/ruu+/SXQf27gcp7D12ADweyE3JTclNMy83vdvIkSNVv359TZkyJd1eFVatWqUWLVqoWLFiGjlypG7fvq1JkyapTp062rlzZ6ofQjt37qyiRYsqMjJSO3fu1BdffKHAwECNHTs23Xjq1q2r7777TnFxcfLw8FB8fLy2bduml156STExMXrjjTdkGIZcXFx07do1/fXXX3Z1sbx+/Xp99913GjhwoPz8/PTJJ5+oQ4cOOnnypNV5xd7Y33//fb3zzjvq3LmzXnjhBV26dEmTJk1S/fr1Ux0bV65cUYsWLdSlSxc999xzypcvn935Tnh4uGbPnq1jx46lWscZZRiGnn76aa1Zs0Z9+/ZV5cqVtWLFCg0fPlxnzpzRRx99ZCnbq1cvzZ8/X88//7xq1qypdevWpTo+bbnfcgUEBGjKlCl66aWX1L59ez3zzDOSpIoVK6Y5zYiICI0cOVK1a9fWe++9J3d3d23ZskWrV6+26oHOXimVuXfnzatXr1aLFi1UtWpVjRgxQq6urpo5c6YaNWqk33//3dLzwq5du9S8eXPlz59fERERSkpK0nvvvZdmzr969WrNnz9fgwcPVt68eVWkSJFMPZ8MGDBACxcu1ODBg1W2bFlduXJF69ev1/79+/XEE0/YjCkj+4GUsWMHgHP98MMPKlasmKWXoft54YUXNHv2bHXs2FGvvfaatmzZosjISO3fv1+LFy+2Knv48GF169ZN/fv313PPPacPPvhAbdq00dSpU/XWW29p4MCBkqTIyEh17tw5VVf39uaJacnMa/OMGTPUv39/1a5dW8OGDdPRo0f19NNPK3fu3AoODrZr3d0rISFBp06dSnVetFVvtm/fPtWpU0cFCxbUm2++KR8fH82fP1/t2rXTokWLLPnd+fPn1bBhQyUmJlrKTZ8+3a47o5OSktS6dWv9+uuv6tKli4YOHapbt27pl19+0d69e9WkSZN0r8eOiDE9tr772cqnbt++rQYNGujw4cMaPHiwihYtqgULFqhXr166fv26VcMcSfrPf/6jW7duadCgQYqNjdXHH3+sRo0aac+ePcqXL5+kO9/zjh49qt69eysoKMjyuJR9+/Zp8+bNqX587dy5s4oUKaLIyEht3rxZn3zyia5du/ZQP6o+SL5kz/4fHx+vZs2aKS4uTi+//LKCgoJ05swZ/fjjj7p+/bpy5MghSZo8ebIiIiK0Zs2aTHksiL3nmozWTaawZ7m++uorvfDCC6pevbpefPFFSVJoaGia05w1a5b69OmjcuXKKTw8XDlz5tSuXbv0888/p/m9Lj228k97j7OM1mcfPHhQXbt2Vf/+/dWvXz+VKlXK7jr/X375RV27dlXjxo0t59f9+/drw4YNluNp5MiRioyMtKzPmzdvavv27dq5c6eeeuqpNNdBRq859/sdA1mAAdhp5syZhiRj1apVxqVLl4xTp04Z8+bNM/LkyWN4eXkZp0+fNgzDMHr27GlIMt58802rz//++++GJOPrr7+2Gv/zzz9bjb948aLh7u5utGrVykhOTraUe+uttwxJRs+ePS3j1qxZY0gy1qxZYxiGYSQmJhpFixY1QkJCjGvXrlnN5+5pDRo0yLC1+z+KGNMiyejbt69x6dIl4+LFi8aWLVuMxo0bG5KMCRMmWC1fsWLFjJiYGMtn4+PjjcDAQKN8+fLG7du3LeN//PFHQ5Lx7rvvWsalbI+XX37Zal20atXKcHd3Ny5dumQZf/c8UuZTvnx5o1GjRqlil2Rs377dMu7EiROGp6en0b59e8u4lH3m2LFjlnFhYWFGWFiY5fWxY8cMScbMmTMt49LaPinzHjFihOV13759jfz58xuXL1+2KtelSxcjR44clmVq27atUa5cOZvTvB9JxqBBg6zGDRs2zJBk/P7775Zxt27dMooWLWoUKVLESEpKMgwj7W2YnieffNIIDQ21vO7fv7/RsGFDwzAM44033jCefPJJy3sdO3Y0vL29jYSEBMu4kJAQq30wZTs0adLEan995ZVXDJPJZFy/ft3qs5KM3377zTLu4sWLhoeHh/Haa69Zxo0aNcrw8fEx/v77b6vY33zzTcNkMhknT540DON/29ff39+4ePGiVVl7t4kkq30mLSnLuW3btjTLtGvXznB3dzeOHDliGXf27FnDz8/PqF+/vmXcyy+/bLi4uBi7du2yjLty5YqRO3fu++7T9izX+PHjU00nxb3b79133zUkGd99912qsndvT1tCQkKMpk2bGpcuXTIuXbpk7Nmzx3j++edT7dP2nvvOnz9vmM1mo127dlblRo4cmercl7I96tatayQmJlrG37p1y8iZM6fRr18/q2mcP3/eyJEjh2X8tWvXDEnG+PHj01y+xYsX33ebG0bq84a9+0FGjh0AjkduSm56d+zkpo8uN717fg0bNjSCgoIsn7WVf1WuXNkIDAw0rly5Yhn3xx9/GK6urkaPHj0s40aMGGFIMvr06WM1v/bt2xt58uS5b1yffvqp1TJv2rTJkGScOHHC+OuvvwxJxr59+wzD+N++ePexlDL/e5fV3d3dOHz4sFXskoxJkyZlOPbjx48bJpPJeP/9963K7dmzxzCbzVbjw8LCDEnG1KlTrcram++kHFu28st72dqH7rZkyRJDkjF69Gir8R07djRcXFws62fHjh2GJGPYsGFW5Xr16pXq2Lj3+LNnuS5dupRqOinu3X6HDh0yXF1djfbt21v29xT3y5lTpnXw4EHj0qVLxvHjx40vv/zS8PLyMgICAozo6GjLdEqUKGE0a9bMapoxMTFG0aJFjaeeesoyrk2bNoa3t7dx5swZqxjNZrPN/c7V1dWyv6bIzPNJjhw50t3mhnFnHwoJCbG8tnc/SFkGe44dAM5348YNQ5LRtm1bu8rv3r3bkGS88MILVuNff/11Q5KxevVqy7iUOqWNGzdaxq1YscKQZHh5eRknTpywjJ82bZpV3mwYGcsT770+ZPa1OSW/rVy5shEXF2cpN336dLvrqe6tk/njjz+MLl26WC1jevVmjRs3NipUqGDExsZarY/atWsbJUqUsIxLyQO3bNliGXfx4kUjR44c9819v/zyS0OS8eGHH6aKP+Val971+FHEaMu91+pjx44Z06ZNMzw8PIx8+fJZrtVp5VMTJ040JBlz5syxjIuPjzdq1apl+Pr6Gjdv3jQM43/b4+7vk4ZhGFu2bDEkGa+88oplnK1c+ptvvklVr5oS+9NPP21VduDAgYYk448//rCMu7dO8N7vl4aR+nqdkXzJ3v1/165dhiRjwYIFqaZpa/p3x5eWkJAQo1WrVmm+b++5JiN1k/euP3uXy8fHx+Z36Hvz2evXrxt+fn5GjRo1rL4HG8b9809b9RkLFy40AgICDA8PD+PUqVOWsvYeZxmpz045X//8889Wcdlb5z906FDD39/fqs73XpUqVUp3mxtG6n30Qa459/sdA48/Hv2ADGvSpIkCAgIUHBysLl26yNfXV4sXL1bBggWtyr300ktWrxcsWKAcOXLoqaee0uXLly1/VatWla+vr9asWSPpzh048fHxevnll61aHqbcLZCeXbt26dixYxo2bFiq57ba6uboXo6I8W4zZsxQQECAAgMDVaNGDUv34vdOp2fPnlYtTLdv366LFy9q4MCBVs9ZatWqlUqXLm3zOXKDBw+2DKfckREfH69Vq1ZZxt89j2vXrunGjRuqV6+eVXeQKWrVqqWqVataXhcuXFht27bVihUrlJSUlKH18KAMw9CiRYvUpk0bGYZhtc2aNWumGzduWGLPmTOnTp8+rW3btmXKvJctW6bq1atb9WTg6+urF198UcePH7d00Zbi3m2Ynrp16+rIkSM6f/68pDu9JqS0cq9Tp4527dpl6VJrw4YNqlGjhl3PcnrxxRet9td69eopKSlJJ06csCpXtmxZSzdT0p3WuaVKldLRo0ct4xYsWKB69eopV65cVuu9SZMmSkpKStXVcocOHVLdPWTvNjEMI1N6U0hKStLKlSvVrl07FStWzDI+f/786tatm9avX2/p9vjnn39WrVq1VLlyZUu53LlzW7oKT09m72uLFi1SpUqVUt0JKdl3Xlu5cqUCAgIUEBCgChUq6KuvvlLv3r01fvx4Sxl7z32//vqrEhMTLXdApHj55ZfTnH+/fv2snt/2yy+/6Pr16+ratavVvEwmk2rUqGGZl5eXl9zd3bV27dpU3ZunSDnP//jjj3Z3c5yR/SCFvccOAOcgNyU3lchNH2VuereRI0fq/Pnzmjp1qs33z507p927d6tXr17KnTu3ZXzFihX11FNPadmyZak+c28vB/Xq1dOVK1fu+ziKlGVdv369pDt5ccGCBVW4cGGVLl1auXPntvQ+lpFeyJo0aWJ111TFihXl7+9vlQvbG/t3332n5ORkde7c2Wp/CAoKUokSJSzHcAoPDw/17t3bapy9+c6sWbNkGMZD96Yg3dmfTCaThgwZYjX+tddek2EYWr58uSRZuvXPSG6Y4kHyuPQsWbJEycnJevfdd63uzJXsO99KUqlSpRQQEKAiRYqoT58+Kl68uJYvX27phWf37t06dOiQunXrpitXrli2Z3R0tBo3bqzffvtNycnJSkpK0qpVq9SuXTsVKFDAMv3ixYurRYsWNucdFhamsmXLWl5n9vkkZ86c2rJli86ePWvXupDs3w9SZOTYAeA8KdcoPz8/u8qnXLvv7U3ptddek6RUeV7ZsmVVq1Yty+uUHgsbNWqkwoULpxpv6xxhT56Ylsy6NqfktwMGDLDqeapXr16Wu8ntcXedTKVKlbRgwQI9//zzqXqOurfe7OrVq1q9erU6d+6sW7duWeK8cuWKmjVrpkOHDlkesbZs2TLVrFnT0quPdKcuz546rEWLFilv3rw2r933u346Ksa7pVyrixYtqv79+6t48eL66aefLNdqyXY+tWzZMgUFBalr166WcW5ubhoyZIiioqK0bt06q/Lt2rWz+j5ZvXp11ahRwyqXvTuXjo2N1eXLl1WzZk1Jsvl9ZdCgQVavU9a5rfz4UbF3/0/Zx1esWJHuYx1GjhwpwzAypTcFe881D1I3mcLe5bLXL7/8olu3bunNN9+0+h4s2Z9/3l2f0bFjR/n4+Gjp0qWWx+dm5DjLaH120aJF1axZM6tx9tb558yZU9HR0VaPcbhXzpw5tW/fPh06dMiudSE92DXnfr9j4PHHox+QYZ9++qlKliwps9msfPnyqVSpUqkqAsxms9WzyKU7z/+5ceOGAgMDbU734sWLkmT54adEiRJW7wcEBKTqqvxeKd09PWj3ro6I8W5t27bV4MGD5eLiIj8/P5UrV04+Pj6pyhUtWtTqdcr8S5Uqlaps6dKlLZV1KVxdXa1+kJOkkiVLSpLVs4l+/PFHjR49Wrt377Z65o+tC+u9y54yzZiYGF26dElBQUGp3s9sly5d0vXr1zV9+nRNnz7dZpmUbfZ///d/WrVqlapXr67ixYuradOm6tatm+rUqfNA8z5x4kSq7uGlO48pSHn/7v3w3m2Ynrp16+qjjz7Shg0b1LhxY+3bt0/jxo2TJNWuXVuJiYnaunWrQkJCdO7cOcsjIu7n7i+E0v+6kLr3R+B7y6WUvbvcoUOH9Oeff6bZdWnKek9ha/kze5vcz6VLlxQTE2PzuClTpoySk5N16tQplStXTidOnLD6Yp3i3q6vbcns5Tpy5IjlUR8PokaNGho9erSSkpK0d+9ejR49WteuXbP6op3Rc9+96yF37txpnvvu3fYpyWnKcwTv5e/vL+nOF8uxY8fqtddeU758+VSzZk21bt1aPXr0sJxfwsLC1KFDB0VEROijjz5SgwYN1K5dO3Xr1i3Nbs0ysh+ksPfYAeAc5KbkphK56aPMTe9Wv359NWzYUOPGjbP5GIX09oUyZcpoxYoVio6Ottqv0rvO+vv76+rVq1aPMPHy8lKOHDlUvnx55cyZ06oxQsr6c3FxUa1atbRhwwb169dPGzZsUHBwsM0891725ML2xn7o0CEZhmFz/5RkeXRLioIFC6Z6DMeD5DsP68SJEypQoECqH7Hu3p9S/ru6uqban+zJmTN7uY4cOSJXV1erH/szatGiRfL399elS5f0ySef6NixY1Y/QqTksT179kxzGjdu3FBsbKxu375tcz2ktW7uXYeZfT4ZN26cevbsqeDgYFWtWlUtW7ZUjx49Up2L72bvfpAiI8cOAOdJ+c5969Ytu8qnnOvvPX8FBQUpZ86c9z0XpPwweO+jElLG33uOsDdPTEtmXZvTyq/d3NzSPXfeK6VOxsXFRd7e3ipTpkyqBsxS6uvA4cOHZRiG3nnnHb3zzjs2p33x4kUVLFgwzTzQVj52ryNHjqhUqVJ23QB1L0fFeLeUa7Wbm5sKFSpks0t+W/nUiRMnVKJEiVTfE9O6pqX13WL+/PmW11evXlVERITmzZuXqh70xo0bqT5/7zRDQ0Pl6upq136dWezd/4sWLapXX31VH374ob7++mvVq1dPTz/9tJ577rkMNdTJCHvPNQ9SN5kis5frYb/vS/+rz7hx44a+/PJL/fbbb1a5cEaPs4zUZ9v6Tmhvnf/AgQM1f/58tWjRQgULFlTTpk3VuXNnNW/e3FL2vffeU9u2bVWyZEmVL19ezZs31/PPP5/uo0ke9pojkX9mRTRUQIZVr15d1apVS7eMh4dHqgt/cnKyAgMD9fXXX9v8TFonP0dydIyFChVSkyZN7lvuYZ/XZY/ff/9dTz/9tOrXr6/PPvtM+fPnl5ubm2bOnKm5c+c+8vk/iOTkZEnSc889l2ZlUcqFr0yZMjp48KB+/PFH/fzzz1q0aJE+++wzvfvuu4qIiHjksWZkG959d1hKi+CUJCNv3rwqUaKE1q9fr1OnTlmVv5+772q/m2EYGS6XnJysp556Sm+88YbNsilfIlPYWn5nb5NH5XFbrrx581rOM82aNVPp0qXVunVrffzxx5bWqY/y3Hfvtk85br/66iubPxrd/eV42LBhatOmjZYsWaIVK1bonXfeUWRkpFavXq0qVarIxcVFCxcu1ObNm/XDDz9oxYoV6tOnjyZMmKDNmzfL19f3geO+m73HDgDnIDfNPOSmD+efmpvea8SIEWrQoIGmTZtms6I9o+53nX3mmWes7nLr2bOnZs2aJVdXV9WqVUsbN26UYRjasGGD3nrrLUu52rVr68svv1R8fLy2bdumdu3aZUo8GSmbnJwsFxcXLV++3GbZe3MVW9vFUfmOoz2Oy1W/fn3lzZtXktSmTRtVqFBB3bt3144dO+Tq6mo5xsePH291p9rdfH197/t8ZFvSypkz63zSuXNn1atXT4sXL9bKlSs1fvx4jR07Vt99912avTxkFDkzkDX4+/urQIEC2rt3b4Y+Z+/dwWmdCxx1jsjsa/PDurtOJj1pXQdef/31VHc8p7CnYeCj5IwY775Wp8UR31WkO9fWjRs3avjw4apcubJ8fX2VnJys5s2bW9ZNeuw9pjJTRvb/CRMmqFevXvr++++1cuVKDRkyRJGRkdq8eXOqmwAy06NeL85arrTcXZ/Rrl071a1bV926ddPBgwct+5T0aI4zW8eKvXX+gYGB2r17t1asWKHly5dr+fLlmjlzpnr06KHZs2dLunO8HjlyxLKuv/jiC3300UeaOnXqfW+8fNhrDvln1kJDBThMaGioVq1apTp16qSbMISEhEi603rr7haqly5dum9LqJRWlHv37k03CUzrROeIGDNDyvwPHjyY6q7kgwcPWt5PkZycrKNHj1r9ePz3339LkqVr0EWLFsnT01MrVqywarU3c+ZMmzHY6rLn77//lre390NXmtt7IQoICJCfn5+SkpLsSvp9fHz07LPP6tlnn1V8fLyeeeYZvf/++woPD0/VPdP9hISE6ODBg6nGHzhwwPL+gwoMDLQ0RvDx8VHZsmWtKoFr166tDRs26PTp0zKZTDZbSj5qoaGhioqKsmu9pyczt8n9BAQEyNvbO83t5urqamnhHxISosOHD6cqZ2ucLfdbrowk3aGhoRmuQEhPq1atFBYWpjFjxqh///7y8fHJ8Lnv8OHDVq1ur1y5Yve5L+U8HRgYaNf+Exoaqtdee02vvfaaDh06pMqVK2vChAmaM2eOpUzNmjVVs2ZNvf/++5o7d666d++uefPm2Ux6M7IfAPhnIzfNPOSmd/xTc9N7hYWFqUGDBho7dqzefffdVHFISjOWvHnz2uylIz0TJkyw2o/v7kq/bt26Wr58uZYuXaqLFy9a3UFeu3Zt/etf/9KyZct0+/Ztuxv3ZqbQ0FAZhqGiRYumasibURnJdx5WSEiIVq1apVu3blndTX/v/hQSEqLk5GQdO3bM6s48e3NmKf3lymjOnJycrL/++ivNRgQZ4evrqxEjRqh3796aP3++unTpYjmn+/v7p3uMBwYGytPT86G+TzyK80n+/Pk1cOBADRw4UBcvXtQTTzyh999/P82GCvbuBwCyntatW2v69OnatGnTfeuUUs71hw4dstx9LkkXLlzQ9evXM/1cYE+e+DDsvTbfnV/fnd8mJCTo2LFjqlSp0kPHkp6UnN7Nze2+14GQkBCbubCtfOxeoaGh2rJlixISElL19JQireuxo2LMDCEhIfrzzz+VnJxs1YA9rWtaWt8tUvbBa9eu6ddff1VERIRVPpxeF/eHDh2yqks7fPiwkpOTH3q/zmi+lJHctEKFCqpQoYLefvttbdy4UXXq1NHUqVM1evTohwnZJnvPNZlRN3m/5bJ3nd79fT8zGuWYTCZFRkaqYcOGmjx5st58880MH2cPk39KGavzd3d3V5s2bdSmTRslJydr4MCBmjZtmt555x3L+sidO7d69+6t3r17KyoqSvXr19fIkSPT/A7j6GsOHg+u9y8CZI7OnTsrKSlJo0aNSvVeYmKirl+/LunOc3nc3Nw0adIkq5ZPEydOvO88nnjiCRUtWlQTJ060TC/F3dNKqRy7t4wjYswM1apVU2BgoKZOnWrVDe7y5cu1f/9+tWrVKtVnJk+ebBk2DEOTJ0+Wm5ubGjduLOnOhdDFxcXqGb7Hjx/XkiVLbMawadMmq+dtnTp1St9//72aNm2aZks2e6W1fe5lMpnUoUMHLVq0yOYPuZcuXbIMX7lyxeo9d3d3lS1bVoZhPNAzUVu2bKmtW7dq06ZNlnHR0dGaPn26ihQp8lBdjkp3Kl13796tlStXqnbt2lbv1a5dW5s2bdLvv/+uihUr2v1cwczUuXNnbdq0SStWrEj13vXr15WYmHjfadi7TQ4cOKCTJ08+dMwmk0lNmzbV999/b9Wt2oULFzR37lzVrVvX0gVis2bNtGnTJu3evdtS7urVq2ne0Xo3e5bL3n1cuvOcwj/++EOLFy9O9d6Dtg79v//7P125ckWff/65JPvPfY0bN5bZbNaUKVOsytx9frmfZs2ayd/fX2PGjLF57KUctzExManuRgsNDZWfn5/lvHft2rVU6yClYvruc+PdMrIfAPhnIzfNPOSmssT8T81N7zVy5EidP38+VZf0+fPnV+XKlTV79myr9bV3716tXLlSLVu2zPC8qlatqiZNmlj+7l6WlMYHY8eOlbe3t9UP1NWrV5fZbLY8Qs0ZDRWeeeYZmUwmRUREpMpZDMNItR/YYm++c+7cOR04cOCB9p97tWzZUklJSalyvI8++kguLi6WH7ZT7ur67LPPrMpNmjTpvvOwZ7lSepezJ2du166dXF1d9d5776W6i/FBc+bu3burUKFClueIV61aVaGhofrggw8UFRWVqnzKMW4ymdSkSRMtWbJEZ8+etbx/+PBhLV++3K55Z+b5JCkpKVUX1IGBgSpQoECaObNk/34AIOt544035OPjoxdeeEEXLlxI9f6RI0f08ccfS5Ll2n1vXvnhhx9Kks0872HdL098GPZem6tVq6aAgABNnTrV6hFUs2bNsuu69LACAwMtPVidO3cu1ft3XwdatmypzZs3a+vWrVbv21OH1aFDB12+fNlmvU7K+knreuyoGDNDy5Ytdf78eX377beWcYmJiZo0aZJ8fX0VFhZmVX7JkiU6c+aM5fXWrVu1ZcsWy7Uv5fvFvftQet+/Pv30U6vXKfnSw15PM5Iv2bv/37x5M1XdboUKFeTq6mqVO1y+fFkHDhxQTEzMQy2DZP+55mHqJu1dLh8fH7vWZ9OmTeXn56fIyMhUdZgPmn82aNBA1atX18SJExUbG5uh4+xh6rNT2Fvnf2/+6erqauntK2Vd3lvG19dXxYsXv2/+KTn2mgPno0cFOExYWJj69++vyMhI7d69W02bNpWbm5sOHTqkBQsW6OOPP1bHjh0VEBCg119/XZGRkWrdurVatmypXbt2afny5fft2snV1VVTpkxRmzZtVLlyZfXu3Vv58+fXgQMHtG/fPssJtmrVqpKkIUOGqFmzZjKZTOrSpYtDYswMbm5uGjt2rHr37q2wsDB17dpVFy5c0Mcff6wiRYrolVdesSrv6empn3/+WT179lSNGjW0fPly/fTTT3rrrbcsd5i1atVKH374oZo3b65u3brp4sWL+vTTT1W8eHH9+eefqWIoX768mjVrpiFDhsjDw8NSOZUZXdWmtX1s+fe//601a9aoRo0a6tevn8qWLaurV69q586dWrVqla5evSrpTuIQFBSkOnXqKF++fNq/f78mT56sVq1aPdAP/W+++aa++eYbtWjRQkOGDFHu3Lk1e/ZsHTt2TIsWLUrVvXRG1a1bVzNnztS2bds0aNAgq/dq166tGzdu6MaNG3r55Zcfaj4Pavjw4Vq6dKlat26tXr16qWrVqoqOjtaePXu0cOFCHT9+/L7Hgr3bpEyZMgoLC9PatWvtiu3LL7/Uzz//nGr80KFDNXr0aP3yyy+qW7euBg4cKLPZrGnTpikuLs5SiS3d+dI+Z84cPfXUU3r55Zfl4+OjL774QoULF9bVq1fTbVlrz3Kl7OP/+te/1KVLF7m5ualNmzY27zAcPny4Fi5cqE6dOqlPnz6qWrWqrl69qqVLl2rq1KkP1Iq/RYsWKl++vD788EMNGjTI7nNfvnz5NHToUE2YMEFPP/20mjdvrj/++MNy7rOnxbG/v7+mTJmi559/Xk888YS6dOmigIAAnTx5Uj/99JPq1KmjyZMn6++//1bjxo3VuXNnlS1bVmazWYsXL9aFCxcs54PZs2frs88+U/v27RUaGqpbt27p888/l7+/f7o/hNi7HwD4ZyM3zTzkpv/zT81N7xUWFqawsDCrRzKkGD9+vFq0aKFatWqpb9++un37tiZNmqQcOXJo5MiRmRpH9erV5e7urk2bNqlBgwZWj5Dy9vZWpUqVtGnTJuXMmfOhnh37oEJDQzV69GiFh4fr+PHjateunfz8/HTs2DEtXrxYL774ol5//fV0p2FvvhMeHm7Z5vbcmbd9+3abd8M1aNBAbdq0UcOGDfWvf/1Lx48fV6VKlbRy5Up9//33GjZsmOXusapVq6pDhw6aOHGirly5opo1a2rdunWWO1/Tyw3tWS4vLy+VLVtW3377rUqWLKncuXOrfPnyNrdl8eLF9a9//UujRo1SvXr19Mwzz8jDw0Pbtm1TgQIFFBkZed91ci83NzcNHTpUw4cP188//6zmzZvriy++UIsWLVSuXDn17t1bBQsW1JkzZ7RmzRr5+/vrhx9+kHSnMc/KlStVp04dvfTSS5Yf/MuXL29VeZyezDqfXL9+XYUKFVLHjh1VqVIl+fr6atWqVdq2bZsmTJiQ5vzt3Q8AZD2hoaGaO3eunn32WZUpU0Y9evRQ+fLlFR8fr40bN2rBggXq1auXJKlSpUrq2bOnpk+fruvXryssLExbt27V7Nmz1a5dOzVs2DBTY7MnT3wY9l6b3dzcNHr0aPXv31+NGjXSs88+q2PHjmnmzJlWPZg9Sp9++qnq1q2rChUqqF+/fipWrJguXLigTZs26fTp0/rjjz8k3anD+uqrr9S8eXMNHTpUPj4+mj59uqUXgfT06NFD//nPf/Tqq69q69atqlevnqKjo7Vq1SoNHDhQbdu2Tfd67IgYM8OLL76oadOmqVevXtqxY4eKFCmihQsXasOGDZo4cWKq/Lt48eKqW7euXnrpJcXFxWnixInKkyePpTt8f39/1a9fX+PGjVNCQoIKFiyolStX6tixY2nGcOzYMUtd2qZNmzRnzhx169btoXvnyEi+ZO/+v3r1ag0ePFidOnVSyZIllZiYqK+++srSkDLF5MmTFRERoTVr1qhBgwb3jfXw4cM2888qVaqoVatWdp1rHqZu0t7lqlq1qlatWqUPP/xQBQoUUNGiRVWjRo1U0/P399dHH32kF154QU8++aS6deumXLly6Y8//lBMTIzlEQgZNXz4cHXq1EmzZs3SgAEDMnScPWh99t3ztqfO/4UXXtDVq1fVqFEjFSpUSCdOnNCkSZNUuXJlS08IZcuWVYMGDVS1alXlzp1b27dv18KFCzV48OA05+/oaw4eEwZgp5kzZxqSjG3btqVbrmfPnoaPj0+a70+fPt2oWrWq4eXlZfj5+RkVKlQw3njjDePs2bOWMklJSUZERISRP39+w8vLy2jQoIGxd+9eIyQkxOjZs6el3Jo1awxJxpo1a6zmsX79euOpp54y/Pz8DB8fH6NixYrGpEmTLO8nJiYaL7/8shEQEGC4uLgY9x4KmRljWiQZgwYNSrdMyvItWLDA5vvffvutUaVKFcPDw8PInTu30b17d+P06dNWZVK2x5EjR4ymTZsa3t7eRr58+YwRI0YYSUlJVmVnzJhhlChRwvDw8DBKly5tzJw50xgxYkSq9ZMS+5w5cyzlq1Spkmo7pOwzx44ds4wLCwszwsLCLK+PHTtmSDJmzpxpGZfe9pFkjBgxwmo+Fy5cMAYNGmQEBwcbbm5uRlBQkNG4cWNj+vTpljLTpk0z6tevb+TJk8fw8PAwQkNDjeHDhxs3btywuW5tLe+9jhw5YnTs2NHImTOn4enpaVSvXt348ccfrcrcbxum5eDBg4YkQ5Lx999/W72XnJxs5MyZ05BkfPvtt6k+e+8+mNaxa+v4CQkJMVq1apVqmvduN8MwjFu3bhnh4eFG8eLFDXd3dyNv3rxG7dq1jQ8++MCIj483DON/23f8+PGppmnvNpGUat62pCxnWn+nTp0yDMMwdu7caTRr1szw9fU1vL29jYYNGxobN25MNb1du3YZ9erVMzw8PIxChQoZkZGRxieffGJIMs6fP5/murF3uUaNGmUULFjQcHV1tTpObJ1Drly5YgwePNgoWLCg4e7ubhQqVMjo2bOncfny5XTXSVrb0zAMY9asWamOPXvOfYmJicY777xjBAUFGV5eXkajRo2M/fv3G3ny5DEGDBiQanukdc1Ys2aN0axZMyNHjhyGp6enERoaavTq1cvYvn27YRiGcfnyZWPQoEFG6dKlDR8fHyNHjhxGjRo1jPnz51umsXPnTqNr165G4cKFDQ8PDyMwMNBo3bq1ZRopbJ037NkPMnLsAHA8clNy03tjJzd9NLlpWvNLmZat43DVqlVGnTp1DC8vL8Pf399o06aN8ddff1mVSdmWly5dshpvazulp1atWoYk46233kr13pAhQwxJRosWLVK9l96+dK97j6OMxr5o0SKjbt26ho+Pj+Hj42OULl3aGDRokHHw4EFLmbCwMKNcuXKp5m1vvtOzZ0+711t6OfOoUaMMw7iT67/yyitGgQIFDDc3N6NEiRLG+PHjjeTkZKtpRUdHG4MGDTJy585t+Pr6Gu3atbN8l/n3v/+d5rqxd7k2btxoVK1a1XB3d7c63mxtP8MwjC+//NJyHsqVK5cRFhZm/PLLL+muj7S2p2EYxo0bN4wcOXJYnSd27dplPPPMM5bjNyQkxOjcubPx66+/Wn32119/NapUqWK4u7sboaGhxhdffGG89tprhqenZ6rtkdb5NzPOJ3Fxccbw4cONSpUqWa5DlSpVMj777DOrefXs2dMICQmxGmfvfmDvsQPg8fL3338b/fr1M4oUKWK4u7sbfn5+Rp06dYxJkyYZsbGxlnIJCQlGRESEUbRoUcPNzc0IDg42wsPDrcoYRtp1ELbOEbbqizKSJ96bgz2Ka7NhGMZnn31mFC1a1PDw8DCqVatm/PbbbzbryGxJr04mvfVwtyNHjhg9evQwgoKCDDc3N6NgwYJG69atjYULF1qV+/PPP42wsDDD09PTKFiwoDFq1ChjxowZ9819DcMwYmJijH/961+W7RsUFGR07NjROHLkiKVMWtfjRxGjLeldq++WVj5lGHeuqb179zby5s1ruLu7GxUqVLDK+Q3DentMmDDBCA4ONjw8PIx69eoZf/zxh1XZ06dPG+3btzdy5sxp5MiRw+jUqZNx9uzZNPfNv/76y+jYsaPh5+dn5MqVyxg8eLBx+/Ztq2na8/3S1vU6o/nS/fb/o0ePGn369DFCQ0MNT09PI3fu3EbDhg2NVatWWU0nZfr21I+FhISkmX/27dvXMAz7zzX21k3eu/7sXa4DBw4Y9evXN7y8vAxJlm2S1vlk6dKlRu3atS3ffapXr25888036a6P9OozkpKSjNDQUCM0NNRITEw0DMP+48ze+uz0zk/21PkvXLjQaNq0qREYGGi4u7sbhQsXNvr372+cO3fOMp3Ro0cb1atXN3LmzGl4eXkZpUuXNt5//33LNAzD9j76sNcce8/ReHy4GMYD9kECAEA2M2zYME2bNk1RUVEP3Y30P8n169eVK1cujR49Wv/617+cHQ4AAACcaPfu3apSpYrmzJmj7t27Ozucx0q7du20b9++dJ9hDQAAgIyhbjJt1GfjcZe5/T8CAPAPcfv2bavXV65c0VdffaW6detm66Tu3vUi/e+5YfZ08wYAAIB/jrRyQ1dXV9WvX98JET0+7l03hw4d0rJly8iZAQAAHgJ1k2mjPhtZkfn+RQAAyH5q1aqlBg0aqEyZMrpw4YJmzJihmzdv6p133nF2aE717bffatasWWrZsqV8fX21fv16ffPNN2ratKnq1Knj7PAAAADgQOPGjdOOHTvUsGFDmc1mLV++XMuXL9eLL76o4OBgZ4fnVMWKFVOvXr1UrFgxnThxQlOmTJG7u7vl+dYAAADIOOom00Z9NrIiGioAAGBDy5YttXDhQk2fPl0uLi564oknNGPGjGx/Z1jFihVlNps1btw43bx5U/ny5dPQoUM1evRoZ4cGAAAAB6tdu7Z++eUXjRo1SlFRUSpcuLBGjhxJl7uSmjdvrm+++Ubnz5+Xh4eHatWqpTFjxqhEiRLODg0AACDLom4ybdRnIytyMQzDcHYQAAAAAAAAAAAAAAAge3B1dgAAAAAAAAAAAAAAACD7oKECAAAAAAAAAAAAAABwGLOzA3gYycnJOnv2rPz8/OTi4uLscAAAAPAIGIahW7duqUCBAnJ1/ee3syXHBQAAyB7IcwEAAPBPk5EcN0s3VDh79qyCg4OdHQYAAAAc4NSpUypUqJCzw3jkyHEBAACyF/JcAAAA/NPYk+Nm6YYKfn5+ku4sqL+/v5OjAfBPFh0drQIFCki688Xax8fHIfONj47XhAITJEmvnX1N7j7uDpkvADxObt68qeDgYEvu909HjgvgceWsnFgiLwbwz0SeCwCO5cx8FgCyi4zkuFm6oUJKF2H+/v4ktwAeKZPJZBn29/d3XEMFU7w85WmZLxWyALKz7NI9LDkugMeVs3JiibwYwD8beS4AOIYz81kAyG7syXH/+Q8/AwAAAAAAAAAAAAAAjw0aKgAAAAAAAAAAAAAAAIehoQIAAAAAAAAAAAAAAHAYGioAAAAAAAAAAAAAAACHoaECAAAAAAAAAAAAAABwGLOzAwCArMDLy0vHjh2zDAMAAADZDTkxAAAAsjLyWQB4vNBQAQDs4OrqqiJFijg7DAAAAMBpyIkBAACQlZHPAsDjhUc/AAAAAAAAAAAAAAAAh6GhAgDYIT4+XsOHD9fw4cMVHx/v7HAAAAAAhyMnBgAAQFZGPgsAjxcaKgCAHRISEvTBBx/ogw8+UEJCgrPDAQAAAByOnBgAAABZGfksADxeaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHIaGCsBj6syZM3ruueeUJ08eeXl5qUKFCtq+fbvlfRcXF5t/48ePT3OaRYoUsfmZQYMGWcqcP39ezz//vIKCguTj46MnnnhCixYtsrwfFxen559/Xv7+/ipZsqRWrVplNY/x48fr5ZdfzsQ1kbYFCxaodOnS8vT0VIUKFbRs2TK7P7thwwaZzWZVrlzZavzIkSNTrZ/SpUtncuRZz7Yp2zSl4hRF+kcq0j9SM2rN0KHlhyzvXz9+XREuETb/9i3Yl+Z0l/Rakqr8nOZzrMr89v5vmlF7ht73fl//zvnvVNO4ffW2vmnzjcb4jtG0KtN0btc5q/d/GvSTNk7Y+JBrwD5bP92qiUUmarTnaH1R4wud2Xom3fK7Z+1OtfyjPUc7JFYAAB5398vLrl69qpdfflmlSpWSl5eXChcurCFDhujGjRvpTve7775T06ZNlSdPHrm4uGj37t2pysTGxmrQoEHKkyePfH191aFDB124cMFq3m3atJGvr6+qVKmiXbt2WX1+0KBBmjBhwsOtADt9+umnKlKkiDw9PVWjRg1t3brV7s/OmzdPLi4uateundX4Xr16pVr3zZs3z+TIs57kpGStfme1Pi76sd73el+fhH6idaPWyTAMSxnDMLTm3TWakH+C3vd6X/9p8h9dOXQl3elOLDLRZh7906CfLGWizkdp8fOL9UHQBxrjM0bTnpimvxb9ZXk/MS5Ri59frEj/SE0qOUlHVx21mseG8Ru07GX7vy89jH0L9mly6cka7TlaUypM0aFlh9Itf3ztcZvLH3U+yiHxAgAAAACcw+zsAACkdu3aNdWpU0cNGzbU8uXLFRAQoEOHDilXrlyWMufOWf8Yu3z5cvXt21cdOnRIc7rbtm1TUlKS5fXevXv11FNPqVOnTpZxPXr00PXr17V06VLlzZtXc+fOVefOnbV9+3ZVqVJF06dP144dO7Rp0yYtX75c3bp104ULF+Ti4qJjx47p888/t2pQkZZLly7Jz89Pnp6eGVk1Fhs3blTXrl0VGRmp1q1ba+7cuWrXrp127typ8uXLp/vZ69evq0ePHmrcuLFVhXOKcuXKWTXAMJs5VfoX8leTfzdR7hK5JUPaPXu35rWdp/67+iuwXKD8g/312rnXrD6zY/oObRy/USValEh32sWbF1fbmW0tr00eJqv3k+KTVLZTWRWqVUi7Zuy69+P67f3fFHcrTv139te2Kdv0Q78f9OL2FyVJpzef1pktZ9Tikxb3XcZbZ2/JJ9BHruYHa8O399u9WvnqSrWa2kqFahTS5ombNafZHA0+OFg+gT5pfs7D30ODDw7+3wiXB5o9AAD/SOnlZWfPntXZs2f1wQcfqGzZsjpx4oQGDBigs2fPauHChWlOMzo6WnXr1lXnzp3Vr18/m2VeeeUV/fTTT1qwYIFy5MihwYMH65lnntGGDRskSe+//75u3bqlnTt3asqUKerXr58lB968ebO2bNmiTz755KGX/9q1a3Jzc5Ovr6/N97/99lu9+uqrmjp1qmrUqKGJEyeqWbNmOnjwoAIDA9Od9vHjx/X666+rXr16Nt9v3ry5Zs6caXnt4eHx4AvyD7Fh7AZtn7Jd7Wa3U2C5QJ3dflbf9/5enjk8VWNIjTtlxm3Qlk+2qN3sdspVNJfWvLNGc5rN0aC/Bsnsaft7Rb9t/WQk/a+xw8W9F/XVU1+pXKdylnGLeyxW7PVYdV3aVd55vbVn7h4t7LxQ/bb3U/4q+bVj+g6d3XFWfTf11eHlh7Wo2yK9fuF1ubi46Nqxa9r5+U5Ljvww4qPjlRibKO883jbfP7XxlBZ1XaTGkY1VsnVJ7Zm7R/PazVP/nf0VWD79fXLwwcHy8P/ffpZeDg0AAAAAyProUQF4DI0dO1bBwcGaOXOmqlevrqJFi6pp06YKDQ21lAkKCrL6+/7779WwYUMVK1YszekGBARYfebHH39UaGiowsLCLGU2btyol19+WdWrV1exYsX09ttvK2fOnNqxY4ckaf/+/Xr66adVrlw5DRo0SJcuXdLly5clSS+99JLGjh0rf3//+y7jsmXLlD9/fg0YMECbNm3K8Dr6+OOP1bx5cw0fPlxlypTRqFGj9MQTT2jy5Mn3/eyAAQPUrVs31apVy+b7ZrPZaj3lzZs3w/H905RqU0olWpZQnhJ5lKdkHjV+v7Hcfd11evNpSZKryVW+Qb5WfwcWH1DZzmXl7uue7rRNHiarz3nl8rJ6v2FEQ9V6pZbyVchn8/OX919W+S7lladkHlV9saou77+zPyYlJOnHAT+q9dTWcjXd/3K34/Md+rDQh1r5+kpd2JO6Acv9bP5ws57o94Sq9K6igLIBaj21tdy83bTry9SNK6y4yHrd5bP9QwQAANlRenlZ+fLltWjRIrVp00ahoaFq1KiR3n//ff3www9KTExMc5rPP/+83n33XTVp0sTm+zdu3NCMGTP04YcfqlGjRqpatapmzpypjRs3avPmzZLu5MRdunRRyZIl9eKLL2r//v2SpISEBA0YMEBTp06VyWSyOf37SUxM1E8//aROnTopf/78OnLkSJplP/zwQ/Xr10+9e/dW2bJlNXXqVHl7e+vLL79Mdx5JSUnq3r27IiIi0vz+4OHhYbXu7240nV2d2nhKpdqWUslWJZWzSE6V7VhWoU1DLb1oGYahLRO3qP7b9VW6bWnlq5hP7f7TTrfO3tKBJQfSnK5PgI9VPvj3j38rV2guhYSFWM27+svVVbB6QeUqlkv1364vz5yeOrfjTgP2y/svq9TTpRRYLlBPDnpSMZdiFHM5RpL000s/qcnYJlaNADLCMAwdX3dc3/f+XhOCJujk+pNplt3y8RYVb15cdYbXUUCZADUa1Uj5n8ivrZPv39OHT6D1enBxpQUvAAAAAPyT0VABeAwtXbpU1apVU6dOnRQYGKgqVaro888/T7P8hQsX9NNPP6lv3752zyM+Pl5z5sxRnz595OLyvwqg2rVr69tvv9XVq1eVnJysefPmKTY2Vg0aNJAkVapUSevXr9ft27e1YsUK5c+fX3nz5tXXX38tT09PtW/f3q75d+/eXXPmzNG1a9fUqFEjlSpVSmPGjNGpU6fs+vymTZtSVS43a9bsvo0eZs6cqaNHj2rEiBFpljl06JAKFCigYsWKqXv37jp58qS8vLy0d+9e7d27V15eXml+NjtITkrW3nl7lRCdoOBawTbLnN1xVud3n9cTfZ+47/SOrz2u8YHjNbnUZP340o+KuRKToXjyVcqnY6uPKTkxWUdWHFG+incaNGwYt0FFGhRRgWoF7JpO3f+rq+YfN9fl/Zc1/YnpmvbENG35ZIuiL0Xf97NJ8Uk6u+OsijX5X0W/i6uLijUpptObTqf72fioeE0MmaiPgj/SvLbzdHHfRbviBQAgO7CVl6Xnxo0b8vf3f6gesXbs2KGEhASrXLN06dIqXLiwJdesVKmSVq9ercTERK1YsUIVK1aUJI0bN04NGjRQtWrVMjzfPXv26LXXXlOhQoXUo0cPBQQEaM2aNapUqZLN8vHx8dqxY4dVnK6urmrSpMl9c+L33ntPgYGB6X5/WLt2rQIDA1WqVCm99NJLunLlSrbPiYNrB+vYr8d05e87j3I4/8d5nVx/UsVbFJckXT92XVHno6xyQs8cnipUo5BObbLve05SfJL+nPOnqvSpYvU9Lbh2sPZ9u0+3r96WkWxo77y9SoxNVJEGRSTdyYlPrj+phNsJOrLiiHzz+8o7r7f+/PpPmT3NKtO+TIaX99rRa1ozYo0+KfaJ5raaq+SkZD27+FmValMqzc+c2nTKavklKbRZ6H1zYkmaWnmqJuSfoK+e+konN6R/rAMAADyI7J7PAsDjhv7MgcfQ0aNHNWXKFL366qt66623tG3bNg0ZMkTu7u7q2bNnqvKzZ8+Wn5+fnnnmGbvnsWTJEl2/fl29evWyGj9//nw9++yzypMnj8xms7y9vbV48WIVL36n8q1Pnz76888/VbZsWeXNm1fz58/XtWvX9O6772rt2rV6++23NW/ePIWGhurLL79UwYIFbc7fbDarVatWatWqlW7cuKH58+frq6++0rvvvqsGDRqoZ8+e6tixY5oJ4/nz55Uvn/Ud9vny5dP58+fTXOZDhw7pzTff1O+//55m5XWNGjU0a9YslSpVSufOnVNERITq1aunvXv3qly5cjY/k11c2HNBM2rNUGJsotx93fXs4mcVUDbAZtldM3Ypb5m8Cq5tuyFDiuLNi6vMM2WUs2hOXTtyTb++9au+bvG1+m7qa1cvCJJU9826+umln/RJ6CfKWSSnnp7xtK4cuqI/Zv+hvpv66scBP+rIyiMqUK2A2nzeRp45bD9uxOxpVvlny6v8s+UVfTFae+bu0e5Zu7Xy9ZUq0bKEKvWspFJtStl8NETM5RgZSYZ88ll3T+uTz0eXD1xOM/Y8pfKo7Zdtla9iPsXeiNWmDzbpy9pfauC+gfIvdP+eSQAA+CdLLy/z8/NLVf7y5csaNWqUXnzx4bq3P3/+vNzd3ZUzZ06r8Xfnmm+++aZeeuklhYaGqkiRIpoxY4YOHTqk2bNna9OmTRowYIBWrlypatWq6fPPP1eOHDlszuvKlSuaM2eOZs+erX379qlly5b67LPP1Lp1a7m7p98r1eXLl5WUlGQzJz5wIO2799evX68ZM2Zo9+7daZZp3ry5nnnmGRUtWlRHjhzRW2+9pRYtWmjTpk3ZOieu+2Zdxd2M0+TSk+VqclVyUrIavd9IFbvfaagSdT5KkmzmhNHn79/4VZIOLDmg2OuxqtyrstX4TvM7aeGzCzUuzzi5ml3l5u2mZxc/q9zFc0uSqvSpogt/XtBnZT+Td15vdZrfSbHXYrX23bXqubanVr+9Wnvn7VXu0Nx6+sun5V/Qdq4ZHxWvvd/u1R+z/9CpjadUtGFRNXivgco8U0buPunvkynr4N7l983na1k3tvjm91Wrqa1UoFoBJcUlaecXOzW7wWy9sOUF5X8i/33nCQAAYC9XV9dsnc8CwOOGhgrAYyg5OVnVqlXTmDFjJElVqlTR3r17NXXqVJsNFb788kt1795dnp62f4C1ZcaMGWrRooUKFLC+2/ydd97R9evXtWrVKuXNm1dLlixR586d9fvvv6tChQpyc3PTp59+avWZ3r17a8iQIdq1a5eWLFmiP/74Q+PGjdOQIUO0aNGi+8aSI0cO9evXT/369dPWrVvVtWtX9ejRQ35+fmrXrp3dy5SepKQkdevWTRERESpZsmSa5Vq0aGEZrlixomrUqKGQkBDNnz8/Qz1W/BPlLZVXA3YPUOyNWP218C8t6blEvdb1StVYIeF2gvbM3aP679S/7zTLdylvGc5XIZ/yVcynT0I/0fG1x1WscdqPMbmbZw5PdZjbwWrc7Eaz9dT4p7Tn6z26dvSaBh8crB/6/aB1761TswnN7jtNn0Af1RxWUzWH1dSh5Yf0fa/vdfD7g+q/q7+CKgfZFZc9gmsFW/VKEVw7WJ+W+VTbp21Xo1GNMm0+AABkRRnJy27evKlWrVqpbNmyGjly5COPLUeOHJo7d67VuEaNGmn8+PH6+uuvdfToUR08eFD9+vXTe++9pwkTJticzqRJkywNMA4fPqzg4PQbeT6sW7du6fnnn9fnn3+e7uPNunTpYhmuUKGCKlasqNDQUK1du1aNGzd+pDE+zvbN36c9X+9Rh7kdFFAuQOd3n9eKYSvkV8BPlXtWzpR57JqxSyValJBfAevGOKvfWa3Y67F6ftXz8s7rrQNLDmhB5wXq/Xtv5auQTyY3k1p92srqM9/3/l7Vh1TX+V3ndWDJAQ34Y4A2jNugn4f8rM6LOtuc/18L/9IPL/ygwPKBGvDHAAWWC8yU5UpP3lJ5lbfU//bH4NrBunbkmjZ/tFntv7Kvxz4AAAAAQNbDox+Ax1D+/PlVtmxZq3FlypSx2dXt77//roMHD+qFF16we/onTpzQqlWrUn3myJEjmjx5sr788ks1btxYlSpV0ogRI1StWrVUjRNSrFmzRvv27dPgwYO1du1atWzZUj4+PurcubPWrl1rVzyxsbFasGCB2rRpo7p16ypv3rz67LPP0q0EDQoK0oULF6zGXbhwQUFBtn9EvnXrlrZv367BgwfLbDbLbDbrvffe0x9//CGz2azVq1fb/FzOnDlVsmRJHTx4UCNHjtTIkSMVHx9v13L905jcTcpdPLcKVC2gJpFNlK9SPm3+eHOqcn8t/EsJMQmq1MN2N8XpyVUsl7zzeuvq4asPHOeumbvkmdNTpduW1vG1x1W6XWmZ3Ewq26msTqw9Ydc04m7FadfMXZrdaLa+afONAssHqt3sdmn2IOGd11suJhdFX7C+Uy76QrR8g3ztjt3kZlL+Kvl17fA1uz8DAEB2kZKXHT582Gr8rVu31Lx5c/n5+Wnx4sVyc3N7qPkEBQUpPj5e169ftxqfXq45c+ZM5cyZU23bttXatWvVrl07ubm5qVOnTunmxC+++KJGjRql8+fPq1y5curdu7dWr16t5OTk+8aZN29emUymDOXER44c0fHjx9WmTRtLTvyf//xHS5culdls1pEjR2x+rlixYsqbN68OHDiQrXPiX4b/ojpv1lH5LuWVr0I+VXq+kmq+UlPrI9dLkiXvs5UT+gT5pJreva6fuK6jq46qygtVrMZfPXJV2yZv09NfPq1ijYspqFKQGoxooALVCmjbp9tsTuvYmmO6uO+iqg+uruNrj6tEyxJy93FXuc7ldHzt8TRjKNW2lJp91EyuZldNrzpdCzot0MGlB5WUkHTf+KU76+De5Y+6EJWhnFiSClQv8FDfCQA8GmfOnNFzzz2nPHnyyMvLSxUqVND27dudHRYA2C0+Pj5b57MA8LihoQLwGKpTp44OHjxoNe7vv/9WSEhIqrIzZsxQ1apV03x2rS0zZ85UYGCgWrWyvuMmJiZG0p0usO5mMplsVpbGxsZq0KBBmjZtmkwmk5KSkpSQkCBJSkhIUFJS2pVZhmHo999/V79+/RQUFKRXX31V5cuX159//qktW7bopZdestmlb4patWrp119/tRr3yy+/qFatWjbL+/v7a8+ePdq9e7flb8CAASpVqpR2796tGjVq2PxcVFSUjhw5ooCAAEVERCgiIsKyjNmdkWwoKS71Nt41Y5dKPV1KPgH3r4y9183TNxVzJUZ++dPe9umJvhSt3977TS0m3bkD00gyLJWqyQnJSk5Ku9I/OSlZh5Yf0qJui/RBvg+04d8bVLRxUQ09OlQ9fu2hSj0qyeRusvlZk7tJBaoW0NFfj1rGGcmGjv56VIVqFbI7/uSkZF3Yc0G++TNWkQsAQHaQkpflz/+/ruBv3ryppk2byt3dXUuXLs1QD2NpqVq1qtzc3KxyzYMHD+rkyZM2c81Lly7pvffe06RJkyQpQzlxgQIF9Pbbb+vvv//Wzz//LHd3dz3zzDMKCQnRm2++qX379qX5WXd3d1WtWtUqzuTkZP36669p5sSlS5dOlRM//fTTatiwoXbv3p1mjw6nT5/WlStXsn1OnBCTIBdXF6txLiYXGcmGJCln0ZzyDfK1ygnjbsbp9JbTVr1opWX3zN3yCfRRyVbWPcAlxNxZ1/fO29Xkapn33RJjE7Vs0DK1ntba8ogKe3Nir1xeqjmspvrv6q9+W/vJP9hfP7z4gybkn6Blg5fp9JbT6S5DcK1gHfv1mNW4o79kLCeWpAu7yYmBx821a9dUp04dubm5afny5frrr780YcIE5cqVy9mhAYDdEhISsnU+CwCPGx79ADyGXnnlFdWuXVtjxoxR586dtXXrVk2fPl3Tp0+3Knfz5k0tWLAgza5kGzdurPbt22vw4MGWccnJyZo5c6Z69uwps9n6FFC6dGkVL15c/fv31wcffKA8efJoyZIl+uWXX/Tjjz+mmv6oUaPUsmVLValy546fOnXqaPjw4erdu7cmT56sOnXqpLmMc+bMUf/+/dW+fXvNnz9fTZo0SdVAIj1Dhw5VWFiYJkyYoFatWmnevHnavn271ToKDw/XmTNn9J///Eeurq4qX7681TQCAwPl6elpNf71119XmzZtFBISorNnz2rEiBEymUzq1KmT3njjDZuxjFw70u64M+y25KI7FZJjfhsjef13ng0e4TxtWBW+SiValFCOwjkUdytOe+bu0fG1x/Xciuesyl09fFUnfjuh7su625zO5NKT1Tiyscq0L6P4qHitjVirsh3KyjfIV1ePXNWqN1Ypd/HcCm0WavnMjZM3dPvqbd04eUNGkqHzu+88Gzp38dxy97V+Tu6KYStU67ValmfuBtcJ1p9f/anQpqHaMX2HguukXUH8+5jftWnCJpV7tpx6rOqh4NoZ63q55qs1taTnEhWoVkAFqxfU5omblRCdoMq9K1vKLO6xWH4F/dQksokkad1761SoZiHlLp5bsddjtXH8Rt04cUNPvPBEhuYNAMA/UVp5WdeuXSX9r5FCTEyM5syZo5s3b+rmzZuSpICAAJlMdxoYli5dWpGRkWrf/k4X8levXtXJkyd19uxZSbI0EA4KClJQUJBy5Mihvn376tVXX1Xu3Lnl7++vl19+WbVq1VLNmjVTxTls2DC99tprKliwoKQ7OfFXX32lpk2bavr06enmxHerXbu2ateurY8//lhLlizRrFmz9MEHH2jXrl2qUKGCzc+8+uqr6tmzp6pVq6bq1atr4sSJio6OVu/evS1levTooYIFCyoyMjJV7ivd6alCkmV8VFSUIiIi1OHaNQX5+urI1at6Y9UqFc+VS03uvmv2/fcld+tc7KE54LEdD6Nkm5L6/f3flaNwDgWWC9S5Xee0+cPNqtynsiTJxcVFNYbV0O+jf1eeEnmUs2hOrXlnjfwK+Kl0u9KW6fyn8X9Uun1pVR9c3TLOSDa0e+ZuVepZSa5m6+9FeUvnVe7iufVj/x/V9IOm8srjpQNLDujIL0fU7cduqeJcN2qdSrQsofxV7jTqKVynsH4Z/ouq9K6irZO3qnCdwnYtb76K+dTsw2Z6atxTOvzzYe2etVuz6s9Sp4WdVKpNKZufqTG0hmaFzdLGCRtVslVJ7Z23V2e3n1Wb6W0sZVaFr9KtM7fU/j93jsnNEzcrZ9GcCiwXqMTYRO38YqeOrT6m51Y+Z3MeAJxj7NixCg4O1syZMy3jihYt6sSIACDjfnv/N6thL3evRz7PBiMbPPJ5AEBWRUMF4DH05JNPavHixQoPD9d7772nokWLauLEiere3frH33nz5skwDEtl7b2OHDmiy5cvW41btWqVTp48qT59+qQq7+bmpmXLlunNN99UmzZtFBUVpeLFi2v27Nlq2bKlVdm9e/dq/vz52r17t2Vcx44dtXbtWtWrV0+lSpVK9dzeuzVu3Fjnz5+Xv7///VaHTbVr19bcuXP19ttv66233lKJEiW0ZMkSq4rXc+fO2XxcRnpOnz6trl27Wu4Yq1u3rjZv3qyAANtd/mcX0RejtbjHYkWdi5JHDg/lq5hPz614TqFPhVqV2/XlLvkX8ldo01Cb07ly8IribsRJunP32cU/L+qP2X8o9nqs/Ar4KbRpqBqOaiizx/8uT2veXaM/Zv9heT2tyjRJUs81PVWkQRHL+MMrDuvq4atWz7GtPri6zm4/qy9qfKGC1QuqwYgGaS5jpecrqc7wOjJ7Ptilsfyz5RVzKUZr312rqPNRCqocpO4/d5dvvv/dCXbj5A2rO+FuX7utH/r9oKjzUfLM5akCVQuoz8Y+aT5iAgCA7OR+ednOnTu1ZcsWSVLx4sWtPnvs2DEVKVJE0p2GCDdu3LC8t3TpUqsf8rt06SJJGjFihEb+94fyjz76SK6ururQoYPi4uLUrFkzffbZZ6liXLFihQ4fPqyvvvrKMm7w4MHavn27atSooerVq2vEiBEZWm5PT0916dJFXbp00dmzZ+Xrm/Zd5c8++6wuXbqkd999V+fPn1flypX1888/K1++fJYyJ0+ezFCDYJPJpD///FOz16/X9dhYFfDzU9PQUI1q2FAe5uxdhdBiUguteWeNlg1cpuiL0fIr4Keq/asq7N0wS5k6b9RRQnSCfnjxB8Vej1XhuoX13M/PWeWYV49cVczlGKtpH111VDdO3lCVPtaPfZDuPB6s27Ju+vXNX/VNm28UHxWv3MVzq93sdirRsoRV2Yt7L+qv+X+p/+7+lnFlO5bV8bXHNbPeTOUplUcd5nbI0HK7ml1VsnVJlWxdUrev3lZyYto9MgTXDtYzc5/RmrfXaPVbq5W7RG51WdJFgeUDLWWizkXpxsn/HZNJ8Ula+dpK3TpzS27ebspXMZ+eX/W8ijbkB1DgcbJ06VI1a9ZMnTp10rp161SwYEENHDhQ/fr1c3ZoAAAAyKJcDMNI3U9gFnHz5k3lyJFDN27ceOAfOwHAHtHR0ZZK4qioKPn4/O+xBo+8R4WWd37YNpYZTutRAQCcKbvlfNlteQE8pmz0bhAdHy/fyEhJUlR4uHwc2KNCfHS8In3vzDs8KlzuPpk8bwBwgqyU96U8XunVV19Vp06dtG3bNg0dOlRTp05Vz549bX4mLi5OcXFxltc3b95UcHBwllheAP9My99arpaRd27IWxa+jB4VAOARyEiOm71vhwAAAAAAAAAApCs5OVnVqlXTmDFjJElVqlTR3r17022oEBkZqYiICEeGCQAAgCzE/v4fAQAAAAAAAADZTv78+VW2bFmrcWXKlEn3kZvh4eG6ceOG5e/UqVOPOkwAAABkIU5vqHDmzBk999xzypMnj7y8vFShQgVt377d2WEBAAAAAAAAACTVqVNHBw8etBr3999/KyQkJM3PeHh4yN/f3+oPAAAASOHURz9cu3ZNderUUcOGDbV8+XIFBATo0KFDypUrlzPDAoBUPD09tXXrVsswAAAAkN14ms3a+sILlmEAQPbxyiuvqHbt2hozZow6d+6srVu3avr06Zo+fbqzQwMAu7mb3TXlhSmWYQCAczm1ZmHs2LEKDg7WzJkzLeOKFi3qxIgAwDaTyaQnn3zS2WEAAAAATmNyddWTBQs6OwwAgBM8+eSTWrx4scLDw/Xee++paNGimjhxorp37+7s0ADAbiZXk0oXLO3sMAAA/+XUhgpLly5Vs2bN1KlTJ61bt04FCxbUwIED1a9fP5vl4+LiFBcXZ3l98+ZNR4UKAAAAAAAAANlW69at1bp1a2eHAQAAgH8IV2fO/OjRo5oyZYpKlCihFStW6KWXXtKQIUM0e/Zsm+UjIyOVI0cOy19wcLCDIwaQXcXHx2v8+PEaP3684uPjnR0OAAAA4HDxSUkav2GDxm/YoPikJGeHAwAAAGRIQlKC5m2Yp3kb5ikhKcHZ4QBAtufUHhWSk5NVrVo1jRkzRpJUpUoV7d27V1OnTlXPnj1TlQ8PD9err75qeX3z5k0aKwBwiISEBL3xxhuSpIEDB8rdnWeYAQAAIHtJSErSG6tWSZIGPvmk3E0mJ0cEAAAA2C8xKVHTVk2TJLV9sq3cTG5OjggAsjen9qiQP39+lS1b1mpcmTJldPLkSZvlPTw85O/vb/UHAAAAAAAAAAAAAACyDqc2VKhTp44OHjxoNe7vv/9WSEiIkyICAAAAAAAAAAAAAACPklMbKrzyyivavHmzxowZo8OHD2vu3LmaPn26Bg0a5MywAAAAAAAAAAAAAADAI+LUhgpPPvmkFi9erG+++Ubly5fXqFGjNHHiRHXv3t2ZYQEAAAAAAAAAAAAAgEfEqQ0VJKl169bas2ePYmNjtX//fvXr18/ZIQEAAAAP5cyZM3ruueeUJ08eeXl5qUKFCtq+fbuzwwIAAAAAAACAx4LZ2QEAAAAA/yTXrl1TnTp11LBhQy1fvlwBAQE6dOiQcuXK5ezQAAAAAAAAAOCxQEMFALCDp6en1qxZYxkGACAtY8eOVXBwsGbOnGkZV7RoUSdGBACZw9Ns1pqePS3DAAAAQFbibnbXRz0/sgwDAJyLmgUAsIPJZFKDBg2cHQYAIAtYunSpmjVrpk6dOmndunUqWLCgBg4cmOYjzuLi4hQXF2d5ffPmTUeFCgAZYnJ1VYMiRZwdBgAAAPBATK4mVS5S2dlhAAD+y9XZAQAAAAD/JEePHtWUKVNUokQJrVixQi+99JKGDBmi2bNn2ywfGRmpHDlyWP6Cg4MdHDEAAAAAAAAAOBY9KgCAHRISEjR9+nRJ0osvvig3NzcnRwQAeFwlJyerWrVqGjNmjCSpSpUq2rt3r6ZOnaqe/+0y/W7h4eF69dVXLa9v3rxJYwUAj6WEpCRN37FDkvRi1apyM5mcHBEAAABgv8SkRP2w4wdJUpuqbWQ28RMZADgTZ2EAsEN8fLwGDx4sSerVqxcNFQAAacqfP7/Kli1rNa5MmTJatGiRzfIeHh7y8PBwRGgA8FDik5I0ePlySVKvypVpqAAAAIAsJSEpQZ8s/0SS1LxycxoqAICT8egHAAAAIBPVqVNHBw8etBr3999/KyQkxEkRAQAAAAAAAMDjhYYKAAAAQCZ65ZVXtHnzZo0ZM0aHDx/W3LlzNX36dA0aNMjZoQEAAAAAAADAY4GGCgAAAEAmevLJJ7V48WJ98803Kl++vEaNGqWJEyeqe/fuzg4NAAAAAAAAAB4LPIAHAAAAyGStW7dW69atnR0GAAAAAAAAADyW6FEBAAAAAAAAAAAAAAA4DA0VAAAAAAAAAAAAAACAw/DoBwCwg4eHh3788UfLMAAAAJDdeJjN+rFrV8swAAAAkJW4m901pusYyzAAwLmoWQAAO5jNZrVq1crZYQAAAABOY3Z1VauSJZ0dBgAAAPBATK4m1SpZy9lhAAD+i0c/AAAAAAAAAAAAAAAAh6FHBQCwQ0JCgr7++mtJUvfu3eXm5ubkiAAAAADHSkhK0td79kiSuleoIDeTyckRAQAAAPZLTErUqj2rJElNKjSR2cRPZADgTJyFAcAO8fHx6t27tySpU6dONFQAAABAthOflKTe338vSepUtiwNFQAAAJClJCQlaOz3YyVJYWXDaKgAAE7Gox8AAAAAAAAAAAAAAIDD0FABAAAAAAAAAAAAAAA4DA0VAAAAAAAAAAAAAACAw9BQAQAAAAAAAAAAAAAAOAwNFQAAAAAAAAAAAAAAgMPQUAEAAAAAAAAAAAAAADiM2dkBAEBW4OHhofnz51uGAQAAgOzGw2zW/I4dLcMAAABAVuJudteIjiMswwAA56JmAQDsYDab1alTJ2eHAQAAADiN2dVVncqVc3YYAAAAwAMxuZrUoFwDZ4cBAPgvHv0AAAAAAAAAAAAAAAAchh4VAMAOiYmJWrx4sSSpffv2MtPVLQAAALKZxORkLd6/X5LUvkwZmV259wEAAABZR1Jykn7f/7skqV6ZejK5mpwcEQBkb/zSBgB2iIuLU+fOnSVJUVFRNFQAAABAthOXmKjOCxdKkqLCw2V257m+AAAAyDriE+MVsTBCkrQsfJm83L2cHBEAZG/c/gAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGHMzg4AALICd3d3zZw50zIMAAAAZDfuJpNmtm1rGQYAAACyEjeTm/6v7f9ZhgEAzkVDBQCwg5ubm3r16uXsMAAAAACncTOZ1KtyZWeHAQAAADwQs8ms5pWbOzsMAMB/8egHAAAAAAAAAAAAAADgMPSoAAB2SExM1IoVKyRJzZo1k9nM6RMAAADZS2JyslYcPixJala8uMyu3PsAAACArCMpOUlbD2+VJFUvXl0mVx5nBgDOxC9tAGCHuLg4tW7dWpIUFRVFQwUAAABkO3GJiWr9zTeSpKjwcJnd3Z0cEQAAAGC/+MR4vfXNW5KkZeHL5OXu5eSIACB74/YHAAAAAAAAAAAAAADgMDRUAAAAAAAAAAAAAAAADkNDBQAAAAAAAAAAAAAA4DA0VAAAAAAAAAAAAAAAAA5DQwUAAAAAAAAAAAAAAOAwNFQAAAAAAAAAAAAAAAAOY3Z2AACQFbi7u2vy5MmWYQAAACC7cTeZNLlFC8swAAAAkJW4mdw0pMUQyzAAwLloqAAAdnBzc9OgQYOcHQYAAADgNG4mkwZVr+7sMAAAAIAHYjaZ1b56e2eHAQD4Lx79AAAAAAAAAAAAAAAAHIYeFQDADklJSfr9998lSfXq1ZOJrm4BAACQzSQlJ+v3kyclSfUKF5bJlXsfAAAAkHUkJSdpz8k9kqQKhSvI5EodLwA4Ew0VAMAOsbGxatiwoSQpKipKPj4+To4IAAAAcKzYxEQ1nD1bkhQVHi4fd3cnRwQAAADYLz4xXq/MfkWStCx8mbzcvZwcEQBkb9z+AAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGFoqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYczODgAAsgI3NzeNGzfOMgwAAABkN24mk8Y1aWIZBgAAALISs8ms/k36W4YBAM7FmRgA7ODu7q7hw4c7OwwAAADAadxNJg2vU8fZYQAAAAAPxM3kpi51ujg7DADAf/HoBwAAAAAAAAAAAAAA4DD0qAAAdkhKStLOnTslSU888YRMdHULAACAbCYpOVk7z52TJD2RP79Mrtz7AAAAgKwjKTlJh84dkiSVyF9CJlfqeAHAmWioAAB2iI2NVfXq1SVJUVFR8vHxcXJEAAAAgGPFJiaq+hdfSJKiwsPl4+7u5IgAAAAA+8UnxuulL16SJC0LXyYvdy8nRwQA2Ru3PwAAAAAAAAAAAAAAAIehoQIAAAAAAAAAIE0jR46Ui4uL1V/p0qWdHRYAAACyMB79AAAAAAAAAABIV7ly5bRq1SrLa7OZqmUAAAA8OLJJAAAAAAAAAEC6zGazgoKCnB0GAAAA/iF49AMAAAAAAAAAIF2HDh1SgQIFVKxYMXXv3l0nT550dkgAAADIwuhRAQAAAAAAAACQpho1amjWrFkqVaqUzp07p4iICNWrV0979+6Vn5+fzc/ExcUpLi7O8vrmzZuOChcAAABZgFMbKowcOVIRERFW40qVKqUDBw44KSIAsM3NzU0jRoywDAMAAADZjZvJpBFhYZZhAED20aJFC8twxYoVVaNGDYWEhGj+/Pnq27evzc9ERkamqvsFAGcym8zqGdbTMgwAcC6nn4nLlSunVatWWV6bzU4PCQBScXd318iRI50dBgAAAOA07iaTRjZo4OwwAACPgZw5c6pkyZI6fPhwmmXCw8P16quvWl7fvHlTwcHBjggPAGxyM7mpV4Nezg4DAPBfTm8VYDabFRQU5OwwAAAAAAAAAAB2iIqK0pEjR/T888+nWcbDw0MeHh4OjAoAAABZiauzAzh06JAKFCigYsWKqXv37jp58qSzQwKAVJKTk7Vv3z7t27dPycnJzg4HAAAAcLhkw9C+ixe17+JFJRuGs8MBADjQ66+/rnXr1un48ePauHGj2rdvL5PJpK5duzo7NACwW7KRrGMXj+nYxWNKNqjjBQBnc2qPCjVq1NCsWbNUqlQpnTt3ThEREapXr5727t0rPz+/VOXj4uIUFxdneX3z5k1HhgsgG7t9+7bKly8v6c5dAz4+Pk6OCAAAAHCs2wkJKj9liiQpKjxcPu7uTo4IAOAop0+fVteuXXXlyhUFBASobt262rx5swICApwdGgDYLS4hTn2m9JEkLQtfJi93LydHBADZm1MbKrRo0cIyXLFiRdWoUUMhISGaP3+++vbtm6p8ZGSkIiIiHBkiAAAAAAAAAGRr8+bNc3YIAAAA+Idx+qMf7pYzZ06VLFlShw8ftvl+eHi4bty4Yfk7deqUgyMEAAAAAAAAAAAAAAAP47FqqBAVFaUjR44of/78Nt/38PCQv7+/1R8AAAAAAAAAAAAAAMg6nNpQ4fXXX9e6det0/Phxbdy4Ue3bt5fJZFLXrl2dGRYAAAAAAAAAAAAAAHhEnNpQ4fTp0+ratatKlSqlzp07K0+ePNq8ebMCAgKcGRYAAADwwEaOHCkXFxerv9KlSzs7LAAAAAAAAAB4bJidOfN58+Y5c/YAAADAI1GuXDmtWrXK8tpsdmraDQAAAAAAAACPFWpMAcAObm5uev311y3DAACkx2w2KygoyNlhAECmcjOZ9HqtWpZhAAAAICsxm8x6ttazlmEAgHNxJgYAO7i7u2v8+PHODgMAkEUcOnRIBQoUkKenp2rVqqXIyEgVLlzYZtm4uDjFxcVZXt+8edNRYQJAhribTBrftKmzwwAAAAAeiJvJTQOaDnB2GACA/3J1dgAAAADAP0mNGjU0a9Ys/fzzz5oyZYqOHTumevXq6datWzbLR0ZGKkeOHJa/4OBgB0cMAAAAAAAAAI5FQwUAsENycrKOHz+u48ePKzk52dnhAAAeYy1atFCnTp1UsWJFNWvWTMuWLdP169c1f/58m+XDw8N148YNy9+pU6ccHDEA2CfZMHT8+nUdv35dyYbh7HAAAACADEk2knX++nmdv35eyQZ1vADgbDz6AQDscPv2bRUtWlSSFBUVJR8fHydHBADIKnLmzKmSJUvq8OHDNt/38PCQh4eHg6MCgIy7nZCgoh9/LEmKCg+Xj7u7kyMCAAAA7BeXEKeuH3eVJC0LXyYvdy8nRwQA2Rs9KgAAAACPUFRUlI4cOaL8+fM7OxQAAAAAAAAAeCzQUAEAAADIRK+//rrWrVun48ePa+PGjWrfvr1MJpO6du3q7NAAAAAAAAAA4LHAox8AAACATHT69Gl17dpVV65cUUBAgOrWravNmzcrICDA2aEBAAAAAAAAwGOBhgoAAABAJpo3b56zQwAAAAAAAACAxxqPfgAAAAAAAAAAAAAAAA5DQwUAAAAAAAAAAAAAAOAwPPoBAOxgNps1cOBAyzAAAACQ3ZhdXTWwWjXLMAAAAJCVmFxNalutrWUYAOBc/NoGAHbw8PDQp59+6uwwAAAAAKfxMJv1aatWzg4DAAAAeCDuZncNazXM2WEAAP6LWyAAAAAAAAAAAAAAAIDD0KMCANjBMAxdvnxZkpQ3b165uLg4OSIAAADAsQzD0OWYGElSXm9vcmIAAABkKYZh6EbMDUlSDu8c5LMA4GQ0VAAAO8TExCgwMFCSFBUVJR8fHydHBAAAADhWTEKCAj/4QJIUFR4uH3d3J0cEAAAA2C82IVbtP2gvSVoWvkxe7l5OjggAsjce/QAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGHMzg4AALICs9msnj17WoYBAACA7Mbs6qqelSpZhgEAAICsxORqUrNKzSzDAADn4tc2ALCDh4eHZs2a5ewwAAAAAKfxMJs1q107Z4cBAAAAPBB3s7vebPems8MAAPwXt0AAAAAAAAAAAAAAAACHoUcFALCDYRiKiYmRJHl7e8vFxcXJEQEAAACOZRiGYhISJEnebm7kxAAAAMhSDMNQbEKsJMnTzZN8FgCcjB4VAMAOMTEx8vX1la+vr6XBAgAAAJCdxCQkyDcyUr6RkZYGCwAAAEBWEZsQq5aRLdUysqWlwQIAwHloqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGHMzg4AALICk8mkjh07WoYBAACA7Mbk6qqOZctahgEAAICsxORqUljZMMswAMC5aKgAAHbw9PTUggULnB0GAAAA4DSeZrMWdOrk7DAAAACAB+JudtfITiOdHQYA4L+4BQIAAAAAAAAAAAAAADgMDRUAAAAAAAAAAAAAAIDD0FABAOwQHR0tFxcXubi4KDo62tnhAAAAAA4XHR8vl4gIuUREKDo+3tnhAAAAABlyO/62GkY0VMOIhrodf9vZ4QBAtkdDBQAAAAAAAAAAAAAA4DA0VAAAAAAAAAAAAAAAAA5DQwUAAAAAAAAAAAAAAOAwNFQAAAAAAAAAAAAAAAAOQ0MFAAAAAAAAAAAAAADgMDRUAAAAAAAAAAAAAAAADmN2dgAAkBWYTCa1bNnSMgwAAABkNyZXV7UsUcIyDAAAAGQlJleTapSoYRkGADgXDRUAwA6enp766aefnB0GAAAA4DSeZrN+6tbN2WEAAAAAD8Td7K5/d/u3s8MAAPwXt0AAAAAAAAAAAAAAAACHoaECAAAAAAAAAAAAAABwGBoqAIAdoqOj5ePjIx8fH0VHRzs7HAAAAMDhouPj5TNmjHzGjFF0fLyzwwEAAAAy5Hb8bbUY00ItxrTQ7fjbzg4HALI9s7MDAICsIiYmxtkhAAAAAE4Vk5Dg7BAAAACABxabEOvsEAAA/0WPCgAAAAAAAAAAAAAAwGFoqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYczODgAAsgJXV1eFhYVZhgEAAIDsxtXFRWEhIZZhAAAAICtxdXFVpZBKlmEAgHPRUAEA7ODl5aW1a9c6OwwAAADAabzc3LS2Vy9nhwEAAAA8EA83D03sNdHZYQAA/osmYwAAAAAAAAAAAAAAwGFoqAAAAAAAAAAAAAAAAByGhgoAYIfo6GgFBAQoICBA0dHRzg4HAAAAcLjo+HgFjB+vgPHjFR0f7+xwAAAAgAy5HX9b7ca3U7vx7XQ7/razwwGAbM/s7AAAIKu4fPmys0MAAAAAnOpyTIyzQwAAAAAe2I2YG84OAQDwX/SoAAAAAAAAAAAAAAAAHIaGCgAAAAAAAAAAAAAAwGFoqAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAALv9+9//louLi4YNG+bsUAAAAJBF0VABAAAAAAAAAGCXbdu2adq0aapYsaKzQwEAAEAWZnZ2AACQFbi6uqpatWqWYQAAACC7cXVxUbUCBSzDAIDsJyoqSt27d9fnn3+u0aNHOzscAMgQVxdXlSpQyjIMAHAuGioAgB28vLy0bds2Z4cBAAAAOI2Xm5u29evn7DAAAE40aNAgtWrVSk2aNLlvQ4W4uDjFxcVZXt+8efNRhwcA6fJw89DUflOdHQYA4L8emyZjPNcMAAAAAAAAAB5P8+bN086dOxUZGWlX+cjISOXIkcPyFxwc/IgjBAAAQFbyWDRU4LlmAAAAAAAAAPB4OnXqlIYOHaqvv/5anp6edn0mPDxcN27csPydOnXqEUcJAACArMTpDRXufq5Zrly5nB0OANgUExOjIkWKqEiRIoqJiXF2OAAAAIDDxSQkqMjEiSoycaJiEhKcHQ4AwIF27Nihixcv6oknnpDZbJbZbNa6dev0ySefyGw2KykpKdVnPDw85O/vb/UHAM4UmxCrLhO7qMvELopNiHV2OACQ7ZmdHQDPNQOQFRiGoRMnTliGAQAAgOzGMAyduHHDMgwAyD4aN26sPXv2WI3r3bu3Spcurf/7v/+TyWRyUmQAYD/DMHThxgXLMADAuZzaUCHluWbbtm2zq3xkZKQiIiIecVQAAAAAAAAAgBR+fn4qX7681TgfHx/lyZMn1XgAAADAHk579APPNQMAAAAAAAAAAAAAIPtxWo8Kdz/XLEVSUpJ+++03TZ48WXFxcam6DPPw8JCHh4ejQwUAAAAAAAAA3GXt2rXODgEAAABZmNMaKvBcMwAAAGQH//73vxUeHq6hQ4dq4sSJzg4HQFY0cqSzIwAAAAAy1dqRa50dAgDAyZzWUIHnmgEAAOCfbtu2bZo2bZoqVqzo7FAAAAAAAAAA4LHh6uwAACArcHFxUdmyZVW2bFm5uLg4OxwAQBYQFRWl7t276/PPP1euXLmcHQ4APDQXFxeVDQhQ2YAAcmIAAABkOS4uLgoJCFFIQAj5LAA8BpzWo4ItPNcMwOPK29tb+/btc3YYAIAsZNCgQWrVqpWaNGmi0aNHp1kuLi5OcXFxltc3b950RHgAkGHebm7aN3Cgs8MAAAAAHoinm6dmDZzl7DAAAP/1WDVUAAAAAP4J5s2bp507d2rbtm33LRsZGamIiAgHRAUAAAAAAAAAjwce/QAAAABkolOnTmno0KH6+uuv5enped/y4eHhunHjhuXv1KlTDogSAAAAAAAAAJyHHhUAwA4xMTF68sknJUnbtm2Tt7e3kyMCADyuduzYoYsXL+qJJ56wjEtKStJvv/2myZMnKy4uTiaTyfKeh4eHPDw8nBEqAGRITEKCnvz8c0nStn795O3m5uSIAAAAAPvFJsRqwOcDJElT+02Vp9v9by4AADw6NFQAADsYhqG//vrLMgwAQFoaN26sPXv2WI3r3bu3Spcurf/7v/+zaqQAAFmJYRj669IlyzAAAACQlRiGoROXTliGAQDORUMFAAAAIBP5+fmpfPnyVuN8fHyUJ0+eVOMBAAAAAAAAIDtydXYAAAAAAAAAAAAAAAAg+6BHBQAAAOARW7t2rbNDAAAAAAAAAIDHBj0qAAAAAAAAAAAAAAAAh6GhAgAAAAAAAAAAAAAAcBge/QDgH2Xk2pGPZLoJsQnKkS+HJGnM72Pk5un2SOYDAAAAPK5cXFwUkiOHZRgAAADISlxcXJQvRz7LMADAuWioAAB2cPN007B5w5wdBgAAAOA03m5uOj5smLPDAAAAAB6Ip5un5g2b5+wwAAD/xaMfAAAAAAAAAAAAAACAw9BQAQAAAAAAAAAAAAAAOAwNFQDADglxCfp8wOf6fMDnSohLcHY4AAAAgMPdTkjQk59/ric//1y3E8iJAQAAkLXEJcRpwOcDNODzAYpLiHN2OACQ7ZmdHQAAZAVGsqGzB89ahgEAAIDsJtkwtP3sWcswAAAAkJUkG8k6ePagZRgA4Fz0qAAAAAAAAAAAAAAAAByGhgoAAAAAAAAAAAAAAMBhaKgAAAAAAAAAAAAAAAAchoYKAAAAAAAAAAAAAADAYWioAAAAAAAAAAAAAAAAHMbs7AAAIKvwzuHt7BAAAAAAp8rrTU4MAACArCuHdw5nhwAA+C8aKgCAHdy93DV8yXBnhwEAAAA4jY+7uy4NJycGAABA1uTl7qUlw5c4OwwAwH/x6AcAAAAAAAAAAAAAAOAwNFQAgP9v797jpK7r/YG/Z2d2dpe7Ny4WiimaouLxGqiJSqWUgZ7SzJ9CpaXhKSU8uXaOrpVBRzM9HQ+WmWhpVqbWEdSUWEtT84ZREuIFtAQvaSi3vX5/f6CTJODuujvfnZnn8/HYx+M7M9+d72v2K+uL4T2fLwAAAAAAAFA0BhUAOqClqSVmnzE7Zp8xO1qaWtKOAwAARbe2pSXGzZ4d42bPjrUtOjEAAKWlqaUpzph9Rpwx+4xoamlKOw5AxculHQCgFCTtSSx7dFlhGwAAKk17ksRdy5YVtgEAoJS0J+3x6LJHC9sApMuKCgAAAAAAAABA0RhUAAAAAAAAAACKxqACAAAAAAAAAFA0BhUAAAAAAAAAgKIxqAAAAAAAAAAAFE0u7QAApaK6tjrtCAAAkKo+1ToxAAClq7a6Nu0IALyuS4MKTz31VLznPe/p7iwAvVa+Lh/n3HpO2jEA6GF6LsCm9c3nY/U5OjFAqdFxAdary9fFrefcmnYMAF7XpUs/7LTTTnHooYfGj370o1i3bl13ZwIAgFTouQAAlBsdFwCA3qhLgwoPP/xw7LnnnjFt2rQYOnRofO5zn4vf//733Z0NAACKSs8FAKDc6LgAAPRGXRpU2GuvveLSSy+N5557Ln7wgx/E8uXL46CDDordd989Lr744njxxRe7OydAqlqbW+O6s6+L686+LlqbW9OOA0AP0XMBNm1da2t8+Lrr4sPXXRfrWnVigFKh4wKs19zaHGdfd3acfd3Z0dzanHYcgIrXpUGFN+RyuTjmmGPiZz/7WXzzm9+MJ554IqZPnx7Dhw+Pk046KZYvX95dOQFS1d7WHkvuXxJL7l8S7W3taccBoIfpuQBv1dbeHnOXLIm5S5ZEW7tODFBqdFyg0rW1t8X9S+6P+5fcH23tbWnHAah472hQ4cEHH4zPf/7zMWzYsLj44otj+vTp8eSTT8Ydd9wRzz33XEycOLG7cgIAQNHouQAAlBsdFwCA3iTXlW+6+OKL46qrrorFixfHhAkT4pprrokJEyZEVdX6uYcddtghZs+eHSNGjOjOrAAA0KP0XAAAyo2OCwBAb9SlQYVZs2bFpz/96ZgyZUoMGzZso/sMHjw4rrzyyncUDgAAiknPBQCg3Oi4AAD0Rl0aVLjjjjtiu+22K0zdviFJknj22Wdju+22i3w+H5MnT+6WkAAAUAx6LgAA5UbHBQCgN6p6+13eascdd4yXXnrpLfe//PLLscMOO7zjUAAAkAY9FwCAcqPjAgDQG3VpUCFJko3ev2rVqqitrX1HgQAAIC16LgAA5UbHBQCgN+rUpR+mTZsWERGZTCbOPffc6NOnT+Gxtra2uP/++2Ovvfbq1oAAvUG+Lh/nzT8v7RgA9BA9F+Dt9c3nIzlPJwYoFTouwIbq8nUx/7z5accA4HWdGlR45JFHImL9FO7ChQsjn88XHsvn8zF69OiYPn169yYEAIAepucCAFBudFwAAHqzTg0qzJ+/ftLsU5/6VFx66aUxYMCAHgkFAADFpOcCAFBudFwAAHqzTg0qvOGqq67q7hwAvVprc2vc9I2bIiLi6HOOjly+S78+Aejl9FyATVvX2hon3rS+E//w6KOjNqcTA5QCHRdgvebW5vjGTd+IiIhzjj4n8rn823wHAD2pw+8qHHPMMTF79uwYMGBAHHPMMZvd98Ybb3zHwQB6k/a29njsrsciImLilyemnAaA7qTnAnRMW3t73PDY+k48e6JODNCb6bgAb9XW3hZ3PXZXRER8eeKXU04DQIcHFQYOHBiZTKawDQAA5UDPBQCg3Oi4AAD0dh0eVHjzEmGWCwMAoFzouQAAlBsdFwCA3q6qK9+0du3aWLNmTeH2smXL4pJLLolf/epX3RYMAACKTc8FAKDc6LgAAPRGXRpUmDhxYlxzzTUREfH3v/899t9///jWt74VEydOjFmzZnVrQAAAKBY9FwCAcqPjAgDQG3VpUOHhhx+Ogw8+OCIibrjhhhg6dGgsW7Ysrrnmmvjv//7vbg0IAADFoucCAFBudFwAAHqjLg0qrFmzJvr37x8REb/61a/imGOOiaqqqnjf+94Xy5Yt69aAAABQLHouAADlRscFAKA36tKgwk477RQ333xzPPvss3H77bfHBz/4wYiIeOGFF2LAgAHdGhCgN6iurY76ufVRP7c+qmur044DQA/RcwE2rU91dayqr49V9fXRp1onBigVOi7AerXVtTG3fm7MrZ8btdW1accBqHhdGlQ499xzY/r06TFixIg44IADYsyYMRGxfiL3X/7lX7o1IEBvkMlkIl+Xj3xdPjKZTNpxAOghei7ApmUymeibz0ffvE4MUEp0XID1MplM1OXroi5fp88C9AK5rnzTxz72sTjooINi+fLlMXr06ML9hx9+eBx99NHdFg4AAIpJzwUAoNzouAAA9EZdGlSIiBg6dGgMHTp0g/v233//dxwIoDdqbW6NWy6+JSIiPjLtI5HLd/nXJwC9nJ4LsHFNra3xuVvWd+LvfuQjUZPTiQFKhY4LENHc2hwX33JxRERM+8i0yOfyKScCqGxdeldh9erVMXPmzJg3b1688MIL0d7evsHjTz31VLeEA+gt2tva49HbH42IiAlfnJByGgB6ip4LsGmt7e1x9aPrO/FlEyZETcp5AOgYHRdgvbb2trj90dsjIuKLE76YchoAujSocPLJJ8ddd90VJ554YgwbNsy1fAAAKAt6LgAA5UbHBQCgN+rSoMKtt94ac+bMiQMPPLC78wAAQGr0XAAAyo2OCwBAb1TVlW/aYostYsstt+zuLAAAkCo9FwCAcqPjAgDQG3VpUOFrX/tanHvuubFmzZruzgMAAKnRcwEAKDc6LgAAvVGXLv3wrW99K5588skYMmRIjBgxIqqrqzd4/OGHH+6WcAAAUEx6LgAA5UbHBQCgN+rSoMKkSZO6OQYAAKRPzwUAoNx0R8edNWtWzJo1K5YuXRoREaNGjYpzzz03jjzyyHf83AAAVKYuDSqcd9553Z0DoFerrq2O6TdNL2wDUJ70XIBN61NdHS9Mn17YBqA0dEfHffe73x0zZ86MkSNHRpIkcfXVV8fEiRPjkUceiVGjRnVDSoCeV1tdGzdNv6mwDUC6qrr6jX//+9/j+9//ftTX18fLL78cEeuXCfvrX//abeEAeotMJhN9B/WNvoP6RiaTSTsOAD1IzwXYuEwmE9v07Rvb9NWJAUrNO+24Rx11VEyYMCFGjhwZO++8c1xwwQXRr1+/uO+++3oyNkC3ymQyMajvoBjUd5A+C9ALdGlFhT/84Q8xfvz4GDhwYCxdujROOeWU2HLLLePGG2+MZ555Jq655pruzgkAAD1OzwUAoNx0d8dta2uLn/3sZ7F69eoYM2ZMD6UGAKDcdWlFhWnTpsWUKVNiyZIlUVv7j+VxJkyYEL/5zW86/DyzZs2KPffcMwYMGBADBgyIMWPGxK233tqVSAA9qrW5NeZcMifmXDInWptb044DQA/prp4LUI6aWltj6pw5MXXOnGhq1YkBSkV3ddyFCxdGv379oqamJk499dS46aabYrfddtvk/k1NTfHqq69u8AWQpubW5rhkziVxyZxLorm1Oe04ABWvS4MKDzzwQHzuc597y/3vete7YsWKFR1+njeubfbQQw/Fgw8+GIcddlhMnDgx/vSnP3UlFkCPaW9rjwd/8WA8+IsHo72tPe04APSQ7uq5AOWotb09/vfBB+N/H3wwWtt1YoBS0V0dd5dddokFCxbE/fffH6eddlpMnjw5HnvssU3uP2PGjBg4cGDha/jw4V3KD9Bd2trb4hcP/iJ+8eAvoq29Le04ABWvS4MKNTU1G52Affzxx2Obbbbp8PO4thkAAL1Jd/VcAADoLbqr4+bz+dhpp51in332iRkzZsTo0aPj0ksv3eT+9fX1sXLlysLXs88+26X8AACUpy4NKnz0ox+Nr371q9HS0hIREZlMJp555pn48pe/HP/6r//apSBtbW1x/fXXb/baZpYLAwCgJ/VEzwUAgDT1VMdtb2+PpqamTT5eU1NTuOTvG18AAPCGLg0qfOtb34pVq1bFNttsE2vXro1DDjkkdtppp+jfv39ccMEFnXquzlzbzHJhAAD0pO7suQAA0Bt0R8etr6+P3/zmN7F06dJYuHBh1NfXR2NjY5xwwgk9nB4AgHKV68o3DRw4MO64446455574tFHH41Vq1bF3nvvHePHj+/0c71xbbOVK1fGDTfcEJMnT4677rpro8MK9fX1MW3atMLtV1991bACAADdpjt67qxZs2LWrFmxdOnSiIgYNWpUnHvuuXHkkUf2UGoAANi07ui4L7zwQpx00kmxfPnyGDhwYOy5555x++23xwc+8IEeTA4AQDnr9KBCe3t7zJ49O2688cZYunRpZDKZ2GGHHWLo0KGRJElkMplOPd8b1zaLiNhnn33igQceiEsvvTS++93vvmXfmpqaqKmp6WxkAAB4W93Vc9/97nfHzJkzY+TIkZEkSVx99dUxceLEeOSRR2LUqFE9/CoAAOAfuqvjXnnllT2cFACAStOpSz8kSRIf/ehH4+STT46//vWvsccee8SoUaNi2bJlMWXKlDj66KPfcaC3u7YZAAB0t+7suUcddVRMmDAhRo4cGTvvvHNccMEF0a9fv7jvvvt68BUAAMCGivFeLgAAdFWnVlSYPXt2/OY3v4l58+bFoYceusFjv/71r2PSpElxzTXXxEknndSh56uvr48jjzwytttuu3jttdfiuuuui8bGxrj99ts7Ewugx1XXVMcXf/zFwjYA5aW7e+4b2tra4mc/+1msXr06xowZs9F9mpqaNhjUffXVVzv/AgCKoK66Op7+4hcL2wD0bj3VcQFKVU11Tfz4iz8ubAOQrk6tqPDjH/84zjnnnLcU24iIww47LM4+++y49tprO/x8b1zbbJdddonDDz88HnjgAdc2A3qlTFUmBg0dFIOGDopMVecucQNA79fdPXfhwoXRr1+/qKmpiVNPPTVuuumm2G233Ta674wZM2LgwIGFr+HDh3f5dQD0pKpMJkYMGhQjBg2Kqk5e9hGA4uvujgtQ6qoyVTF00NAYOmhoVGU69c9jAPSATv0m/sMf/hBHHHHEJh8/8sgj49FHH+3w81155ZWxdOnSaGpqihdeeCHuvPNOQwoAABRdd/fcXXbZJRYsWBD3339/nHbaaTF58uR47LHHNrpvfX19rFy5svD17LPPdjo/AAD8s+7uuAAA0J06demHl19+OYYMGbLJx4cMGRKvvPLKOw4F0Nu0tbTFvCvnRUTE4Z85PLLV2ZQTAdCdurvn5vP52GmnnSIiYp999okHHnggLr300vjud7/7ln1ramqipsaSk0Dv19zWFl+Zt74TX3D44ZHP6sQAvZn3cgE21NLWElfOuzIiIj5z+GeiOutyZgBp6tSgQltbW+Rym/6WbDYbra2t7zgUQG/T1toW9/7k3oiIGDd5XOqDCg2NDcU/5rjiHxOgWHq657a3t0dTU1OXvx+gN2hpa4uL7l3fiRvGjTOoANDLeS8XYEOtba3xk3t/EhERk8dNNqgAkLJODSokSRJTpkzZ5Ce+vPkKAEAp6s6eW19fH0ceeWRst9128dprr8V1110XjY2Ncfvtt3dXXAAAeFveywUAoDfr1KDC5MmT33afk046qcthAAAgDd3Zc1944YU46aSTYvny5TFw4MDYc8894/bbb48PfOAD7zQmAAB0mPdyAQDozTo1qHDVVVf1VA4AAEhNd/bcK6+8stueCwAAusp7uQAA9GZVaQcAAAAAAAAAACqHQQUAAAAAAAAAoGg6dekHAAAAAAAA4O01NjQW/ZjjGsYV/ZgAXWFQAaADqmuq47QfnFbYBgCASlNXXR1/PO20wjYAAJSSmuqa+MFpPyhsA5AugwoAHZCpysTgHQanHQMAAFJTlcnEqME6MQAApakqUxU7DN4h7RgAvK4q7QAAAAAAAAAAQOWwogJAB7S1tMVvr/1tREQcfMLBka3OppwIAACKq7mtLb7x2/Wd+JyDD458VicGAKB0tLS1xLW/vTYiIk44+ISozrqcGUCaDCoAdEBba1vcdfVdEREx9rixBhUAAKg4LW1tcf5d6zvxWWPHGlQAAKCktLa1xtV3XR0REceNPc6gAkDKXPoBAAAAAAAAACgaKyoAAAAA6Wto2PRjzRERmfXbF3wjIl+EYwIAAAA9xooKAAAAAAAAAEDRGFQAAAAAAAAAAIrGoAIAAAAAAAAAUDQGFQAAAAAAAACAosmlHQCgFOTyuTh51smFbQAAqDS1uVz8/uSTC9sAAFBK8rl8zDp5VmEbgHR5ZwGgA6qyVfGu974r7RgAAJCabFVV7PcunRgAgNKUrcrGe9/13rRjAPA6l34AAAAAAAAAAIrGigoAHdDW0hb3/fy+iIh437++L7LV2ZQTAQBAcTW3tcWl963vxF983/sin9WJAQAoHS1tLfHz+34eERH/+r5/jepsdcqJACqbQQWADmhrbYs7v3tnRETsN3E/gwoAAFSclra2+Pc713fiz++3n0EFAABKSmtba3z3zu9GRMTE/SYaVABImUs/AAAAAAAAAABFY1ABAAAAAAAAACgagwoAAAAAAAAAQNEYVAAAAAAAAAAAisagAgAAAAAAAABQNAYVAAAAAAAAAICiyaUdAKAU5PK5mPztyYVtAACoNLW5XMyfPLmwDQAApSSfy8e3J3+7sA1AuryzANABVdmqGLHXiLRjAABAarJVVTFuxIi0YwAAQJdkq7Kx14i90o4BwOtc+gEAAAAAAAAAKBorKgB0QFtrWzz0fw9FRMQ+R+0T2Vw25UQAAFBcLW1t8b2H1nfiz+6zT1RndWIAAEpHa1tr/N9D/xcREUftc1Tksv6JDCBNfgsDdEBbS1vc+t+3RkTEXkfsZVABAICK09zWFqffur4TT9lrL4MKAACUlJa2lvjvW/87IiKO2OsIgwoAKXPpBwAAAAAAAACgaAwqAAAAAAAAAABFY1ABAAAAAAAAACgagwoAAAAAAAAAQNEYVAAAAAAAAAAAisagAgAAAAAAAABQNLm0AwCUglw+F8d/4/jCNgAAVJqaXC5uOf74wjYAAJSSfC4f3zj+G4VtANLlnQWADqjKVsXOY3ZOOwYAAKQmV1UVH95ZJwYAoDRlq7IxZucxaccA4HUu/QAAAAAAAAAAFI0VFQA6oK21LRbeuTAiIvYYv0dkc9mUEwEAQHG1tLXFtQvXd+IT9tgjqrM6MQAApaO1rTXuXHhnRESM32N85LL+iQwgTX4LA3RAW0tb/OKbv4iIiN0O2c2gAgAAFae5rS0+9Yv1nfjju+1mUAEAgJLS0tYS3/zFNyMi4pDdDjGoAJAyl34AAAAAAAAAAIrGoAIAAAAAAAAAUDQGFQAAAAAAAACAojGoAAAAAAAAAAAUjUEFAAAAAAAAAKBoDCoAAAAAAAAAAEWTSzsAQCnI5XPxsfM+VtgGAIBKU5PLxU8/9rHCNgAAlJJ8Lh/nfey8wjYA6fLOAkAHVGWrYtS4UWnHAACA1OSqquLjo3RiAABKU7YqG+NGjUs7BgCvc+kHAAAAAAAAAKBorKgA0AHtbe2x6LeLIiJi14N3jaqsOS8AACpLa3t73LRofSc+etddI1elEwMAUDra2tvit4t+GxERB+96cGSrsiknAqhsBhUAOqC1uTVuOP+GiIion1sf+TrXMAMAqEgNDWknSE1Ta2sce8P6Tryqvj5yeZ0YAIDS0dzaHOffcH5ERMytnxt1+bqUEwFUNh9/AAAAAAAAAACKxqACAAAAAAAAAFA0BhUAAAAAAAAAgKIxqAAAAAAAAAAAFI1BBQAAAAAAAACgaAwqAAAAAAAAAABFk0s7AEApyFZnY+KXJxa2AQCg0uSz2bhq4sTCNgAAlJLqbHV8eeKXC9sApMugAkAHZHPZ2OuIvdKOAQAAqanOZmPKXnulHQMAALokl83FEXsdkXYMAF7n0g8AAAAAAGzSjBkzYr/99ov+/fvH4MGDY9KkSbF48eK0YwEAUMIMKgB0QHtbezx+7+Px+L2PR3tbe9pxAACg6Frb22PO44/HnMcfj9Z2nRigktx1110xderUuO++++KOO+6IlpaW+OAHPxirV69OOxpAh7W1t8W9j98b9z5+b7S1t6UdB6DipXrphxkzZsSNN94Yf/7zn6Ouri7Gjh0b3/zmN2OXXXZJMxbAW7Q2t8aPz/lxRETUz62PfF0+5UQAAFBcTa2t8ZEfr+/Eq+rrI5fXiQEqxW233bbB7dmzZ8fgwYPjoYceive///0ppQK6S2NDY9oRiqK5tTnO+fE5ERExt35u1OXrUk4EUNlSXVHBJC4AAAAAQGlZuXJlRERsueWWm9ynqakpXn311Q2+AADgDamuqGASFwAAAACgdLS3t8cZZ5wRBx54YOy+++6b3G/GjBlx/vnnFzEZAAClJNUVFf5ZRyZxAQCgN5sxY0bst99+0b9//xg8eHBMmjQpFi9enHYsAADoFlOnTo0//vGPcf311292v/r6+li5cmXh69lnny1SQgAASkGvGVToyCSu5cIAAOjtXN4MAIBydfrpp8ctt9wS8+fPj3e/+92b3bempiYGDBiwwRcAALwh1Us/vNkbk7h33333JvexXBgAAL2dy5sBAFBukiSJf/u3f4ubbropGhsbY4cddkg7EgAAJa5XrKjQ0Ulcy4UBAFBqXN4MAIBSN3Xq1PjRj34U1113XfTv3z9WrFgRK1asiLVr16YdDQCAEpXqigqdncStqamJmpqaIqUD+IdsdTaO/MKRhW0A6IiOXt6sqampcNvlzYDeKp/Nxv8ceWRhG4DKMWvWrIiIGDdu3Ab3X3XVVTFlypTiBwLogupsdXzhyC8UtgFIV6qDClOnTo3rrrsufvGLXxQmcSMiBg4cGHV1dWlGA9hANpeN/Y/eP+0YAJQYlzcDykl1NhtT99eJASpRkiRpRwB4x3LZXBy9/9FpxwDgdale+mHWrFmxcuXKGDduXAwbNqzw9ZOf/CTNWAAA8I65vBkAAAAAwMalfukHgFLQ3tYezyx8JiIitttju6jKpjrnBUAv5vJmQLlqa2+P3z6zvhMfvN12ka3SiQEAKB1t7W2x8JmFERGxx3Z7RLbK5cwA0pTqoAJQ3hoaG9KO0G1am1vj6jOvjoiI+rn1ka/Lp5wIgN7K5c2AcrWutTUOvXp9J15VXx998zoxAAClo7m1Oc68+syIiJhbPzfq8v6ODpAmH38AAIBu5PJmAAAAAACbZ0UFAADoRi5vBgAAAACweVZUAAAAAAAAAACKxqACAAAAAAAAAFA0BhUAAAAAAAAAgKIxqAAAAAAAAAAAFE0u7QAApSCby8b4z40vbAMAQKWpzmbjv8aPL2wDAEApyWVz8bnxnytsA5Auv4kBOiBbnY0DP3Fg2jEAACA1+Ww2zjpQJwYAoDRVZ6vjEwd+Iu0YALzOpR8AAAAAAAAAgKKxogJAB7S3tcfyJcsjImLYyGFRlTXnBQBAZWlrb4+Hl6/vxHsPGxbZKp0YAIDS0dbeFkuWL4mIiJHDRka2yuXMANJkUAGgA1qbW+P7p30/IiLq59ZHvi6fciIAACiuda2tsf/313fiVfX10TevEwMAUDqaW5vjtO+fFhERc+vnRl2+LuVEAJXNxx8AAAAAAAAAgKIxqAAAAAAAAAAAFI1BBQAAAAAAAACgaAwqAAAAAAAAAABFY1ABAAAAAAAAACgagwoAAAAAAAAAQNHk0g4AUAqyuWwcMvmQwjYAAFSa6mw2zjvkkMI2AACUklw2F5MPmVzYBiBdfhMDdEC2OhvjpoxLOwYAAKQmn81Gw7hxaccAAIAuqc5Wx5RxU9KOAcDrXPoBAAAAAAAAACgaKyoAdEDSnsSLy16MiIhttt8mMlWZlBMBAEBxtSdJLHpxfSfedZttoiqjEwMAUDrak/ZY9uKyiIjYfpvtoyrjs7wAaTKoANABLU0tMevTsyIion5ufeTr8iknAgCA4lrb0hK7z1rfiVfV10ffvE4MAEDpaGppik/P+nRERMytnxt1+bqUEwFUNuNiAAAAAAAAAEDRGFQAAAAAAAAAAIrGoAIAAAAAAAAAUDQGFQAAAAAAAACAojGoAAAAAAAAAAAUjUEFAAAAAAAAAKBocmkHACgF2Vw2xhw3prANAACVpjqbjeljxhS2AQCglOSyuThuzHGFbQDS5TcxQAdkq7PxwVM/mHYMAABITT6bjQs/qBMDAFCaqrPVceoHT007BgCvc+kHAAAAAAAAAKBorKgA0AFJexIrX1gZEREDBw+MTFUm5UQAAFBc7UkSz6xc34m3GzgwqjI6MQAApaM9aY8XVr4QERGDBw6OqozP8gKkyaACQAe0NLXEpcdfGhER9XPrI1+XTzkRAAAU19qWltjh0vWdeFV9ffTN68QAAJSOppamOP7S4yMiYm793KjL16WcCKCyGRcDAAAAAAAAAIrGoAIAAAAAAAAAUDQGFQAAAAAAAACAojGoAAAAAAAAAAAUTS7tAACUhobGhuIfc1zxjwkAAAAAAEDPsqICAAAAAAAAAFA0VlQA6ICqbFXsO3HfwjYAAFSaXFVVfH7ffQvbAABQSrJV2Zi478TCNgDpMqgA0AG5fC4+fMaH044BAACpqcnl4rIP68QAAJSmfC4fZ3z4jLRjAPA6H4EAAAAAAAAAAIrGigoAHZAkSaxZuSYiIvoM7BOZTCblRAAAUFxJksRLa9Z34q376MQAAJSWJEli5ZqVERExsM9AfRYgZVZUAOiAlnUtcdHRF8VFR18ULeta0o4DAABFt6alJQZfdFEMvuiiWNOiEwMAUFrWtayLoy86Oo6+6OhY17Iu7TgAFc+gAgAAAAAAAABQNAYVAAAAAAAAAICiMagAAAAAAAAAABSNQQUAAAAAAAAAoGgMKgAAAAAAAAAARWNQAQAAAAAAAAAomlzaAQBKQVW2KkZ/aHRhGwAAKk2uqiomjx5d2AYAgFKSrcrGh0Z/qLANQLoMKgB0QC6fi0lnT0o7BgAApKYml4vZkyalHQMAALokn8vH2ZPOTjsGAK/zEQgAAAAAAAAAoGisqADQAUmSRMu6loiIqK6tjkwmk3IiAAAoriRJYk3L+k7cp1onBgCgtCRJEuta1kVERG11rT4LkDIrKgB0QMu6lpgxYUbMmDCjMLAAAACVZE1LS/SbMSP6zZhRGFgAAIBSsa5lXUyYMSEmzJhQGFgAID1WVAAAAAAAAIAy0NjQWPRjjmsYV/RjAqXPigoAAAAAAAAAQNEYVAAAAAAAAAAAisalHwAAAChNDQ1pJwAAAACgC6yoAAAAAAAAAAAUjUEFAAAAAAAAAKBoXPoBoAOqslWx2yG7FbYBAKDSZKuq4mO77VbYBgCAUpKtysYhux1S2AYgXQYVADogl8/Fxxs+nnYMAABITW0uFz/7uE4MAEBpyufy0fDxhrRjAPA6H4EAAAAAAAAAAIrGoAIAAAAAAAAAUDQu/QDQAc1rm2PGhBkREVE/tz7ydfmUEwEAQHGtbm6OfjPWd+JV9fXRN68TAwD0hMaGxrQjlKW1zWtjwowJERExt35u1OXrUk4EUNmsqAAAAAAAwGb95je/iaOOOiq23XbbyGQycfPNN6cdCQCAEpbqoIJyCwAAAADQ+61evTpGjx4dl112WdpRAAAoA6kOKii3AACUG8O4AACUoyOPPDK+/vWvx9FHH512FAAAykAuzYMfeeSRceSRR6YZAQAAutUbw7if/vSn45hjjkk7DgAApKKpqSmampoKt1999dUU0wAA0NukOqjQWcotAAC9nWFcgBLS0FAZxwRIwYwZM+L8889POwYAAL1Uqpd+6KwZM2bEwIEDC1/Dhw9POxIAAAAAAP+kvr4+Vq5cWfh69tln044EAEAvUlIrKtTX18e0adMKt1999VXDCkBRVGWrYuQBIwvbANBdrBoGlIpsVVVMGDmysA0Am1NTUxM1NTVpxwAoyFZl44CRBxS2AUhXSQ0qKLdAWnL5XHxy5ifTjgFAGbIkLlAqanO5mPNJnRgAgNKUz+Vj5idnph0DgNf5CAQAAKTIkrgAAJSCVatWxYIFC2LBggUREfH000/HggUL4plnnkk3GAAAJSnVFRVWrVoVTzzxROH2G+V2yy23jO222y7FZFB+Ghob0o4AAGyEVcMAACgFDz74YBx66KGF229confy5Mkxe/bslFIBAFCqUh1UUG6BUtG8tjkuOuaiiIiYfuP0yNflU04EQG9lGBcoV6ubm2PwRes78QvTp0ffvE4MUEnGjRsXSZKkHQOgy9Y2r41jLjomIiJunH5j1OXrUk4EUNlSHVRQboFS0rKuJe0IAJQAw7hAOVvTohMDAFC61rWsSzsCAK9LdVABADYnjUuWNIwr/jGB8mIYFwAAAABg86rSDgAAAAAAAAAAVA6DCgAAAAAAAABA0RhUAAAAAAAAAACKxqACAAAAAAAAAFA0ubQDAJSCTFUmth+9fWEbAAAqTVUmE4dsv31hGwAASklVpipGbz+6sA1AugwqAHRAdU11TLlkStoxAAAgNXXV1dE4ZUraMQAAoEtqqmvikimXpB0DgNcZGQMAAAAAAAAAisagAgAAAAAAAABQNAYVADqgeW1zXDjpwrhw0oXRvLY57TgAAFB0q5ubY5sLL4xtLrwwVjfrxAAAlJa1zWtj0oWTYtKFk2Jt89q04wBUvFzaAQBKxZqVa9KOAAAAqXppjU4MAEDpWrlmZdoRAHidFRUAAAAAAAAAgKIxqAAAAAAAAAAAFI1BBQAAAAAAAACgaHJpBwAAAKAMNDSknQAAAACAEmFFBQAAAAAAAACgaKyoANABmapMbLvLtoVtAACoNFWZTOy77baFbQAAKCVVmarYZdtdCtsApMugAkAHVNdUxymXn5J2DAAASE1ddXU8cIpODABAaaqpronLT7k87RhlqbGhsejHHNcwrujHBLqXkTEAAAAAAAAAoGgMKgAAAAAAAAAARePSDwAd0LKuJS6bcllEREydPTWqa6tTTkRPaWhsKP4xxxX/mAAAnbWmpSV2u2x9J35s6tToU60TAwBQOta1rIspl02JiIjZU2dHbXVtuoEAKpxBBYAOSJIkVj6/srANAACVJkmSWLZSJwYAoDQlSRLPr3y+sA1Aulz6AQAAAAAAAAAoGoMKAAAAAAAAAEDRGFQAAAAAAAAAAIoml3YAAAAAAACA3qixoTHtCABQlqyoAAAAAAAAAAAUjRUVADogk8nENttvU9gGAIBKk8lkYrdtdGIAAEpTJpOJ7bfZvrANQLoMKgB0QHVtdXx+9ufTjgEAAKnpU10df/q8TgwAQGmqra6N2Z+fnXYMAF5nUAEAAACgWBoaKuOYAAAAsBlVaQcAAAAAAAAAACqHFRUAOqBlXUtcceoVERFxyuWnRHVtdcqJKCcNjQ3FP+a44h8TAChta1paYr8r1nfiB045JfpU68QAAJSOdS3r4tQrTo2IiMtPuTxqq2tTTgRQ2QwqAHRAkiTx4rIXC9sAAFBpkiSJx17UiQEAKE1JksSyF5cVtgFIl0EFAACAcuN69AAAAJSxxobGoh9zXMO4oh8TyllV2gEAAAAAAAAAgMphUAEAAAAAAAAAKBqDCgAAAAAAAABA0eTSDgCVqKGxIe0IAAAAAAAAAKkwqADQAZlMJgYOGVjYBgCASpPJZGL7gToxAAClKZPJxJCBQwrbAKTLoAJAB1TXVscZ15+RdgwAAEhNn+rqWHrGGWnHAACALqmtro3rz7g+7RgAvK4q7QAAAAAAAAAAQOUwqAAAAAAAAAAAFI1BBYAOaGlqiStOvSKuOPWKaGlqSTsOAAAU3dqWltjviitivyuuiLUtOjEAAKWlqaUpTr3i1Dj1ilOjqaUp7TgAFS+XdgCAUpC0J/Hc4ucK2wAAHdbQkHYC6BbtSRIPPvdcYRsAAEpJe9Iei59bXNiGzmpsaCz6Mcc1jCv6MaFYDCoAAAAAAAC9Xhr/SAgA9AyXfgAAAAAAAAAAisaKCgBQgRoaG4p/zHHFPyYAAAAAAND7GFQAAAAAKGcNDZVxTAAAAEqGSz8AAAAAAAAAAEVjRQWADuozsE/aEQAAIFVb99GJAQAoXQP7DEw7AgCvM6gA0AH5unycdfNZaccAAIDU9M3n48WzdGIAAEpTXb4ubj7r5rRjAPA6gwoAAEDlcM10AADoFo0NjWlHAABKWFXaAQAAAAAAAACAymFFBYAOaGlqiWu/fG1ERJzwzROiuqY65URQehoaG4p/zHHFPyYAlKu1LS1x5LXrO/GtJ5wQddU6MQAApaOppSm+fO2XIyLimyd8M2qqa1JOBFDZDCpQ8dL4hzNKT9KexLJHlxW2AQCg0rQnSdy1bFlhGwAASkl70h6PLnu0sA1AugwqAAAAANC9Ghoq45gAANCDGhsai37McQ3jin5MKlNV2gEAAAAAAAAAgMphRQUAAAAAAChhaXziFgDgnTCoAACUrYbGhuIfc1zxjwkAAAAAAKXEoAIAAJAO1xIHAAAAgIpkUAGgg6prq9OOAAAAqepTrRMDAFC6aqtr044AvV4alxMa1zCu6MckfQYV6FXSWKIbOiJfl49zbj0n7RgAAJCavvl8rD5HJwYAoDTV5evi1nNuTTsGAK+rSjsAAAAAAAAAAFA5rKgAAAAAQOlraKiMYwIAAJQBgwoAHdDa3Bo/PfenERFx7FePjVzer09g44p9GaOGccU9HgCVa11ra/zrT9d34p8fe2zU5nRiANiYNK7tDby95tbmOPen50ZExFeP/Wrkc/mUEwFvSOP/neMaxhX9mGzIuwpsUrH/oQV6s/a29lhy/5LCNgAAVJq29vaYu2RJYRsIqzgAQAlpa2+L+5fcX9gGIF0GFQAAAP/oAQAAAAAUTa8YVLjsssviwgsvjBUrVsTo0aPjO9/5Tuy///5pxwIA6PXSWAHJ5SY6RscFAKDc6LgAQLlwuYn0pT6o8JOf/CSmTZsWl19+eRxwwAFxySWXxIc+9KFYvHhxDB48OO14vYbLMAAAlA4dFwCAclOqHTeNf4QAAODtpT6ocPHFF8cpp5wSn/rUpyIi4vLLL485c+bED37wgzj77LNTTgcAAJ2n4wIAPSaNyzW5RBSh4wIAvFNWcdhQqoMKzc3N8dBDD0V9fX3hvqqqqhg/fnzce++9KSbbPKsbAACwKaXacQEANslwRMXTcQEA6G6pDiq89NJL0dbWFkOGDNng/iFDhsSf//znt+zf1NQUTU1NhdsrV66MiIhXX321Z4P+c47VTW+/E1BWmtc1F7ab1jRF0p4U58Dr3rS9JiLai3NYgM0pdvd643hJUqTfve9QqXbcaNJxgc1b3fyPTvxqU1O0FfH3cnPzP6rxq00R+dL4XwLwTrzpH8TL9Zil1HM723Ejek/PXd20uqjHA3qvdc3/eLN1TdOaaE+82QqUv978Xm7ql37ojBkzZsT555//lvuHDx+eQhqgUl38sYvTOfDH0jkswD+bGTNTOe5rr70WAwcOTOXYPUnHBUrRthen1IkjYmZ6hwbK3Uw9tzvpuUBv9rGLvdkKVIh0Km6HOm6qgwpbb711ZLPZeP755ze4//nnn4+hQ4e+Zf/6+vqYNm1a4XZ7e3u8/PLLsdVWW0Umk9nkcV599dUYPnx4PPvsszFgwIDuewH0Ks5zZXCeK4PzXBmc58rQHec5SZJ47bXXYtttt+3mdD2jWB23K/y5qwzOc2Vwnsufc1wZnOfKsKnzXEo9t7MdN6J4Pdefo/Lm/JYv57a8Ob/ly7ktb8V+LzfVQYV8Ph/77LNPzJs3LyZNmhQR6wvrvHnz4vTTT3/L/jU1NVFTU7PBfYMGDerw8QYMGOAPTQVwniuD81wZnOfK4DxXhnd6nkvpE2bF7rhd4c9dZXCeK4PzXP6c48rgPFeGjZ3nUum5ne24EcXvuf4clTfnt3w5t+XN+S1fzm15K9Z7ualf+mHatGkxefLk2HfffWP//fePSy65JFavXh2f+tSn0o4GAABdouMCAFBudFwAALpT6oMKxx13XLz44otx7rnnxooVK2KvvfaK2267LYYMGZJ2NAAA6BIdFwCAcqPjAgDQnVIfVIiIOP300ze5RFh3qKmpifPOO+8tS41RXpznyuA8VwbnuTI4z5Whks9zT3fcrqjk81FJnOfK4DyXP+e4MjjPlaGczrOOS7E5v+XLuS1vzm/5cm7LW7HPbyZJkqQoRwIAAAAAAAAAKl5V2gEAAAAAAAAAgMphUAEAAAAAAAAAKBqDCgAAAAAAAABA0ZTNoMJll10WI0aMiNra2jjggAPi97///Wb3/9nPfhbvfe97o7a2NvbYY4+YO3dukZLyTnTmPF9xxRVx8MEHxxZbbBFbbLFFjB8//m3/u6B36Oyf5zdcf/31kclkYtKkST0bkG7R2fP897//PaZOnRrDhg2Lmpqa2Hnnnf3uLgGdPc+XXHJJ7LLLLlFXVxfDhw+PM888M9atW1ektHTFb37zmzjqqKNi2223jUwmEzfffPPbfk9jY2PsvffeUVNTEzvttFPMnj27x3NWEr24MujFlUEvLn86cWXQicufTtzzdNzyptuWL322vOmy5Ut/LU+9srMmZeD6669P8vl88oMf/CD505/+lJxyyinJoEGDkueff36j+99zzz1JNptN/uu//it57LHHkv/4j/9Iqqurk4ULFxY5OZ3R2fP8yU9+MrnsssuSRx55JFm0aFEyZcqUZODAgclf/vKXIienMzp7nt/w9NNPJ+9617uSgw8+OJk4cWJxwtJlnT3PTU1Nyb777ptMmDAhufvuu5Onn346aWxsTBYsWFDk5HRGZ8/ztddem9TU1CTXXntt8vTTTye33357MmzYsOTMM88scnI6Y+7cuclXvvKV5MYbb0wiIrnppps2u/9TTz2V9OnTJ5k2bVry2GOPJd/5zneSbDab3HbbbcUJXOb04sqgF1cGvbj86cSVQSeuDDpxz9Jxy5tuW7702fKmy5Yv/bV89cbOWhaDCvvvv38yderUwu22trZk2223TWbMmLHR/Y899tjkwx/+8Ab3HXDAAcnnPve5Hs3JO9PZ8/zPWltbk/79+ydXX311T0WkG3TlPLe2tiZjx45Nvv/97yeTJ09WYEtAZ8/zrFmzkve85z1Jc3NzsSLSDTp7nqdOnZocdthhG9w3bdq05MADD+zRnHSfjhTcf//3f09GjRq1wX3HHXdc8qEPfagHk1UOvbgy6MWVQS8ufzpxZdCJK49O3P103PKm25Yvfba86bLlS3+tDL2ls5b8pR+am5vjoYceivHjxxfuq6qqivHjx8e999670e+59957N9g/IuJDH/rQJvcnfV05z/9szZo10dLSEltuuWVPxeQd6up5/upXvxqDBw+Oz3zmM8WIyTvUlfP8y1/+MsaMGRNTp06NIUOGxO677x7f+MY3oq2trVix6aSunOexY8fGQw89VFhK7Kmnnoq5c+fGhAkTipKZ4tDDeo5eXBn04sqgF5c/nbgy6MRsig7WcTpuedNty5c+W9502fKlv/JmxehUuW57ppS89NJL0dbWFkOGDNng/iFDhsSf//znjX7PihUrNrr/ihUreiwn70xXzvM/+/KXvxzbbrvtW/5Q0Xt05TzffffdceWVV8aCBQuKkJDu0JXz/NRTT8Wvf/3rOOGEE2Lu3LnxxBNPxOc///loaWmJ8847rxix6aSunOdPfvKT8dJLL8VBBx0USZJEa2trnHrqqXHOOecUIzJFsqke9uqrr8batWujrq4upWSlTy+uDHpxZdCLy59OXBl0YjZFJ+44Hbe86bblS58tb7ps+dJfebNidNaSX1EBOmLmzJlx/fXXx0033RS1tbVpx6GbvPbaa3HiiSfGFVdcEVtvvXXacehB7e3tMXjw4Pje974X++yzTxx33HHxla98JS6//PK0o9GNGhsb4xvf+Eb87//+bzz88MNx4403xpw5c+JrX/ta2tEAyoZeXJ704sqgE1cGnRig43Tb8qHPlj9dtnzpr7wTJb+iwtZbbx3ZbDaef/75De5//vnnY+jQoRv9nqFDh3Zqf9LXlfP8hosuuihmzpwZd955Z+y55549GZN3qLPn+cknn4ylS5fGUUcdVbivvb09IiJyuVwsXrw4dtxxx54NTad15c/zsGHDorq6OrLZbOG+XXfdNVasWBHNzc2Rz+d7NDOd15Xz/J//+Z9x4oknxsknnxwREXvssUesXr06PvvZz8ZXvvKVqKoyX1kONtXDBgwY4JNj75BeXBn04sqgF5c/nbgy6MRsik7ccTpuedNty5c+W9502fKlv/JmxeisJf9fRz6fj3322SfmzZtXuK+9vT3mzZsXY8aM2ej3jBkzZoP9IyLuuOOOTe5P+rpyniMi/uu//iu+9rWvxW233Rb77rtvMaLyDnT2PL/3ve+NhQsXxoIFCwpfH/3oR+PQQw+NBQsWxPDhw4sZnw7qyp/nAw88MJ544onCX1AiIh5//PEYNmyYEttLdeU8r1mz5i3F9Y2/vCRJ0nNhKSo9rOfoxZVBL64MenH504krg07MpuhgHafjljfdtnzps+VNly1f+itvVpROlZSB66+/PqmpqUlmz56dPPbYY8lnP/vZZNCgQcmKFSuSJEmSE088MTn77LML+99zzz1JLpdLLrroomTRokXJeeedl1RXVycLFy5M6yXQAZ09zzNnzkzy+Xxyww03JMuXLy98vfbaa2m9BDqgs+f5n02ePDmZOHFikdLSVZ09z88880zSv3//5PTTT08WL16c3HLLLcngwYOTr3/962m9BDqgs+f5vPPOS/r375/8+Mc/Tp566qnkV7/6VbLjjjsmxx57bFovgQ547bXXkkceeSR55JFHkohILr744uSRRx5Jli1bliRJkpx99tnJiSeeWNj/qaeeSvr06ZOcddZZyaJFi5LLLrssyWazyW233ZbWSygrenFl0Isrg15c/nTiyqATVwaduGfpuOVNty1f+mx502XLl/5avnpjZy2LQYUkSZLvfOc7yXbbbZfk8/lk//33T+67777CY4ccckgyefLkDfb/6U9/muy8885JPp9PRo0alcyZM6fIiemKzpzn7bffPomIt3ydd955xQ9Op3T2z/ObKbClo7Pn+Xe/+11ywAEHJDU1Ncl73vOe5IILLkhaW1uLnJrO6sx5bmlpSRoaGpIdd9wxqa2tTYYPH558/vOfT1555ZXiB6fD5s+fv9H/375xbidPnpwccsghb/mevfbaK8nn88l73vOe5Kqrrip67nKmF1cGvbgy6MXlTyeuDDpx+dOJe56OW9502/Klz5Y3XbZ86a/lqTd21kySWHcDAAAAAAAAACiOqrffBQAAAAAAAACgexhUAAAAAAAAAACKxqACAAAAAAAAAFA0BhUAAAAAAAAAgKIxqAAAAAAAAAAAFI1BBQAAAAAAAACgaAwqAAAAAAAAAABFY1ABAAAAAAAAACgagwpAqqZMmRKTJk16R8+xdOnSyGQysWDBgk3u09jYGJlMJv7+979HRMTs2bNj0KBBhccbGhpir732ekc5umrFihXxgQ98IPr27btBpp6Q5uvsCR059wAAxabj6rjvhI4LAND76PgA3c+gAtAhU6ZMiUwmE5lMJvL5fOy0007x1a9+NVpbW9OO1iFjx46N5cuXx8CBAzf6+PTp02PevHmF291RPDvq29/+dixfvjwWLFgQjz/++Eb3aWhoKPz8M5lMDBw4MA4++OC46667OnWsf36dvcVtt90WmUwmVqxYscH9w4YNixEjRmxw3xuFft68eTF8+PBYvnx57L777kVMCwCUCx235+i4Oi4AQFpKuef35o4P0N0MKgAddsQRR8Ty5ctjyZIl8aUvfSkaGhriwgsv3Oi+zc3NRU63efl8PoYOHRqZTGajj/fr1y+22mqrIqda78knn4x99tknRo4cGYMHD97kfqNGjYrly5fH8uXL4957742RI0fGRz7ykVi5cmWHj5Xm69ycgw46KHK5XDQ2NhbuW7RoUaxduzZeeeWVWLp0aeH++fPnR01NTRx44IGRzWZj6NChkcvlih/6TZIkKYm/6AAAb6Xj9gwdV8cFAEhTR3u+jg+QHoMKQIfV1NTE0KFDY/vtt4/TTjstxo8fH7/85S8j4h+TmxdccEFsu+22scsuu0RExMKFC+Owww6Lurq62GqrreKzn/1srFq16i3Pff7558c222wTAwYMiFNPPXWDgnjbbbfFQQcdFIMGDYqtttoqPvKRj8STTz75luf485//HGPHjo3a2trYfffdN/gk1j8vmfXP3rxkVkNDQ1x99dXxi1/8ojB529jYGIcddlicfvrpG3zfiy++GPl8frOf4Jo1a1bsuOOOkc/nY5dddokf/vCHhcdGjBgRP//5z+Oaa66JTCYTU6ZM2eTz5HK5GDp0aAwdOjR22223+OpXvxqrVq3a4BNqf//73+Pkk08u/CwPO+ywePTRRzf6OiP+cd4uuuiiGDZsWGy11VYxderUaGlpKeyzfPny+PCHPxx1dXWxww47xHXXXRcjRoyISy65ZJNZH3jggfjABz4QW2+9dQwcODAOOeSQePjhhze5f79+/WK//fbb4E3cxsbGOOigg+LAAw98y/3ve9/7ora29i3Lpb1xnufNmxf77rtv9OnTJ8aOHRuLFy9+y8/ghz/8YYwYMSIGDhwYn/jEJ+K1114r7NPe3h4zZsyIHXbYIerq6mL06NFxww03bJAhk8nErbfeGvvss0/U1NTE3XffvcnXBwD0XjqujqvjxgbH0XEBgHKwqZ6v4/e+lciAymVQAeiyurq6DYrYvHnzYvHixXHHHXfELbfcEqtXr44PfehDscUWW8QDDzwQP/vZz+LOO+98S0maN29eLFq0KBobG+PHP/5x3HjjjXH++ecXHl+9enVMmzYtHnzwwZg3b15UVVXF0UcfHe3t7Rs8z1lnnRVf+tKX4pFHHokxY8bEUUcdFX/72986/bqmT58exx57bGHqdvny5TF27Ng4+eST47rrroumpqbCvj/60Y/iXe96Vxx22GEbfa6bbropvvjFL8aXvvSl+OMf/xif+9zn4lOf+lTMnz8/Ita/2XnEEUfEscceG8uXL49LL720QxmbmpriqquuikGDBhXKdETExz/+8XjhhRfi1ltvjYceeij23nvvOPzww+Pll1/e5HPNnz8/nnzyyZg/f35cffXVMXv27Jg9e3bh8ZNOOimee+65aGxsjJ///Ofxve99L1544YXN5nvttddi8uTJcffdd8d9990XI0eOjAkTJmzwRuk/O/TQQws/lzdyjRs3Lg455JAN7m9sbIxDDz10s8f/yle+Et/61rfiwQcfjFwuF5/+9Kc3ePzJJ5+Mm2++OW655Za45ZZb4q677oqZM2cWHp8xY0Zcc801cfnll8ef/vSnOPPMM+P//b//95ZliM8+++yYOXNmLFq0KPbcc8/NZgIASoOOq+Nuio4LAFC63tzzdXyAXiIB6IDJkycnEydOTJIkSdrb25M77rgjqampSaZPn154fMiQIUlTU1Phe773ve8lW2yxRbJq1arCfXPmzEmqqqqSFStWFL5vyy23TFavXl3YZ9asWUm/fv2Stra2jWZ58cUXk4hIFi5cmCRJkjz99NNJRCQzZ84s7NPS0pK8+93vTr75zW8mSZIk8+fPTyIieeWVV5IkSZKrrroqGThwYGH/8847Lxk9evRGX+8b1q5dm2yxxRbJT37yk8J9e+65Z9LQ0LDJn9vYsWOTU045ZYP7Pv7xjycTJkwo3J44cWIyefLkTT7HG/mqqqqSvn37Jn379k0ymUwyYMCA5NZbby3s89vf/jYZMGBAsm7dug2+d8cdd0y++93vbvJ1br/99klra+sG+Y477rgkSZJk0aJFSUQkDzzwQOHxJUuWJBGRfPvb395s5jdra2tL+vfvn/zf//3fJve54447kohInnvuuSRJkmTw4MHJ73//++R3v/tdsv322ydJkiRPPvlkEhHJXXfdlSTJP879I488kiTJP87znXfeWXjeOXPmJBGRrF27tvAz6NOnT/Lqq68W9jnrrLOSAw44IEmSJFm3bl3Sp0+f5He/+90G+T7zmc8kxx9//AbHufnmmzv8MwAAeh8dV8d9g46r4wIA5WNzPV/HB+g9rKgAdNgtt9wS/fr1i9ra2jjyyCPjuOOOi4aGhsLje+yxR+Tz+cLtRYsWxejRo6Nv376F+w488MBob2/fYJnS0aNHR58+fQq3x4wZE6tWrYpnn302IiKWLFkSxx9/fLznPe+JAQMGxIgRIyIi4plnntkg35gxYwrbuVwu9t1331i0aFG3vPaIiNra2jjxxBPjBz/4QUREPPzww/HHP/5xs0vZLlq0KA488MAN7jvwwAO7lGuXXXaJBQsWxIIFC+Khhx6K0047LT7+8Y/Hgw8+GBERjz76aKxatSq22mqr6NevX+Hr6aef3ugSY28YNWpUZLPZwu1hw4YVPk22ePHiyOVysffeexce32mnnWKLLbbYbNbnn38+TjnllBg5cmQMHDgwBgwYEKtWrXrLOXuzsWPHRj6fj8bGxnjsscdi7dq1sffee8e+++4bL774Yjz99NPR2NgYdXV18b73vW+zx3/zJ7+GDRsWEbHBJ+RGjBgR/fv33+hrfuKJJ2LNmjXxgQ98YIOf4zXXXPOWn+O+++672RwAQO+n4+q4ETrum+m4AEA52FzP1/EBeodc2gGA0nHooYfGrFmzIp/Px7bbbhu53Ia/Qt5c5LrTUUcdFdtvv31cccUVse2220Z7e3vsvvvuGyzJWywnn3xy7LXXXvGXv/wlrrrqqjjssMNi++23L8qx8/l87LTTToXb//Iv/xI333xzXHLJJfGjH/0oVq1aFcOGDdvgWrdvGDRo0Caft7q6eoPbmUzmLcuRddbkyZPjb3/7W1x66aWx/fbbR01NTYwZM2az56xPnz6x//77x/z58+Pll1+Ogw46KLLZbGSz2Rg7dmzMnz8/5s+fHwceeOAGf5F4u9eUyWQiIjZ4TZt7zW9ce27OnDnxrne9a4P9ampqNrjdU//NAwDFo+PquB2l4wIAlI7N9XwdH6B3sKIC0GF9+/aNnXbaKbbbbru3vIG7Mbvuums8+uijsXr16sJ999xzT1RVVW1wzdlHH3001q5dW7h93333Rb9+/WL48OHxt7/9LRYvXhz/8R//EYcffnjsuuuu8corr2z0ePfdd19hu7W1NR566KHYddddu/JSI5/PR1tb21vu32OPPWLfffeNK664Iq677rq3XBf2n+26665xzz33bHDfPffcE7vttluXcv2zbDZb+NntvffesWLFisjlcrHTTjtt8LX11lt36fl32WWXaG1tjUceeaRw3xNPPLHJc/CGe+65J77whS/EhAkTYtSoUVFTUxMvvfTS2x7v0EMPjcbGxmhsbIxx48YV7n//+98fjY2Ncdddd73ttXvfqd122y1qamrimWeeecvPcfjw4T16bACg+HRcHTdCxwUAKDed6fk6PkA6DCoAPeaEE06I2tramDx5cvzxj3+M+fPnx7/927/FiSeeGEOGDCns19zcHJ/5zGfisccei7lz58Z5550Xp59+elRVVcUWW2wRW221VXzve9+LJ554In7961/HtGnTNnq8yy67LG666ab485//HFOnTo1XXnmlywVsxIgR8Yc//CEWL14cL730UrS0tBQeO/nkk2PmzJmRJEkcffTRm32es846K2bPnh2zZs2KJUuWxMUXXxw33nhjTJ8+vdOZWltbY8WKFbFixYpYsmRJfP3rX4/HHnssJk6cGBER48ePjzFjxsSkSZPiV7/6VSxdujR+97vfxVe+8pXC0rmd9d73vjfGjx8fn/3sZ+P3v/99PPLII/HZz3426urqCp/i2piRI0fGD3/4w1i0aFHcf//9ccIJJ0RdXd3bHu/QQw+NJUuWxO233x6HHHJI4f5DDjkkbr755nj22Wd7/E3c/v37x/Tp0+PMM8+Mq6++Op588sl4+OGH4zvf+U5cffXVPXpsAKD303F1XB0XAKC86PgA6TCoAPSYPn36xO233x4vv/xy7LfffvGxj30sDj/88Pif//mfDfY7/PDDY+TIkfH+978/jjvuuPjoRz9auF5YVVVVXH/99fHQQw/F7rvvHmeeeWZceOGFGz3ezJkzY+bMmTF69Oi4++6745e//GWXP2V1yimnxC677BL77rtvbLPNNht8Yuz444+PXC4Xxx9/fNTW1m72eSZNmhSXXnppXHTRRTFq1Kj47ne/G1ddddUGn6TqqD/96U8xbNiwGDZsWOy1117x05/+NGbNmhUnnXRSRKxf2nXu3Lnx/ve/Pz71qU/FzjvvHJ/4xCdi2bJlGxTqzrrmmmtiyJAh8f73vz+OPvroOOWUU6J///6bfe1XXnllvPLKK7H33nvHiSeeGF/4whdi8ODBb3usMWPGRE1NTSRJEvvss0/h/gMOOCBaWlqiX79+sd9++3X5tXTU1772tfjP//zPmDFjRuy6665xxBFHxJw5c2KHHXbo8WMDAL2bjqvj6rgAAOVFxwdIRyZJkiTtEAClZOnSpbHjjjvGAw88EHvvvXfacYruL3/5SwwfPjzuvPPOOPzww9OOAwBAN9BxdVwAAMpLpXd8oPczqADQQS0tLfG3v/0tpk+fHk8//fRbrstbrn7961/HqlWrYo899ojly5fHv//7v8df//rXePzxx6O6ujrteAAAvAM6ro4LAEB5qdSOD5SeXNoBAErFPffcE4ceemjsvPPOccMNN6Qdp2haWlrinHPOiaeeeir69+8fY8eOjWuvvdYbuAAAZUDH1XEBACgvldrxgdJjRQUAAAAAAAAAoGiq0g4AAAAAAAAAAFQOgwoAAAAAAAAAQNEYVAAAAAAAAAAAisagAgAAAAAAAABQNAYVAAAAAAAAAICiMagAAAAAAAAAABSNQQUAAAAAAAAAoGgMKgAAAAAAAAAARWNQAQAAAAAAAAAomv8PmKKuwiA6KRoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression: Threshold Tuning Results\n",
        "\n",
        "---\n",
        "\n",
        "#### **Performance Comparison**\n",
        "\n",
        "| **Threshold** | **Metric**                      | **Winners (%)** | **Non-Winners (%)** |\n",
        "|---------------|----------------------------------|------------------|----------------------|\n",
        "| **Standard (0.5)** | Correct Predictions          | 37.51           | 80.78               |\n",
        "| **Adjusted (0.45)** | Correct Predictions          | 67.78           | 52.10               |\n",
        "| **Standard (0.5)** | Misclassification Rate       | 62.49           | 19.22               |\n",
        "| **Adjusted (0.45)** | Misclassification Rate       | 32.22           | 47.90               |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Key Observations**\n",
        "\n",
        "1. **Standard Threshold (0.5)**:\n",
        "   - Provides better results for non-winners with an **80.78% correct prediction rate**.\n",
        "   - Struggles with winners, achieving only **37.51% correct predictions**.\n",
        "\n",
        "2. **Adjusted Threshold (0.45)**:\n",
        "   - Improves predictions for winners significantly (**+30.27% increase**).\n",
        "   - Reduces accuracy for non-winners (**-28.68% decrease**).\n",
        "\n",
        "---\n",
        "\n",
        "#### **Insights and Recommendations**\n",
        "\n",
        "- **Threshold Selection**:\n",
        "  - Standard threshold (0.5) reflects balanced scenarios, better suited for **non-winner prioritization**.\n",
        "  - Adjusted threshold (0.45) works well for **winner-sensitive applications**, improving their identification.\n",
        "\n",
        "- **Trade-Off**:\n",
        "  - Lowering the threshold favors recall for winners but sacrifices precision for non-winners.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "XUO-uadcH5QQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}